<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[遇到未解决的问题]]></title>
    <url>%2F2018%2F10%2F01%2F%E9%81%87%E5%88%B0%E6%9C%AA%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"></content>
      <categories>
        <category>问题</category>
      </categories>
      <tags>
        <tag>未解决的问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haoop第三天之脚本分析，单个进程启动]]></title>
    <url>%2F2018%2F09%2F30%2Fhaoop%E7%AC%AC%E4%B8%89%E5%A4%A9%E4%B9%8B%E8%84%9A%E6%9C%AC%E5%88%86%E6%9E%90%EF%BC%8C%E5%8D%95%E4%B8%AA%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[ssh权限问题1.~/.ssh/authorized_keys 644 2.$/.ssh 700 3.root 配置SSH生成密钥对 $&gt;ssh-keygen -t rsa -P &apos;&apos; -f ~/.ssh/id_rsa 添加认证文件 $&gt;cat ~/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keys 权限设置,文件和文件夹权限除了自己之外，别人不可写。 $&gt;chmod 700 ~/.ssh $&gt;chmod 644 ~/.ssh/authorized_keys scp远程复制. rsync远程同步,支持符号链接。 rsync -lr xxx xxx 完全分布式1.配置文件 [core-site.xml] fs.defaultFS=hdfs://s201:8020/ [hdfs-site.xml] replication=1 //伪分布 replication=3 //完全分布 [mapred-site.xml] mapreduce.framework.name=yarn [yarn-site.xml] rm.name=s201 [slaves] s202 s203 s204 2.分发文件 a)ssh openssh-server //sshd openssh-clients //ssh openssh //ssh-keygen b)scp/rsync 3.格式化文件系统 $&gt;hadoop namenode -format 4.启动hadoop所有进程 //start-dfs.sh + start-yarn.sh $&gt;start-all.sh 5.xcall.sh jps /usr/local/bin/jps /usr/local/bin/java 6.查看jps进程 $&gt;xcall.sh jps 7.关闭centos的防火墙 $&gt;sudo service firewalld stop // &lt;=6.5 start/stop/status/restart $&gt;sudo systemctl stop firewalld // 7.0 停止 start/stop/status/restart $&gt;sudo systemctl disable firewalld //关闭 $&gt;sudo systemctl enable firewalld //启用 7.最终通过webui http://s201:50070/ 符号连接1.修改符号连接的owner $&gt;chown -h centos:centos xxx //-h:针对连接本身，而不是所指文件. 2.修改符号链接 $&gt;ln -sfT index.html index //覆盖原有的连接。 hadoop模块common // hdfs // mapreduce // yarn // 进程[hdfs]start-dfs.sh NameNode NN DataNode DN SecondaryNamenode 2NN [yarn]start-yarn.sh ResourceMananger RM NodeManager NM 脚本分析sbin/start-all.sh -------------- libexec/hadoop-config.sh start-dfs.sh start-yarn.sh sbin/start-dfs.sh -------------- libexec/hadoop-config.sh sbin/hadoop-daemons.sh --config .. --hostname .. start namenode ... sbin/hadoop-daemons.sh --config .. --hostname .. start datanode ... sbin/hadoop-daemons.sh --config .. --hostname .. start sescondarynamenode ... sbin/hadoop-daemons.sh --config .. --hostname .. start zkfc ... // sbin/start-yarn.sh -------------- libexec/yarn-config.sh bin/yarn-daemon.sh start resourcemanager bin/yarn-daemons.sh start nodemanager sbin/hadoop-daemons.sh ---------------------- libexec/hadoop-config.sh slaves hadoop-daemon.sh sbin/hadoop-daemon.sh ----------------------- libexec/hadoop-config.sh bin/hdfs .... sbin/yarn-daemon.sh ----------------------- libexec/yarn-config.sh bin/yarn bin/hadoop ------------------------ hadoop verion //版本 hadoop fs //文件系统客户端. hadoop jar // hadoop classpath hadoop checknative bin/hdfs ------------------------ dfs // === hadoop fs classpath namenode -format secondarynamenode namenode journalnode zkfc datanode dfsadmin haadmin fsck balancer jmxget mover oiv oiv_legacy oev fetchdt getconf groups snapshotDiff lsSnapshottableDir portmap nfs3 cacheadmin crypto storagepolicies version hdfs常用命令$&gt;hdfs dfs -mkdir /user/centos/hadoop $&gt;hdfs dfs -ls -r /user/centos/hadoop $&gt;hdfs dfs -lsr /user/centos/hadoop $&gt;hdfs dfs -put index.html /user/centos/hadoop $&gt;hdfs dfs -get /user/centos/hadoop/index.html a.html $&gt;hdfs dfs -rm -r -f /user/centos/hadoop no route 关闭防火墙。 $&gt;su root $&gt;xcall.sh &quot;service firewalld stop&quot; $&gt;xcall.sh &quot;systemctl disable firewalld&quot; hdfs500G 1024G = 2T/4T 切割。 寻址时间:10ms左右 磁盘速率 : 100M /s 64M 128M //让寻址时间占用读取时间的1%. 1ms 1 / 100 size = 181260798 block-0 : 134217728 block-1 : 47043070 -------------------- b0.no : 1073741829 b1.no : 1073741830 HAhigh availability,高可用性。通常用几个9衡量。 99.999% SPOF:single point of failure,单点故障。 secondarynamenode找到所有的配置文件1.tar开hadoop-2.7.3.tar.gz hadoop-2.7.3\share\hadoop\common\hadoop-common-2.7.3.jar\core-default.xml hadoop-2.7.3\share\hadoop\hdfs\hadoop-hdfs-2.7.3.jar\hdfs-default.xml hadoop-2.7.3\share\hadoop\mapreduce\hadoop-mapreduce-client-core-2.7.3.jar\mapred-default.xml hadoop-2.7.3\share\hadoop\yarn\hadoop-yarn-common-2.7.3.jar\yarn-site.xml 本地模式[core-site.xml] fs.defaultFS=file:/// //默认值 配置hadoop临时目录1.配置[core-site.xml]文件 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://s201/&lt;/value&gt; &lt;/property&gt; &lt;!--- 配置新的本地目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/centos/hadoop&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; //以下属性均由hadoop.tmp.dir决定,在hdfs-site.xml文件中配置。 dfs.namenode.name.dir=file://${hadoop.tmp.dir}/dfs/name dfs.datanode.data.dir=file://${hadoop.tmp.dir}/dfs/data dfs.datanode.data.dir=file://${hadoop.tmp.dir}/dfs/data dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary 2.分发core-site.xml文件 $&gt;xsync core-site.xml 3.格式化文件系统,只对namenode的本地目录进行初始化。 $&gt;hadoop namenode -format //hdfs namenode -format 4.启动hadoop $&gt;start-dfs.sh 使用xcall.sh在所有节点上创建jps符号连接，指向/soft/jdk/bin/jps1.切换到root用户 $&gt;su root 2.创建符号连接 $&gt;xcall.sh &quot;ln -sfT /soft/jdk/bin/jps /usr/local/bin/jps&quot; 3.修改jps符号连接的owner $&gt;xcall.sh &quot;chown -h centos:centos /usr/local/bin/jps&quot; 4.查看所有主机上的java进程 $&gt;xcall.sh jps 在centos桌面版中安装eclipse1.下载eclipse linux版 eclipse-jee-mars-R-linux-gtk-x86_64.tar.gz 2.tar开到/soft下, $&gt;tar -xzvf eclipse-jee-mars-R-linux-gtk-x86_64.tar.gz -C /soft 3.启动eclipse $&gt;cd /soft/eclipse $&gt;./eclipse &amp; //后台启动 4.创建桌面快捷方式 $&gt;ln -s /soft/eclipse/eclipse ~/Desktop/eclipse 5. 收集hadoop的所有jar包使用hadoop客户端api访问hdfs1.创建java项目 2.导入hadoop类库 3. 4. 5. 网络拓扑1. 2. 3. 4. 作业1.使用hadoop API递归输出整个文件系统 2.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hadoop第二天之搭建]]></title>
    <url>%2F2018%2F09%2F29%2FHadoop%E7%AC%AC%E4%BA%8C%E5%A4%A9%E4%B9%8B%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[hadoop1.独立模式(standalone|local) nothing! 本地文件系统。 不需要启用单独进程。 2.pesudo(伪分布模式) 等同于完全分布式，只有一个节点。 SSH: //(Socket), //public + private //server : sshd ps -Af | grep sshd //clint : ssh //ssh-keygen:生成公私秘钥。 //authorized_keys 需要使用644 //ssh 192.168.231.201 yes [配置文件] core-site.xml //fs.defaultFS=hdfs://localhost/ hdfs-site.xml //replication=1 mapred-site.xml // yarn-site.xml // 3.full distributed(完全分布式) 让命令行提示符显式完整路径1.编辑profile文件，添加环境变量PS1 [/etc/profile] export PS1=&apos;[\u@\h `pwd`]\$&apos; 2.source $&gt;source /etc/profile 配置hadoop，使用符号连接的方式，让三种配置形态共存。1.创建三个配置目录,内容等同于hadoop目录 ${hadoop_home}/etc/local ${hadoop_home}/etc/pesudo ${hadoop_home}/etc/full 2.创建符号连接 $&gt;ln -s 3.对hdfs进行格式化 $&gt;hadoop namenode -format 4.修改hadoop配置文件，手动指定JAVA_HOME环境变量 [${hadoop_home}/etc/hadoop/hadoop-env.sh] ... export JAVA_HOME=/soft/jdk ... 5.启动hadoop的所有进程 $&gt;start-all.sh 6.启动完成后，出现以下进程 $&gt;jps 33702 NameNode 33792 DataNode 33954 SecondaryNameNode 29041 ResourceManager 34191 NodeManager 7.查看hdfs文件系统 $&gt;hdfs dfs -ls / 8.创建目录 $&gt;hdfs dfs -mkdir -p /user/centos/hadoop 9.通过webui查看hadoop的文件系统 http://localhost:50070/ 10.停止hadoop所有进程 $&gt;stop-all.sh 11.centos防火墙操作 [cnetos 6.5之前的版本] $&gt;sudo service firewalld stop //停止服务 $&gt;sudo service firewalld start //启动服务 $&gt;sudo service firewalld status //查看状态 [centos7] $&gt;sudo systemctl enable firewalld.service //&quot;开机启动&quot;启用 $&gt;sudo systemctl disable firewalld.service //&quot;开机自启&quot;禁用 $&gt;sudo systemctl start firewalld.service //启动防火墙 $&gt;sudo systemctl stop firewalld.service //停止防火墙 $&gt;sudo systemctl status firewalld.service //查看防火墙状态 [开机自启] $&gt;sudo chkconfig firewalld on //&quot;开启自启&quot;启用 $&gt;sudo chkconfig firewalld off //&quot;开启自启&quot;禁用 hadoop的端口50070 //namenode http port 50075 //datanode http port 50090 //2namenode http port 8020 //namenode rpc port 50010 //datanode rpc port hadoop四大模块common hdfs //namenode + datanode + secondarynamenode mapred yarn //resourcemanager + nodemanager 启动脚本1.start-all.sh //启动所有进程 2.stop-all.sh //停止所有进程 3.start-dfs.sh // 4.start-yarn.sh [hdfs] start-dfs.sh stop-dfs.sh NN DN 2NN [yarn] start-yarn.sh stop-yarn.sh RM NM 修改主机名1./etc/hostname s201 2./etc/hosts 127.0.0.1 localhost 192.168.231.201 s201 192.168.231.202 s202 192.168.231.203 s203 192.168.231.204 s204 完全分布式1.克隆3台client(centos7) 右键centos-7--&gt;管理-&gt;克隆-&gt; ... -&gt; 完整克隆 2.启动client 3.启用客户机共享文件夹。 4.修改hostname和ip地址文件 [/etc/hostname] s202 [/etc/sysconfig/network-scripts/ifcfg-ethxxxx] ... IPADDR=.. 5.重启网络服务 $&gt;sudo service network restart 6.修改/etc/resolv.conf文件 nameserver 192.168.231.2 7.重复以上3 ~ 6过程. 准备完全分布式主机的ssh1.删除所有主机上的/home/centos/.ssh/* 2.在s201主机上生成密钥对 $&gt;ssh-keygen -t rsa -P &apos;&apos; -f ~/.ssh/id_rsa 3.将s201的公钥文件id_rsa.pub远程复制到202 ~ 204主机上。 并放置/home/centos/.ssh/authorized_keys $&gt;scp id_rsa.pub centos@s201:/home/centos/.ssh/authorized_keys $&gt;scp id_rsa.pub centos@s202:/home/centos/.ssh/authorized_keys $&gt;scp id_rsa.pub centos@s203:/home/centos/.ssh/authorized_keys $&gt;scp id_rsa.pub centos@s204:/home/centos/.ssh/authorized_keys 4.配置完全分布式(${hadoop_home}/etc/hadoop/) [core-site.xml] &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://s201/&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; [hdfs-site.xml] &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; [mapred-site.xml] 不变 [yarn-site.xml] &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;s201&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; [slaves] s202 s203 s204 [hadoop-env.sh] ... export JAVA_HOME=/soft/jdk ... 5.分发配置 $&gt;cd /soft/hadoop/etc/ $&gt;scp -r full centos@s202:/soft/hadoop/etc/ $&gt;scp -r full centos@s203:/soft/hadoop/etc/ $&gt;scp -r full centos@s204:/soft/hadoop/etc/ 6.删除符号连接 $&gt;cd /soft/hadoop/etc $&gt;rm hadoop $&gt;ssh s202 rm /soft/hadoop/etc/hadoop $&gt;ssh s203 rm /soft/hadoop/etc/hadoop $&gt;ssh s204 rm /soft/hadoop/etc/hadoop 7.创建符号连接 $&gt;cd /soft/hadoop/etc/ $&gt;ln -s full hadoop $&gt;ssh s202 ln -s /soft/hadoop/etc/full /soft/hadoop/etc/hadoop $&gt;ssh s203 ln -s /soft/hadoop/etc/full /soft/hadoop/etc/hadoop $&gt;ssh s204 ln -s /soft/hadoop/etc/full /soft/hadoop/etc/hadoop 8.删除临时目录文件 $&gt;cd /tmp $&gt;rm -rf hadoop-centos $&gt;ssh s202 rm -rf /tmp/hadoop-centos $&gt;ssh s203 rm -rf /tmp/hadoop-centos $&gt;ssh s204 rm -rf /tmp/hadoop-centos 9.删除hadoop日志 $&gt;cd /soft/hadoop/logs $&gt;rm -rf * $&gt;ssh s202 rm -rf /soft/hadoop/logs/* $&gt;ssh s203 rm -rf /soft/hadoop/logs/* $&gt;ssh s204 rm -rf /soft/hadoop/logs/* 10.格式化文件系统 $&gt;hadoop namenode -format 11.启动hadoop进程 $&gt;start-all.sh rsync四个机器均安装rsync命令。 远程同步. $&gt;sudo yum install rsync 将root用户实现无密登录1.同 编写脚本1.xcall.sh 2.xsync.sh xsync.sh /home/etc/a.txt rsync -lr /home/etc/a.txt centos@s202:/home/etc netstat -anop 查看进程]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>搭建</tag>
        <tag>第二天</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop安装配置]]></title>
    <url>%2F2018%2F09%2F24%2FHadoop%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"></content>
      <categories>
        <category>-hadoop</category>
      </categories>
      <tags>
        <tag>-hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之Yum命令]]></title>
    <url>%2F2018%2F09%2F20%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8BYum%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[软件源Repository //仓库. URL //http:// .d //directory目录 xxxd //daemon 查看仓库文件/etc/yum.repos.d/xxx.repo curl传输url上的数据的。 [下载文件到指定目录] curl -o /etc/yum.repos.d/ali.repo http://mirrors.aliyun.com/repo/Centos-7.repo 更换centos的软件源1.下载源仓库文件,xxx.repo curl -o /etc/yum.repos.d/ali.repo http://mirrors.aliyun.com/repo/Centos-7.repo 2.将repo文件保存到/etc/yum.repos.d/目录中。 屏蔽软件仓库1.将/etc/yum.repos.d/xxx.repo文件删除或者更换扩展名即可。 修改centos能够使用sudo命令[/etc/sudoers] $&gt;su root $&gt;nano /etc/sudoers ... centos ALL 使用yum进行软件包安装卸载$&gt;yum list //列出所有软件包 $&gt;yum list installed //列出已经安装的软件包 $&gt;yum list installed | grep nano //列出已经安装的软件包 $&gt;yum search nano //在yum的软件源中搜索软件 $&gt;yum remove nano //卸载软件 $&gt;yum -y install nano //直接安装，不需要yes确认. $&gt;yum list installed | grep nano //查看是否安装了Nano $&gt;mkdir /home/centos/rpms $echo 以下命令只下载软件，不安装软件 $&gt;sudo yum install --downloadonly //只下载 --downloaddir=/home/centos/rpms //指定下载目录 wget //下载已经安装的软件 $&gt;sudo yum reinstall --downloadonly --downloaddir=/home/centos/rpms wget $&gt;sudo yum localinstall xxx.rpm //从本地rpm文件直接安装软件 $&gt;su root $&gt;yum search ifconfig $&gt;yum -y install net-tools //安装网络工具 #==========修改网络地址====================== //需要重启network服务 $&gt;sudo nano /etc/sysconfig/network-scripts/ifcfg-eth1677736 [/etc/sysconfig/network-scripts/ifcfg-eth1677736] ... IPADDR=192.168.231.201 GATEWAY=192.168.231.2 DNS=192.168.231.2 $&gt;service network restart //重启网络服务。 $&gt;sudo nano /etc/resolv.conf //修改该文件不需要重启network服务 [/etc/resolv.conf] nameserver 192.168.231.2 在没有nano时，使用自带的vi文本编辑器1.vi xx.txt 2.模式切换 esc //切换到命令模式,退出编辑模式 //:q! 不保存退出 //:wq 保存退出 //x 删除一个字符 //dd 删除一行 insert //切换到编辑模式,退出命令模式 //del backspace Which命令which命令用于查找并显示给定命令的绝对路径，环境变量PATH中保存了查找命令时需要遍历的目录。 which指令会在环境变量$PATH设置的目录里查找符合条件的文件。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 语法which(选项)(参数)]]></content>
      <tags>
        <tag>Linux基础</tag>
        <tag>Yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础第之循环命令]]></title>
    <url>%2F2018%2F09%2F19%2FLinux%E5%9F%BA%E7%A1%80%E7%AC%AC%E4%B9%8B%E5%BE%AA%E7%8E%AF%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[访问文件(夹)物理位置pwd命令是显示当前的逻辑位置。 物理位置是针对符号连接也是针对软连接的。 //进入/t的物理位置 $&gt;cd -P /t //显式当前目录的物理位置 $&gt;pwd -P 访问环境变量echo ${PATH} //ok echo $PATH //ok echo &quot;$PATH&quot; //ok echo &apos;$PATH&apos; //&apos;&apos;原样输出这个不行，显示“PATH” export定义环境变量,只在session中有效 (当前会话)$&gt;export name=${PATH}:tom 设置name为${Var1}的值，Var1没有设置为${Var2}的值。 $&gt;export name=${Var1:-${Var2}} 命令执行过程$? //命令的返回值存储变量,0:成功 1:失败。 $# //参数个数 $1 //第几个参数 $0 //当前脚本(命令)名称 $@ //取出所有参数 shift //参数左移 ${a/b/c} // 下面一个例子 向左移位解释： if 命令讲解语法: 中括号是可以选择的： if COMMANDS; then COMMANDS; [ elif COMMANDS; then COMMANDS; ]... [ else COMMANDS; ] fi if [ $# -lt 3 ]; then xx ; fi 3,5 使用for循环输出1 - 100个数看一下for的帮助文档，注意从冒号之后是开始的： for NAME [in WORDS ... ] ; do COMMANDS; done for x in a b c d ; do echo $x ; done ; 通过for循环打印一个三角形：首先看一下 然后这段是命令： while语法for: for NAME [in WORDS ... ] ; do COMMANDS; done for ((: for (( exp1; exp2; exp3 )); do COMMANDS; done 一个例子： #!/bin/bash ((i=0)) while ((i&lt;100)) ; do echo $i; i=$((i+1)) done]]></content>
      <tags>
        <tag>linux</tag>
        <tag>循环命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之hostname]]></title>
    <url>%2F2018%2F09%2F19%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8Bhostname%2F</url>
    <content type="text"><![CDATA[命令嵌套使用$&gt;echo `cat b.txt` //命令解析,无法嵌套 $&gt;$(... $()) //支持命令的嵌套 创建用户0.用户和组之间，一个用户可以属于多个组。 但是有一个首要组。 1.adduser,等同于useradd 符号链接。 /usr/sbin/adduser --&gt; /usr/sbin/useradd. 2.useradd 输入新密码. 重复输入 $&gt;su root $&gt;useradd -m centos2 $&gt;su root $&gt;passwd centos2 -m, --create-home create the user&apos;s home directory -p, --password PASSWORD encrypted password of the new account 3.使用方法 $&gt;su root $&gt;userdel -r centos2 //用户所在组目录也会被删除.在删除用户时候要用exit退出要删除的用户,删除的时候可能会exit好多次，因为会来回su。]]></content>
      <tags>
        <tag>Linux基础</tag>
        <tag>基础命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之进程查看]]></title>
    <url>%2F2018%2F09%2F18%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8B%E8%BF%9B%E7%A8%8B%E6%9F%A5%E7%9C%8B%2F</url>
    <content type="text"><![CDATA[job 放到后台运行的进程.1.将程序放到后台运行,以&amp;结尾. $&gt;nano b.txt &amp; 2.查看后台运行的jobs数 $&gt;jobs 3.切换后台作业到前台来. $&gt;fg %n //n是job编号. 4.前台正在的进程，放到后台。 ctrl + z 5.让后作业运行 $&gt;bg %1 // 6.杀死作业 $&gt;kill %1 // man + 命令 ：查看该命令详细帮助 进程查看,prcess show $&gt;ps -Af |grep gnome //-A:所有进程 -f:所有列格式. $&gt;top //动态显示进程信息。含有cpu、内存的使用情况. //q,按照q退出。 cut剪切显示文件的每一行。 $&gt;cut -c 1-5 a.txt //从第一个字符开始,下标从1开始。 $&gt;ps -Af | cut -c 45-80 | more //吧PS里面获得的内容剪切显示，显示没一行的45-80，翻页查看 查看帮助$&gt;help //查看os内置的命令 $&gt;man ifcon fig //查看特定命令 $&gt;ifconfig --help $&gt;ifconfig -h $&gt;info ifconfig // 磁盘分区使用$&gt;fdisk -l /dev/sda 里面的中括号是可选的，尖括号是必须要写的 里面sad是磁盘，sda1是分区。sd1，sd2，sd3是磁盘的三个分区。 查看磁盘使用情况(disk free)$&gt;df -ah /home/centos //查看 dirname取出指定地址的上级目录. $&gt;dirname /a/b/c/d $&gt;/a/b/c basename取出当前地址的上级目录. $&gt;dirname /a/b/c/d $&gt;d 主机名$&gt;hostname //显式主机名 $&gt;修改主机名(sudo) [/etc/hostname] s200 关机重启命令$&gt;reboot //重启 $&gt;halt //停止,黑屏 //halt -p === poweroff //halt -r === reboot $&gt;poweroff //关机 $&gt;shutdown //shutdown now, 命令嵌套1.使用 $&gt;echo `cat b.txt` //命令解析,无法嵌套 $&gt;$(... $()) //支持命令的嵌套 2.]]></content>
      <tags>
        <tag>Linux基础</tag>
        <tag>进程查看</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之符号连接]]></title>
    <url>%2F2018%2F09%2F18%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%AC%A6%E5%8F%B7%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[权限 r //100 = 4 //文件 :读取内容， //文件夹:是查看文件夹的内容 w //文件 :写数据到文件 //文件夹:增删文件. //10 = 2 x //文件 : 运行程序 //文件夹: 进入该目录. // 1 = 1 权限控制涉及范围 U:user ,rwx r-x --- G:group , O:other , 修改文件的owner,change owner chown -R root:root a.txt //递归修改owner chmod -R 777 xxx //递归修改权限. -R :递归显示 -l :列表显示 通过递归改变整个文件夹里面的文件的权限和所有者和所在组 chown -R root:root tmp Linux文件夹 / //根目录 /bin //祖先 /sbin //祖先 /usr/bin //厂商 /usr/sbin //厂商 /usr/local/bin //用户 /usr/local/sbin //用户 /etc //配置目录 /mnt //挂载目录 /boot //引导目录 /dev //设备目录 /lib[64] //库目录 -:文件 d:目录 l:link 等价于windows快捷方式 b:block,块设备 c:charactor,字符文件 创建连接文件 1.硬链接两个完全相同文件，类似于实时备份。两个文件之间完全同步。删除时，只删一个。 目录不能使用硬链接。 ln a.txt alink //a.txt:目标文件, alink:连接名称. ln b.txt b_lnk //硬链接，修改连接文件，源文件也改变，但是删除连接文件源文件不被删除。 硬链接用的很少，大多使用符号连接 mv b_link b.txt 同一目录下改名字就用移动命令即可 2.符号连接-软连接相当于快捷方式. 可以对文件，也可以对文件夹创建符号连接。 符号连接存在的时候，可以删除目标文件。 $&gt;ln -s a.txt alink //a.txt: 目标文件 alink:连接名称(symbolic) blk存放的是路径的字节数大小。开始的时候只想本目录下的b.txt所以是5个字节，后来只想一个绝对路径就变成了28个字符。例子如下图所示 删除掉了链接指向的文件，就会变成红色。删除后在加上就回复正常变成了浅蓝色。 sudo 临时借用root的权限执行命令,只在当前命令下有效。命令结束后，还是原来用户。 1.配置当前用户具有sudo的执行权利 [/etc/sudoers] ... root ALL=(ALL) ALL centos ALL=(ALL) ALL ... $&gt;sudo chown -R centos:centos . 临时切换超级管理员权限 sudo 切换到另外一个用户 su]]></content>
      <tags>
        <tag>linux基础</tag>
        <tag>符号连接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之虚拟机增强工具的安装-文本模式的安装]]></title>
    <url>%2F2018%2F09%2F18%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8B%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%A2%9E%E5%BC%BA%E5%B7%A5%E5%85%B7%E7%9A%84%E5%AE%89%E8%A3%85-%E6%96%87%E6%9C%AC%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[虚拟机增强工具 1.原理 插入iso(C:\myprograms\vmwar11.0.4-x86_64\linux.iso)文件到光盘中。 2.vmware虚拟机菜单 -&gt; 重新安装vmware-tools 3.自动会将C:\myprograms\vmwar11.0.4-x86_64\linux.iso镜像文件插入光驱中，并直接打开。 4.复制VMwareTools-9.9.3-2759765.tar.gz文件到centos的桌面下。 5.tar开该文件. 鼠标右键点击桌面的tar.gz文件，选择 extract here. 6.进入桌面的vmware-tools-distrib目录下. $&gt;su root $&gt;cd /home/centos/Desktop/vmware-tools-distrib 7.执行安装脚本 $&gt;./vmware-install.pl 一路回车。 只到遇到Enjoy!!... 图片为在xshell里面执行。在Mini中执行虚拟机增强的方法： 在mini版的centos7下遇到了很多问题。又在大坑系列中也有这一部分。其实这部分遇到了很多问题，除了视频中的问题，按照如下所示可以完美解决： 为了实现文件夹的共享，要安装vmtools。现在的VMware是11版本。Centos是1151版本。 然后按照视频上讲解的来安装不上。最后先是 这样子，然后 之后按照如图所示挂载即可 本视频还有一个while循环实现99乘法表的例子（我没细看）：]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux基础基础—————踩过的大坑]]></title>
    <url>%2F2018%2F09%2F18%2FLinux%E5%9F%BA%E7%A1%80%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94%E2%80%94%E8%B8%A9%E8%BF%87%E7%9A%84%E5%A4%A7%E5%9D%91%2F</url>
    <content type="text"><![CDATA[问题：图形界面浏览器能访问外网，但是ping不通很奇怪的问题，配置都配置好好的跟着视频一步一步走下来的，按理说应该没问题。但是。。。。 解决：将网络中心里面改成这样子就行了。 具体的网站解释：https://blog.csdn.net/Arnold_lee_yc/article/details/74785995 不通CentOS版本的目录都不太一样。centos7和7.3的目录结构都不同。所以本教程使用的是7.1也就是1503版本的centos 切换用户之后出现这种情况： 解决办法：是在设置centos用户的权限的时候配置错了。修改回来即可 su root vi sudoers 视频里面的人他的ALL写成了小写的l。配置错误 安装VMtools工具为了实现文件夹的共享，要安装vmtools。现在的VMware是11版本。Centos是1151版本。我的理解是需要将那个文件夹挂载到虚拟机上。才能实现共享，可能和VMware的版本有关。网上说vmware14可以直接挂载不需要设置，这里我使用的是vmware11 然后按照视频上讲解的来安装不上。最后先是 这样子，然后 之后按照如图所示挂载即可 克隆机器后网卡设置克隆机器后会出现设置ifg-eno123142这个文件但是设置之后Ip还是没有修改的问题。实际上是因为克隆机器后ifg-eno123123的网卡名字变成了ifcfg-ens33这个这个名字，所以需要把ifg-eno12312这个网卡改名ifg-ens33然后把里面的name和device两个都改成ens33即可。 看这张图下面的网卡名字是ens33，在网卡配置中就要在name和device中写ens33 配置无密登陆在按照视频生成秘钥和公钥的时候，开始的时候删掉的其他机器的.ssh文件。所以导致传输公钥的时候，传输完了之后仍然需要密码。这是由于其他机器的.ssh文件的权限有问题，因为是删除了之后自己重新建立的。所以默认的权限是不对的。这里的网站讲解的非常详细 将ssh文件夹配置成700的属性即可。 https://blog.csdn.net/qq_26442553/article/details/79357498 多次format namenode会导致namenode的id和datanode的id有变化，需要重新格式化/tmp文件夹]]></content>
      <tags>
        <tag>Linux基础</tag>
        <tag>大坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之网络配置-域名解析-光驱挂载]]></title>
    <url>%2F2018%2F09%2F17%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE-%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90-%E5%85%89%E9%A9%B1%E6%8C%82%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[[客户端与宿主机之间的网络连通方式]1.桥接桥接(client完全等价于一台物理主机) 2.NAT(最多,默认模式)a.Net Address transform,网络地址转换. b.客户机能访问外网，可以访问局域网内的其他物理主机。 c.其他的局域网内物理主机不能访问客户机。 3.only host.a.和NAT非常像。 b.不能访问外网。 4.查看client机的网络连接模式a.右键选择Centos客户机。 b.点击&quot;设置&quot; c.网络适配器. 5.查看DHCP的分配网段a.vmware--&gt;编辑--&gt;虚拟网络编辑器 b.选中V8条目 c.下方显示的V8的详细信息。 d.点击DHCP的设置. e.查看分配网段. [修改静态IP]1.切换root用户$&gt;su root 2.编辑/etc/sysconfig/network-scripts/ifcfg-eno16777736a.备份文件 $&gt;cd /etc/sysconfig/network-scripts $&gt;cp ifcfg-eno16777736 ifcfg-eno16777736.bak b.进入/etc/sysconfig/network-scripts $&gt;cd /etc/sysconfig/network-scripts c.编辑ifcfg-eno16777736文件 $&gt;nano ifcfg-eno16777736 TYPE=Ethernet BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=no IPV6_DEFROUTE=no IPV6_PEERDNS=no IPV6_PEERROUTES=no IPV6_FAILURE_FATAL=no NAME=eno16777736 UUID=33f3ce5f-8b5c-41af-90ed-863736e09c29 DEVICE=eno16777736 ONBOOT=yes IPADDR=192.168.231.200 PREFIX=24 GATEWAY=192.168.231.2 DNS=192.168.231.2 注意:查看NAT网络的网关地址。 0)Client机的网卡的DNS和GATEWAY设置为虚拟网卡NAT的网关值。 1)vmware--&gt;编辑--&gt;虚拟网路编辑器 2)v8条目 3)点击&quot;NAT设置&quot;按钮 4)查看网关地址:192.168.231.2(通常为xxx.xxx.xxx.2) e.重启网络服务 $&gt;su root $&gt;service network restart f.解决通过ip能够访问网络，通过域名无法访问的问题。 1)编辑/etc/resolv.conf,添加名称服务器，内容是网关地址。 nameserver 192.168.231.2 2)保存退出 3)重启服务 $&gt;su root $&gt;service network restart 4)测试www.baidu.com $&gt;ping www.baidu.com service管理命令 1.查看服务的状态$&gt;service server_name status //语法 $&gt;service network status $&gt;service network start //启动 $&gt;service network stop //停止 $&gt;service network restart //重启 里面的lo网卡是自回环网络lopback（音似）还有一个就是局域网网卡 其中的ifcfg-lo就是自回环网络 打开里面的内容查看 mount挂载外设 1.右键client右下角的光盘图标 -&gt;设置 2.iso文件 选择一个iso镜像文件。 3.右键client右下角的光盘图标 -&gt;连接. 4.创建文件夹/mnt/cdrom $&gt;su root $&gt;mkdir cdrom 5.挂载光驱/dev/cdrom到/mnt/cdrom $&gt;mount /dev/cdrom /mnt/cdrom $&gt;find . /mnt/cdrom 卸载外设 1.从挂载的目录中出来,否则出现设备繁忙 $&gt;cd .. 2.使用umount进行卸载 $&gt;umount /mnt/cdrom 启用client和host之间共享目录的功能 1.右键点击vmware中的client机，选择设置 2.找到”选项” -&gt; “共享文件夹” 3.选择”总是启用” 4.在文件夹区域中添加要共享的目录 d:/downloads 5.确定. 6.重启客户机.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之网络连接模式]]></title>
    <url>%2F2018%2F09%2F16%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Linux基础之文件类型-权限]]></title>
    <url>%2F2018%2F09%2F16%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8B%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B-%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[目录和权限 [windows] 以磁盘分区物理结构作为文件系统结构 每个用户在/home下面都有一个自己的家目录比如centos的家目录在/home/centos但是root是管理员比较特殊root的目录在/root下~是home的子一级 ‘ [centos] 逻辑结构./ //文件系统的根. /bin //最初的命令(祖先)，binary文件,可执行文件 /sbin //super binary(重要性高) /usr/bin //厂商相关的命令,ubuntu /usr/sbin //厂商相关的命令,ubuntu /usr/local/bin //用户级别。 /usr/local/sbin [Linux文件类型] - //文件 d //目录 l //链接,类似于windows快捷方式. b //block,块文件。 c //字符文件 第一个字母是L的意思是link连接类的。 ifconfig的命令的目录在/sbin/ifconfig这里，但是实际上/sbin已经链接到了/usr/bin里面了。所以CentOS是没有bin和、usr/bin之分的，因为已经link过去了 [linux的权限]一共有9个位，每个成分是从0-7如果是777就是全部权限都付给他了 看这段截图。里面的-rw-rw-r–第一个-是文件类型第rw后面的-是代表0 $&gt;chmod //修改文件(夹)权限 $&gt;chmod g-w //去除group中write权. chmod //不受文件权限控制,只有owner和root才具有文件权限的修改权。 【read权限】 文件 :文件内容 文件夹 :文件夹的内容 【write权限】 ------------ 【execute权限】 ------------- 文件 :执行 文件夹 :进入目录 看下面这个例子： 看最下面的这个chmode 644 a.txt 6是用户的成分。4是组的成分，最后4，是others的成分。所以chmode 644最后是 -rw-r–r– 这里面的小细节格式 ： chmode 655 a.txt chmode g+w a.txt]]></content>
      <tags>
        <tag>Linux基础</tag>
        <tag>文件类型权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础]]></title>
    <url>%2F2018%2F09%2F16%2FLinux%E5%9F%BA%E7%A1%80%E4%B9%8BCentOS%E5%91%BD%E4%BB%A4%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[CentOS Windows $&gt;ls cmd&gt;dir // $&gt;ls --help //查看命令帮助 $&gt;man ls //查看命令帮助 $&gt;clear cmd&gt;cls //清屏 $&gt;cd /home cmd&gt;cd d:/ //切换目录 $&gt;cd . cmd&gt;cd . //进入当前目录 $&gt;cd .. cmd&gt;cd .. //进入上级目录 $&gt;cd /home/centos cmd&gt;cd d:/xx/x/x //进入绝对路径 $&gt;pwd //显式当前目录 $&gt;whoami //显式当前用户名 $&gt;su root //切换用户,输入密码,swith user $&gt;passwd //修改当前用户的密码 $&gt;ifconfig cmd&gt;ipconfig //查看ip地址 $&gt;ping localhost cmd&gt;ping localhost //查看网络连通情况 $&gt;ping www.baidu.com cmd&gt;ping www.baidu.com //查看网络连通情况 $&gt;启动桌面版的网卡 on. $&gt;su centos // $&gt;cd /home/centos // $&gt;cd ~ //回到主目录 $&gt;cd - //回到上次的目录 $&gt;ll //别名,ls -l --autocolor... $&gt;alias //查看所有的别名 $&gt;ls -a -l -h //查看当前目录-h:人性化 -l:列表 -a:显式.开头 $&gt;mkdir ~/Downloads/a //创建目录 $&gt;touch ~/Downloads/a/1.txt //创建文件 $&gt;echo helloworld &gt; 1.txt //重定向输出(覆盖) $&gt;echo helloworld &gt;&gt; 1.txt //重定向输出(追加模式) $&gt;cat 1.txt cmd&gt;type a.txt //查看文件 $&gt;cp 1.txt 2.txt //复制文件 $&gt;rm 1.txt //删除文件 $&gt;rm -rf / //强行递归删除 $&gt;mv a.txt tmp/ //强行递归删除 [centos client中切换模式] ctrl + alt + f6 //切换到文本模式 ctrl + alt //切换鼠标 ctrl + alt + f1 //切换桌面模式. ctrl + alt + f5 //切换到新的文本模式 [nano文本编辑器,命令行模式] $&gt;nano a.txt //打开nano编辑器，编辑a.txt文件 $&gt;.... $&gt;ctrl + o //保存文件,提示后直接回车 $&gt;ctrl + x //退出文件 $&gt;ctrl + k //cut 文本 $&gt;ctrl + u //cut 文本 $&gt;more a.txt //分屏显式 q:退出 h:帮助 $&gt;more -5 a.txt //显式前5行内容 $&gt;tail a.txt //最后10行内容 $&gt;find . | more // | 是管道符，前面的命令的输出作为后面命令输入。 $&gt;find ~ $&gt;ls -aR ~ //递归显式主目录所有的文件.(a表示包含.开头的文件) $&gt;head a.txt //显式前10行 $&gt;head -n 10 a.txt //显式前10行 $&gt;head -10 a.txt //显式前10行 $&gt;tail a.txt $&gt;tail -n 20 a.txt $&gt;tail -20 a.txt $&gt;tail --lines=20 a.txt $&gt;wc -c -l -w a.txt //统计文本信息, //显式统计信息-c:字节 -l:line -w:word $&gt;hostname //查看主机名称 $&gt;uname -r //查看系统内核 $&gt;uname -a //查看系统内核 $&gt;uname -p //查看系统内核 $&gt;uname -m //查看系统内核 $&gt;file xxx.xx //查看文件类型 $&gt;gzip a.txt //原地压缩 $&gt;gzip -d a.txt //原地压缩 $&gt;gzip -dr tmp //递归操纵文件夹下的文件 $&gt;gunzip a.txt.gz //等价于gzip -d a.txt $&gt;tar -cvf my.tar 1.txt tmp //创建归档文件 $&gt;tar -vxf my.tar //解档文件 把多个文件保存到一个文件，也可以从归档文件恢复到单个文件 -c create创建 -f 归档文件名 -vf 列出所有文件在。。里面 -xf 从。。里面抽取所有文件。 —r 追加 -cf 创建 例子 tar -cf my.tar a.txt ：将a.txt归档压缩到my.tar tar -xvf my.tar a.txt: 抽取my.tar里面的a.txt tar -cf my.tar a.txt tmp/ :将a.txt和tmp/都压缩到my.tar里面 xargs 在&apos;xargs&apos;加单引号把他识别为一个命令。 $&gt;find . | grep txt | cp `xargs` temp //xargs是多行变单行，使用空格替换回车换行符. //`` : 是强制命令解析。 反引号’’问题 $&gt;ping `cat a.txt` //命令嵌套 $&gt;which echo //查看命令的文件路径]]></content>
      <tags>
        <tag>linux</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[京东实战项目之hive实战（1）]]></title>
    <url>%2F2018%2F09%2F14%2F%E4%BA%AC%E4%B8%9C%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E4%B9%8Bhive%E5%AE%9E%E6%88%98%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[先熟悉一下Hive的基本语句： 首先里面的库有这么几个表， desc formatted ods_order; 看到表有几个信息 可以看到表的字段的信息。 同时可以看见表的是否是分区表partition information Location:可以看见路径，数据是在哪里的。 table Type: 是否是内部表 可以通过Hive看到进入到dfs里面的路径 可以看见里面文件的大小 通过explain 来看他的hive是怎么走的，看他的执行计划。 观察一个表的分区信息： 查看hadoop正在运行的任务 yarn application -list show functions;//显示hive里所有函数desc function extended add_months//显示里面具体的函数的用法 有时候desc formatted ods_order;里面显示的路径可能会是假的路径。在hadoop搭建的时候配置出问题，就会出现假的路径。 通过命令 desc extended ods_order partition(dt=20151010); //通过这个命令可以找到库表的实际路径。其中的dt是通过 show partition ado_order;来找到的。 以前的0.1之前有些扫描数据的时候默认是不开启mapreduce的。在select的时候是不开启mapreduce的。如果是少量的数据可以直接扫描出来的。但是表的数据非常大，如果不主动开启reduce执行，那么需要手动执行。通过上图来操作。设置是否开启mapreduce来执行。]]></content>
      <tags>
        <tag>hive</tag>
        <tag>实战项目</tag>
        <tag>基本hive语句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础学习笔记]]></title>
    <url>%2F2018%2F09%2F12%2FJava%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Java中的总结合集（1）]]></title>
    <url>%2F2018%2F09%2F12%2FJava%E4%B8%AD%E7%9A%84%E6%80%BB%E7%BB%93%E5%90%88%E9%9B%86%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[关于构造函数构造函数本身是没有返回值的。但是不能加void，一旦加了void就变成了一个函数。 public class sadf { public static void main(String[] args) { Cat cat = new Cat(); cat.cry(); } } abstract class Animal{ public String name; public abstract void cry(); public void Animal() { System.out.println(&quot;new Animal&quot;); } } class Cat extends Animal{ public void cry() { System.out.println(&quot;喵喵12345 &#125; &#125;这样的函数运行之后是 喵喵 因为Animal有void变成了一个函数。还有一个默认的空构造。 应该去掉void。 public class sadf { public static void main(String[] args) { Cat cat = new Cat(); cat.cry(); } } abstract class Animal{ public String name; public abstract void cry(); public Animal() { System.out.println(&quot;new Animal&quot;); } } class Cat extends Animal{ public void cry() { System.out.println(&quot;喵喵1234567 &#125; &#125;***结果是： new Animal 喵喵 关于抽象abstractclass ABSTACT { public static void main(String[] args) { JiaFeiCat j = new JiaFeiCat(); } } abstract class Animal { abstract void cry(); public Animal() { System.out.println(&quot;我是动物&quot;); } } abstract class Cat extends Animal { public Cat() { System.out.println(&quot;我是猫&quot;); } final void catchMouse() { System.out.println(&quot;猫能抓老鼠&quot;); } } final class JiaFeiCat extends Cat { public JiaFeiCat() { System.out.println(&quot;我是加菲猫&quot;); } @Override void cry() { System.out.println(&quot;加菲猫会哭&quot;); } } class BosiCat extends Cat { public BosiCat() { System.out.println(&quot;我叫波斯猫&quot;); } @Override void cry() { System.out.println(&quot;波斯猫会叫&quot;); } } 打印结果： 我是动物 我是猫 我是加菲猫 运行成功abstact抽象类方法可以在子类的子类中继承即可，不用一定在第一代子类中继承。]]></content>
      <tags>
        <tag>Java基础问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop权威指南学习笔记（1）——关于JS在Hadoop里面函数]]></title>
    <url>%2F2018%2F09%2F11%2FHadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[先看一段代码 package lianxi; import java.io.IOException; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.LongWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapred.MapReduceBase; import org.apache.hadoop.mapred.OutputCollector; import org.apache.hadoop.mapred.Reporter; import org.apache.hadoop.mapreduce.Mapper; import org.apache.hadoop.mapreduce.lib.map.WrappedMapper.Context; public class MaxTemperatureMapper extends MapReduceBase implements org.apache.hadoop.mapred.Mapper&lt;LongWritable, Text, Text, IntWritable&gt; { private static final int MISSING = 9999; public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { String line = value.toString(); String year = line.substring(15, 19); int airTemperature; if (line.charAt(87) == &apos;+&apos;) {// parseInt doesn&apos;t like leading plus signs airTemperature = Integer.parseInt(line.substring(88, 92)); } else { airTemperature = Integer.parseInt(line.substring(87, 92)); } String quality = line.substring(92, 93); if (airTemperature != MISSING &amp;&amp; quality.matches(&quot;[01459]&quot;)) { context.write(new Text(year), new IntWritable(airTemperature)); } } @Override public void map(LongWritable arg0, Text arg1, OutputCollector&lt;Text, IntWritable&gt; arg2, Reporter arg3) throws IOException { // TODO Auto-generated method stub } } 这个里面的涉及到的JS的函数： toString:toString() 方法可把一个逻辑值转换为字符串，并返回结果。 substring:substring() 方法用于提取字符串中介于两个指定下标之间的字符。 语法stringObject.substring(start,stop)返回值一个新的字符串，该字符串值包含 stringObject 的一个子字符串，其内容是从 start 处到 stop-1 处的所有字符，其长度为 stop 减 start。 说明substring() 方法返回的子串包括 start 处的字符，但不包括 stop 处的字符。 如果参数 start 与 stop 相等，那么该方法返回的就是一个空串（即长度为 0 的字符串）。如果 start 比 stop 大，那么该方法在提取子串之前会先交换这两个参数。 chartAt:charAt() 方法可返回指定位置的字符。 请注意，JavaScript 并没有一种有别于字符串类型的字符数据类型，所以返回的字符是长度为 1 的字符串 语法stringObject.charAt(index) 注释：字符串中第一个字符的下标是 0。如果参数 index 不在 0 与 string.length 之间，该方法将返回一个空字符串。 关于Integer 方法摘要 这里使用的函数是：paresInt(String int):将字符串参数作为有符号的十进制整数进行分析。 语法： parseInt(string, radix) parseInt(&quot;10&quot;); //返回 10 parseInt(&quot;19&quot;,10); //返回 19 (10+9) parseInt(&quot;11&quot;,2); //返回 3 (2+1) parseInt(&quot;17&quot;,8); //返回 15 (8+7) parseInt(&quot;1f&quot;,16); //返回 31 (16+15) parseInt(&quot;010&quot;); //未定：返回 10 或 8 matches() 方法用于检测字符串是否匹配给定的正则表达式。 调用此方法的 str.matches(regex) 形式与以下表达式产生的结果完全相同： 在字符串匹配给定的正则表达式时，返回 true。 public class Test { public static void main(String args[]) { String Str = new String(&quot;www.runoob.com&quot;); System.out.print(&quot;返回值 :&quot; ); System.out.println(Str.matches(&quot;(.*)runoob(.*)&quot;)); System.out.print(&quot;返回值 :&quot; ); System.out.println(Str.matches(&quot;(.*)google(.*)&quot;)); System.out.print(&quot;返回值 :&quot; ); System.out.println(Str.matches(&quot;www(.*)&quot;)); } } 以上程序执行结果为： 返回值 :true 返回值 :false 返回值 :true]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop权威指南</tag>
        <tag>MapReduce学习</tag>
        <tag>JS函数学习</tag>
      </tags>
  </entry>
</search>
