<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>无心是一首歌</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://erichunn.github.io/"/>
  <updated>2019-01-16T13:07:41.914Z</updated>
  <id>http://erichunn.github.io/</id>
  
  <author>
    <name>Eric Hunn</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>大数据电商项目（一）</title>
    <link href="http://erichunn.github.io/2019/01/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E5%95%86%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/16/大数据电商项目（一）/</id>
    <published>2019-01-16T13:07:41.000Z</published>
    <updated>2019-01-16T13:07:41.914Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目面试总结</title>
    <link href="http://erichunn.github.io/2019/01/15/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/"/>
    <id>http://erichunn.github.io/2019/01/15/实战大数据电信项目面试总结/</id>
    <published>2019-01-15T14:27:10.000Z</published>
    <updated>2019-01-16T08:10:04.084Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/GR90bE7.png" alt=""></p><p>4.Hadoop以及HBase的HA集群配置与实战。<br>  hadoop的使用QJM的高可用架构配置讲解，ResourceManager的高可用架构配置讲解。<br>  zookeeper的工作原理以及配置、实操演练，hbase与Hadoop HA集成注意事项以及客户端<br>  API编程细节处理。</p><h2 id="hadoop-HDFS-HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾"><a href="#hadoop-HDFS-HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾" class="headerlink" title="hadoop HDFS HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾"></a>hadoop HDFS HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾</h2><p>配置hdfs-site和core-site.xml指定zk地址。</p><pre><code>自动容灾引入两个组件，zk quarum + zk容灾控制器(ZKFC)。运行NN的主机还要运行ZKFC进程，主要负责:a.健康监控b.session管理c.选举</code></pre><h2 id="resourcemanager自动容灾配置"><a href="#resourcemanager自动容灾配置" class="headerlink" title="resourcemanager自动容灾配置"></a>resourcemanager自动容灾配置</h2><p>对yarn-site.xml进行配置配置自动容灾并且将zk地址配制进去。</p><h2 id="部署zk集群"><a href="#部署zk集群" class="headerlink" title="部署zk集群"></a>部署zk集群</h2><p>1、配置zk配置文件</p><p> [/soft/zk/conf/zoo.cfg]<br>    …<br>    dataDir=/home/centos/zookeeper</p><pre><code>server.1=s201:2888:3888server.2=s202:2888:3888 server.3=s203:2888:3888</code></pre><p>2、在每台主机的/home/centos/zookeeper中添加myid,内容分别是1,2,3</p><h2 id="配置HBase和Hbase高可用"><a href="#配置HBase和Hbase高可用" class="headerlink" title="配置HBase和Hbase高可用"></a>配置HBase和Hbase高可用</h2><h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><p>1、安装后配置环境后在修改配置文件[hbase/conf/hbase-env.sh]，添加hbase在hdfs存放路径、zk地址、zk本地目录、使用完全分布式true。</p><p>2、配置regionservers</p><pre><code>[hbase/conf/regionservers]s202s203s204</code></pre><h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>直接在2台机器上执行命令：</p><p>hbase-daemon.sh start master</p><h2 id="配置Kafka集群"><a href="#配置Kafka集群" class="headerlink" title="配置Kafka集群"></a>配置Kafka集群</h2><p>1、配置kafka<br>    [kafka/config/server.properties]<br>    …<br>    broker.id=202<br>    …<br>    listeners=PLAINTEXT://:9092<br>    …<br>    log.dirs=/home/centos/kafka/logs<br>    …<br>    zookeeper.connect=s201:2181,s202:2181,s203:2181</p><p>2、分发server.properties，同时修改每个文件的broker.id</p><h2 id="配置Flume"><a href="#配置Flume" class="headerlink" title="配置Flume"></a>配置Flume</h2><p>配置flume将其配置文件修改为source为某个文件夹，然后sink为kafka集群</p><hr><h2 id="创建hbase名字空间-表"><a href="#创建hbase名字空间-表" class="headerlink" title="创建hbase名字空间+表"></a>创建hbase名字空间+表</h2><pre><code>1.创建名字空间和表。表是：名字空间+列族。    $&gt;hbase shell                        //进入hbase shell    $hbase&gt;create_namespace &apos;ns1&apos;        //创建空间    $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;    //创建表    $hbase&gt;truncate &apos;ns1:calllogs&apos;        //重建表</code></pre><h2 id="创建kafka消费者，订阅calllog主题"><a href="#创建kafka消费者，订阅calllog主题" class="headerlink" title="创建kafka消费者，订阅calllog主题"></a>创建kafka消费者，订阅calllog主题</h2><pre><code>1.设计rowkey    业务数据: caller , callee , date , duration    分区号    号码     时间,标记  (对方号码),时长    regionNo, caller,date , flag,callee,duration    caller(11) + 通话时间(201701) =     (后四位) + 201701 = % 100</code></pre><p>对日志信息进行整理，删除多余的部分如/:之类的<br>解析日志数据将日志数据截取串，实例化put对象，插入Hbase中去。</p><p>打成jar包放到classpath之中，将kafka消费者打成Jar包，并且，用maven在windows将其的依赖都下载下来放到classpath当中。</p><p>将这个文件夹都放置到Linux下，然后写一个执行这个jar包的脚本：</p><pre><code>java -cp CallLogConsumerModule.jar;./lib/activation-1.1.jar;./lib/apacheds-i18n-2.0.0-M15.jar;./lib/apacheds-kerberos-codec-2.0.0-M15.jar;./lib/api-asn1-api-1.0.0-M20.jar;./lib/api-util-1.0.0-M20.jar;./lib/avro-1.7.4.jar;./lib/commons-beanutils-1.7.0.jar;./lib/commons-beanutils-core-1.8.0.jar;./lib/commons-cli-1.2.jar;./lib/commons-codec-1.9.jar;./lib/commons-collections-3.2.2.jar;./lib/commons-compress-1.4.1.jar;./lib/commons-configuration-1.6.jar;./lib/commons-digester-1.8.jar;./lib/commons-el-1.0.jar;./lib/commons-httpclient-3.1.jar;./lib/commons-io-2.4.jar;./lib/commons-lang-2.6.jar;./lib/commons-logging-1.2.jar;./lib/commons-math3-3.1.1.jar;./lib/commons-net-3.1.jar;./lib/findbugs-annotations-1.3.9-1.jar;./lib/guava-12.0.1.jar;./lib/hadoop-annotations-2.5.1.jar;./lib/hadoop-auth-2.5.1.jar;./lib/hadoop-common-2.5.1.jar;./lib/hadoop-mapreduce-client-core-2.5.1.jar;./lib/hadoop-yarn-api-2.5.1.jar;./lib/hadoop-yarn-common-2.5.1.jar;./lib/hamcrest-core-1.3.jar;./lib/hbase-annotations-1.2.4.jar;./lib/hbase-client-1.2.4.jar;./lib/hbase-common-1.2.4.jar;./lib/hbase-protocol-1.2.4.jar;./lib/htrace-core-3.1.0-incubating.jar;./lib/httpclient-4.2.5.jar;./lib/httpcore-4.2.4.jar;./lib/jackson-core-asl-1.9.13.jar;./lib/jackson-mapper-asl-1.9.13.jar;./lib/jaxb-api-2.2.2.jar;./lib/jcodings-1.0.8.jar;./lib/jdk.tools-1.6.jar;./lib/jetty-util-6.1.26.jar;./lib/jline-0.9.94.jar;./lib/joni-2.1.2.jar;./lib/jopt-simple-4.9.jar;./lib/jsch-0.1.42.jar;./lib/jsr305-1.3.9.jar;./lib/junit-4.12.jar;./lib/kafka-clients-0.10.0.1.jar;./lib/kafka_2.11-0.10.0.1.jar;./lib/log4j-1.2.15.jar;./lib/lz4-1.3.0.jar;./lib/mail-1.4.jar;./lib/metrics-core-2.2.0.jar;./lib/netty-3.7.0.Final.jar;./lib/netty-all-4.0.23.Final.jar;./lib/paranamer-2.3.jar;./lib/protobuf-java-2.5.0.jar;./lib/scala-library-2.11.8.jar;./lib/scala-parser-combinators_2.11-1.0.4.jar;./lib/slf4j-api-1.6.1.jar;./lib/slf4j-log4j12-1.7.21.jar;./lib/snappy-java-1.1.2.6.jar;./lib/stax-api-1.0-2.jar;./lib/xmlenc-0.52.jar;./lib/xz-1.0.jar;./lib/zkclient-0.8.jar;./lib/zookeeper-3.4.6.jar com.it18zhang.calllog.consumer.HbaseConsumer</code></pre><p>执行kafak消费者</p><h2 id="业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）"><a href="#业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）" class="headerlink" title="业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）"></a>业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）</h2><p>通过在service中建立和hbase的连接，通过使用scan对象，将查询的内容填充到实体类中，将实体类添加到list当中去，然后返回list，在controller层调用service层的findall方法。返回给前段，前段通过jsp界面，将返回的数据填充到表格中去。</p><h2 id="业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫-利用hbase查询"><a href="#业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫-利用hbase查询" class="headerlink" title="业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫(利用hbase查询)"></a>业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫(利用hbase查询)</h2><p>这块就有点内容了，首先hbase的rowkey的实际根据实际的业务需要把rowkey设置成reginonumber,callerid calltime(精确到分) flag calleeid duration.为什么设置成这样根据rowkey的设计原则，吧尽可能多的内容设计到rowkey里面，可以直接查询的到。最常用的放到前面，可以通过callerid和time直接查询的到。设计成不同的regionnumber将不同的号码进行类似于分桶可以切割放到不同的服务器里面。</p><p>在查询rowkey的时候考虑到根据时间段查询的时候，由于rowkey的设计是哈希号，主叫，时间，被叫，所以哈希号是个根据主叫+时间（年月）来设计的，这块根据主叫+年月的设计是因为要是淡出根据手机号来哈希的话大多数都是138值类的会造成热点问题。所以根据时间+手机号来设计，然后搜易在根据时间来查找的时候，要考虑起止时间是否是同年月，不同年月，如果是同年月的话就是说在同一个哈希号之间，开始时间就是开始时间，结束时间是day+1，前包后不包，如果是不同年月的话就在不同的区号之间，比如是2017.3.11-2017.5.9就要搜索2017.3.11-2017.4,2017.4-2017.5,2017.5-2017,5,9</p><p>要取到callerid+年月作为hash的值而不能取到时，分作为哈希的值，因为取到时，分的话就每个都是不一样的哈希的值，查询的时候就要根据时分来查询而不能根据年月来查询。因为每次查询的时候要指定callerid和年月。如果是根据callerid+时分来计算的话，每次存储的时候即便是同一天同一个月也不会分散的同一个哈希区域，而是分散到不同的区域，难以查询到，如果是这样只能通过每一分钟每一分钟的查询，没法查询了。</p><p>由于在输入数据的时候只是插入主叫的数据，在查询通话详单的时候要查询该号码即是主叫，又是被叫的情况下，在rowkey是rno,callerid,calltime,calleeid,calleeid,duration的情况下要查询位置在后面的calleeid的情况下，几乎要全表扫描。所以这块我们在每次put进来数据的时候我们使用协处理器，每次添加主叫的时候，在添加一个被叫。这个被叫的Rowkey是哈希+被叫+时间+1+主叫+时长。然后在put这个被叫的时候区域号也就是rno还是根据主叫+时间片来哈希的。就可以让被叫信息和主叫信息在同一个哈希区域内，然后插入flag=1的rowkey，然后他的value值就是原来主叫表的rowkey的各个值。这样的话避免了将之前主叫表的冗余的value在重复插入一遍。也就是一个二级索引的思想，在协处理器里面重写Postput方法和postScannerNext()方法，postput方法的作用就是在插入一条主叫记录的同时，在插入一条被叫记录，而postgetOp()方法的作用是查询被叫返回主叫信息。在查询的时候用的是scan的API然后查询value值，所以在查询被叫的时候让他返回主叫信息，（这边视频中这边考虑的是如果得到rowkey还需要解析，就算了这样说的），</p><h2 id="业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）"><a href="#业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）" class="headerlink" title="业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）"></a>业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）</h2><p>业务场景是吧人员信息放到一个简单的关系型数据库中，也就是人员信息在公安部的信息中，然后实现一个和关系型数据库的交互查询    。</p><h2 id="查询电话号码最近通话记录"><a href="#查询电话号码最近通话记录" class="headerlink" title="查询电话号码最近通话记录"></a>查询电话号码最近通话记录</h2><p>通过完成hive到hbase表的映射，实现对最近通话信息的查询，<br>从现有手段hbase查询，首先rowkey没法确定。rowkey是手机号+年份+月份。因为每个月份的哈希code都不一样，所以只能一个月一个月查。很麻烦。但是我们可以通过hive里面的max()聚集函数查询，借助于mr，也就是用Hive查询。通过hive操纵hbase里面的表，创建一个外部表映射到hbase上去通过Hive的聚集函数通过max min count等聚集函数来查询。</p><p><img src="https://i.imgur.com/FFumqvN.png" alt=""></p><p>由于hive操作是通过hive和beeline来操作。hive客户端只能本地使用并且不能并发，所以使用hiveserver2服务通过beeline.sh这个脚本，㑨10000，走的是thrift服务器。而ssm是通过ssm里面的service通过jdbc和hiveserver2交互，hiveserver2找到hive外部表并且操作这个是走的jdbc可以实现远程访问。</p><p>那么怎样在hive里面查询最近通话详单呢：（最近一条记录）<br>$hive&gt;select * from ext_calllogs_in_hbase where id like ‘%xxxx%’ order by callTime desc limit 1 ;</p><p><img src="https://i.imgur.com/7N6lXVy.png" alt=""></p><h2 id="业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）"><a href="#业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）" class="headerlink" title="业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）"></a>业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）</h2><p>hive中查询某个人一年的通话记录按月份进行分组：</p><p>select count(*) , substr(calltime,1,6) from ext_calllogs_in_hbase where caller = ‘15032293356’ and substr(calltime,1,4) == ‘2017’ group by substr(calltime,1,6) ;</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/GR90bE7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.Hadoop以及HBase的HA集群配置与实战。&lt;br&gt;  hadoop的使用QJM的高可用架构配置讲解，ResourceManager的高可用架构配置讲
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（四）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E5%9B%9B%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（四）/</id>
    <published>2019-01-11T07:56:51.000Z</published>
    <updated>2019-01-15T12:30:08.565Z</updated>
    
    <content type="html"><![CDATA[<p>hive统计某个人的通话次数：<br>数据在kafka最多是7天时间。<br>hive中查询某个人一年的通话记录按月份进行分组：<br>select count(*) , substr(calltime,1,6) from ext_calllogs_in_hbase where caller = ‘15032293356’ and substr(calltime,1,4) == ‘2017’ group by substr(calltime,1,6) ;</p><p>要写hiveservice，在里面添加</p><pre><code>1.HiveCallLogService.java        /**         * 查询指定人员指定年份中各个月份的通话次数         */        public List&lt;CallLogStat&gt; statCallLogsCount(String caller, String year){            List&lt;CallLogStat&gt; list = new ArrayList&lt;CallLogStat&gt;() ;            try {                Connection conn = DriverManager.getConnection(url);                Statement st = conn.createStatement();                String sql = &quot;select count(*) ,substr(calltime,1,6) from ext_calllogs_in_hbase &quot; +                        &quot;where caller = &apos;&quot; + caller+&quot;&apos; and substr(calltime,1,4) == &apos;&quot; + year                        + &quot;&apos; group by substr(calltime,1,6);&quot;;                ResultSet rs = st.executeQuery(sql);                CallLog log = null;                while (rs.next()) {                    CallLogStat logSt = new CallLogStat();                    logSt.setCount(rs.getInt(1));                    logSt.setYearMonth(rs.getString(2));                    list.add(logSt);                }                rs.close();                return list;            } catch (Exception e) {                e.printStackTrace();            }            return null;        }</code></pre><p>2.CallLogController.java</p><pre><code>    /**     * 统计指定人员，指定月份的通话次数     */    @RequestMapping(&quot;/callLog/toStatCallLog&quot;)    public String toStatCallLog(){        return &quot;callLog/statCallLog&quot; ;    }    /**     * 统计指定人员，指定月份的通话次数     */    @RequestMapping(&quot;/callLog/statCallLog&quot;)    public String statCallLog(Model m ,@RequestParam(&quot;caller&quot;) String caller ,@RequestParam(&quot;year&quot;) String year){        List&lt;CallLogStat&gt; list = hcs.statCallLogsCount(caller, year);        m.addAttribute(&quot;stat&quot; , list) ;        return &quot;callLog/statCallLog&quot; ;    }3.statCallLog.jsp    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;通话记录统计结果&lt;/title&gt;        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;        &lt;script type=&quot;text/javascript&quot; src=&quot;../js/jquery-3.2.0.min.js&quot;&gt;&lt;/script&gt;        &lt;script type=&quot;text/javascript&quot;&gt;            //定义函数            function refreshTable(){                $(&quot;#t1 tbody&quot;).empty();                $.getJSON(&quot;/callLog/json/findAll&quot;, function (data) {                    $.each(data, function (i, obj) {                        var str = &quot;&lt;tr&gt;&lt;td&gt;&quot; + obj.caller + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callerName + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callee + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.calleeName + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callTime + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callDuration + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;/tr&gt;&quot;;                        $(&quot;#t1 tbody&quot;).append(str);                    });                });            }            $(function(){                setInterval(refreshTable, 2000);            })        &lt;/script&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;form action=&apos;&lt;c:url value=&quot;/callLog/statCallLog&quot; /&gt;&apos; method=&quot;post&quot;&gt;            电话号码 : &lt;input type=&quot;text&quot; name=&quot;caller&quot;&gt;&lt;br&gt;            年 份:  &lt;input type=&quot;text&quot; name=&quot;year&quot;&gt;&lt;br&gt;            &lt;input type=&quot;submit&quot; name=&quot;查询&quot;&gt;        &lt;/form&gt;        &lt;br&gt;        &lt;table id=&quot;t1&quot; border=&quot;1px&quot; class=&quot;t-1&quot; style=&quot;width: 800px&quot;&gt;            &lt;thead&gt;                &lt;tr&gt;                    &lt;td&gt;月份&lt;/td&gt;                    &lt;td&gt;次数&lt;/td&gt;                &lt;/tr&gt;            &lt;/thead&gt;            &lt;tbody&gt;                &lt;c:forEach items=&quot;${stat}&quot; var=&quot;s&quot;&gt;                    &lt;tr&gt;                        &lt;td&gt;&lt;c:out value=&quot;${s.yearMonth}&quot;/&gt;&lt;/td&gt;                        &lt;td&gt;&lt;c:out value=&quot;${s.count}&quot;/&gt;&lt;/td&gt;                    &lt;/tr&gt;                &lt;/c:forEach&gt;            &lt;/tbody&gt;        &lt;/table&gt;    &lt;/body&gt;    &lt;/html&gt;</code></pre><h2 id="做了一个xcall-sh和xkill脚本"><a href="#做了一个xcall-sh和xkill脚本" class="headerlink" title="做了一个xcall.sh和xkill脚本"></a>做了一个xcall.sh和xkill脚本</h2><p>[xkill.sh]</p><pre><code>#!/bin/bashpids=`jps | grep $1 | awk &apos;{print $1}&apos;`for pid in $pids ; do    kill -9 $piddone</code></pre><p>[xcall.sh]</p><pre><code>#!/bin/bashparams=$@i=201for (( i=201 ; i &lt;= 206 ; i = $i + 1 )) ; do    tput setaf 2    echo ============= s$i =============    tput setaf 7    ssh -4 s$i &quot;source /etc/profile ; $params&quot;done</code></pre><p>//开启kafka集群<br>[/usr/local/bin/xkafka-cluster-start.sh]</p><pre><code>#!/bin/bashservsers=&quot;s202 s203 s204&quot;for s in $servers ; do    ssh $s &quot;source /etc/profile ; kafka-server-start.sh -daemon /soft/kakfa/config/server.properties&quot;done</code></pre><p>//启动zk集群<br>[/usr/local/bin/xzk-cluster-start.sh]</p><pre><code>#!/bin/bashservers=&quot;s201 s202 s203&quot;for s in $servers ; do    ssh $s &quot;source /etc/profile ; zkServer.sh start&quot;done</code></pre><p>//xconsumer-start.sh<br>[/usr/local/bin/xconsumer-start.sh]</p><pre><code>#!/bin/bashcd /home/centos/KafkaHbaseConsumerrun.sh &amp;</code></pre><p>//s201:xflume-calllog-start.sh<br>[/usr/local/bin/xconsumer-start.sh]</p><pre><code>#!/bin/bashcd /soft/flume/confflume-ng agent -f calllog.conf -n a1 &amp;</code></pre><hr><p>查询所有用户的各个月份的通话次数     </p><p>使用echart实现数据可视化</p><p>业务场景：根据电话号码，年份实现每个月的电话次数以echar可视化的图标展示<br>通过在service连接hive服务器，执行Hivesql查询查询到的内容，通过controller层调用返回的内容传到前台。前台jsp界面继承echart和c标签库展示后台查询的内容</p><p>在集群中安装ganglia监控集群CPU内存进程监控fulme kafka gendata数据生成进程    </p><h2 id="ganglia"><a href="#ganglia" class="headerlink" title="ganglia"></a>ganglia</h2><pre><code>集群监控.不仅能够监控单个主机的资源情况，还可以对集群整个资源进行统计。gmond            //在每个节点收集资源数据的。gmetad            //接受每个节点发送资源数据gweb            //webui,展示数据web程序，和gmetad通信。</code></pre><h2 id="安装ganglia"><a href="#安装ganglia" class="headerlink" title="安装ganglia"></a>安装ganglia</h2><pre><code>1.ganglia-gmond    所有节点。    $&gt;sudo yum install -y ganglia-gmond2.ganglia-gmetad    s201    $&gt;sudo yum install -y ganglia-gmetad3.ganglia-gweb    [s201]    a)安装依赖        $&gt;sudo yum install -y httpd php    b)下载ganglia-web-3.5.12.tar.gz程序        wget http://ncu.dl.sourceforge.net/project/ganglia/ganglia-web/3.5.12/ganglia-web-3.5.12.tar.gz    c)tar开文件    d)修改Makefile文件，执行编译命令sudo make install        ...    e)启动服务        [s201]        $&gt;sudo service httpd start         $&gt;sudo service gmetad start         $&gt;sudo service gmond start         [s202]        $&gt;sudo service gmond start </code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;hive统计某个人的通话次数：&lt;br&gt;数据在kafka最多是7天时间。&lt;br&gt;hive中查询某个人一年的通话记录按月份进行分组：&lt;br&gt;select count(*) , substr(calltime,1,6) from ext_calllogs_in_hbase whe
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（三）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%89%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（三）/</id>
    <published>2019-01-11T07:56:40.000Z</published>
    <updated>2019-01-16T07:53:04.472Z</updated>
    
    <content type="html"><![CDATA[<p>前段请求和hive交互，在hive之中创建外部表，映射到Hbase当中<br>一般hive在远端通过jdbc方式来交互，要想走jdbc协议hive还需要打开hiveserver2，其实就是启动thrift服务器，端口是10000.而ssm是在controller里面，交互service在SSM里面得有一个service。service通过jdbc协议和hive server2交互，转换hive语句，在通过hbase交互。</p><p>为什么要用到Hive映射到hbase表：</p><h2 id="要想查询用户最近通话信息-，"><a href="#要想查询用户最近通话信息-，" class="headerlink" title="要想查询用户最近通话信息 ##，"></a>要想查询用户最近通话信息 ##，</h2><p>从现有手段hbase查询，首先rowkey没法确定。rowkey是手机号+年份+月份。因为每个月份的哈希code都不一样，所以只能一个月一个月查。很麻烦。但是我们可以通过hive里面的max()聚集函数查询，借助于mr，也就是用Hive查询。通过hive操纵hbase里面的表，创建一个外部表映射到hbase上去通过Hive的聚集函数通过max min count等聚集函数来查询。</p><p><img src="https://i.imgur.com/FFumqvN.png" alt=""></p><p>由于hive操作是通过hive和beeline来操作。hive客户端只能本地使用并且不能并发，所以使用hiveserver2服务通过beeline.sh这个脚本，㑨10000，走的是thrift服务器。而ssm是通过ssm里面的service通过jdbc和hiveserver2交互，hiveserver2找到hive外部表并且操作这个是走的jdbc可以实现远程访问。</p><p>那么怎样在hive里面查询最近通话详单呢：（最近一条记录）<br>$hive&gt;select * from ext_calllogs_in_hbase where id like ‘%xxxx%’ order by callTime desc limit 1 ;</p><p><img src="https://i.imgur.com/7N6lXVy.png" alt=""></p><p>1.SSm中创建service做一个hive的聚集表的查询，查询最近的通话记录进行Mr查询。加一个pom的hive驱动<br>    @Service(“hiveCallLogService”)<br>    public class HiveCallLogService {</p><pre><code>    //hiveserver2连接串    private static String url = &quot;jdbc:hive2://s201:10000/&quot; ;    //驱动程序类    private static String driverClass = &quot;org.apache.hive.jdbc.HiveDriver&quot; ;    static{        try {            Class.forName(driverClass);        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 查询最近的通话记录,使用hive进行mr查询.     */    public CallLog findLatestCallLog(String phoneNum){        try {            Connection conn = DriverManager.getConnection(url);            Statement st = conn.createStatement();            String sql = &quot;select * from ext_calllogs_in_hbase where id like &apos;%&quot;+ phoneNum+&quot;%&apos; order by callTime desc limit 1&quot; ;            ResultSet rs = st.executeQuery(sql);            CallLog log = null ;            if(rs.next()){                log = new CallLog();                log.setCaller(rs.getString(&quot;caller&quot;));                log.setCallee(rs.getString(&quot;caller&quot;));                log.setCallTime(rs.getString(&quot;callTime&quot;));                log.setCallDuration(rs.getString(&quot;callDuration&quot;));            }            rs.close();            return log ;        } catch (Exception e) {             e.printStackTrace();        }        return null ;    }}</code></pre><p>在controller层添加内容：</p><pre><code>/**     * 查询最近通话记录     */    @RequestMapping(value = &quot;/callLog/findLatestCallLog&quot;,method = RequestMethod.POST)    public String findLatestCallLog(Model m , @RequestParam(&quot;caller&quot;) String caller){        CallLog log = hcs.findLatestCallLog(caller);        if(log != null){            m.addAttribute(&quot;log&quot;, log);        }        return &quot;callLog/latestCallLog&quot; ;    }    /**     * 查询最近通话记录     */    @RequestMapping(value = &quot;/callLog/toFindLatestCallLog&quot;)    public String toFindLatestCallLog(){        return &quot;callLog/findLatestCallLog&quot; ;    }}</code></pre><p>jsp界面编写：</p><pre><code>&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;通话记录&lt;/title&gt;    &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;&lt;/head&gt;&lt;body&gt;    &lt;c:if test=&quot;${log == null}&quot;&gt;        无记录！    &lt;/c:if&gt;    &lt;c:if test=&quot;${log != null}&quot;&gt;        &lt;table id=&quot;t1&quot; border=&quot;1px&quot; class=&quot;t-1&quot; style=&quot;width: 800px&quot;&gt;            &lt;tr&gt;                &lt;td&gt;电话1&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.caller}&quot; /&gt;&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;电话2&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.callee}&quot;/&gt;&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;时间&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.callTime}&quot;/&gt;&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;时长&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.callDuration}&quot;/&gt;&lt;/td&gt;            &lt;/tr&gt;        &lt;/table&gt;    &lt;/c:if&gt;&lt;/body&gt;&lt;/html&gt;    </code></pre><p>在中间有一个报错问题：<br><img src="https://i.imgur.com/qyHtkg0.png" alt=""><br><img src="https://i.imgur.com/V9gqUmv.png" alt=""><br><img src="https://i.imgur.com/QCKt99s.png" alt=""><br>解决办法是更新继承的tomcat倒9。0版本。然后hive的依赖百年城1.2.1</p><h2 id="然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容"><a href="#然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容" class="headerlink" title="然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容"></a>然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容</h2><p>业务场景是吧人员信息放到一个简单的关系型数据库中，也就是人员信息在公安部的信息中，然后实现一个和关系型数据库的交互查询    </p><pre><code>1.建表create table persons(id ...) ;2.domainpublic class Person {    private Integer id ;    private String name ;    private String phone  ;    ...}3.dao4.service5.</code></pre><p>//在查询之中集成MYSQL的查询到的内容，整理一下下就是写mapper的SQL语句，在DAO层getSqlSession().selectOne(“persons.selectNameByPhone”,phone)通过这句话来返回，然后service层调用这个方法，然后在到personserviceimpl中调用这个方法，然后在calllogseriviceimpl中调用这个方法返回内容填充到实体类里面，controller层调用这些方法然后在jsp文件里面进行一个内容的填充。<br>——————</p><h2 id="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制"><a href="#MR运行参数配置，关闭物理内存和虚拟内存对容器的限制" class="headerlink" title="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制"></a>MR运行参数配置，关闭物理内存和虚拟内存对容器的限制</h2><pre><code>默认限制是开启的，最多分配给容器8G的物理内存，虚拟内存是物理内存的2.1倍。[yarn-site.xml]&lt;property&gt;    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;    &lt;value&gt;8192&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;    &lt;value&gt;2.1&lt;/value&gt;&lt;/property&gt;</code></pre><hr><p>0310然后实现一个生成带名字的数据源的代码。然后要做一个局部刷新的fastjson。<br>0311实现一个通过服务器返回给客户端json格式的内容，通过集成jQuery实现ajax访问，动态刷新通话记录。</p><p>启动顺序，先启动kafka，启动kafka消费者，启动flume，启动ssm，启动日志生成程序。.<br>flume-ng agent -f calllog.conf -n a1在s201中<br>kafka-server-start.sh -daemon /soft/kafka/config/server.properties启动3个<br>启动kafka消费者：kafka-console-consumer.sh –zookeeper s202:2181 –topic calllog<br>开启hadoop集群和hbase集群</p><p>真机使用：<br>10个kafka3台zk我们是1，2，3是zk。3台zk里面分配好myid。配置好zoo.cfg里面配置好3台主机的Ip地址<br>kafka配置配置kafka/config/server.properties 。kafka依赖于zk在kafka的配置文件里面配置zk的ip<br>单独安装flume配置配置文件。配置source channel sink<br>一边生成日志一边搜集。</p><hr><h2 id="协处理器-批处理。"><a href="#协处理器-批处理。" class="headerlink" title="协处理器:批处理。"></a>协处理器:批处理。</h2><pre><code>1.类似于触发器。    完成被叫日志的写入过程。2.重写postPut()/postGetOp()/postScannNext();    put / get / scann    直接返回主叫。</code></pre><h2 id="按时间段查询通话记录"><a href="#按时间段查询通话记录" class="headerlink" title="按时间段查询通话记录"></a>按时间段查询通话记录</h2><pre><code>hashcode            //确定分区。100</code></pre><h2 id="用户最近的通话信息"><a href="#用户最近的通话信息" class="headerlink" title="用户最近的通话信息"></a>用户最近的通话信息</h2><pre><code>hbase:rowkeymax()聚集函数。</code></pre><h2 id="mr-hive"><a href="#mr-hive" class="headerlink" title="mr:hive"></a>mr:hive</h2><pre><code>MapReduce.</code></pre><h2 id="用户最近的通话信息-1"><a href="#用户最近的通话信息-1" class="headerlink" title="用户最近的通话信息"></a>用户最近的通话信息</h2><pre><code>1.启动hadoop的yarn集群    [s201]    $&gt;start-yarn.sh    [s206]    $&gt;yarn-daemon.sh start resourcemanager    [验证]    http://s201:8088/2.初始化hive    $&gt;cd /soft/hive/bin    $&gt;./schemaTool -dbType mysql -initSchema    $&gt;hive            //进入hive的shell    $hive&gt;create database mydb ;    $hive&gt;use mydb ;    $hive&gt;create external table ext_calllogs_in_hbase(id string, caller string,callTime string,callee string,callDuration string) STORED BY &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,f1:caller,f1:callTime,f1:callee,f1:callDuration&quot;) TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;ns1:calllogs&quot;);    $hive&gt;select * from ext_calllogs_in_hbase where id like &apos;%xxxx%&apos; order by callTime desc limit 1 ;    $hive&gt;select * from ext_calllogs_in_hbase where callTime = (select max(tt.callTime) from ext_calllogs_in_hbase tt where tt.id like &apos;%xxx%&apos;);3.ssm中创建service，查询hive表中数据。    a.增加依赖        [pom.xml]        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;            &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;            &lt;version&gt;1.2.1&lt;/version&gt;        &lt;/dependency&gt;    b.编写类        package com.it18zhang.ssm.hive;        import com.it18zhang.ssm.domain.CallLog;        import java.sql.Connection;        import java.sql.DriverManager;        /**         * Created by Administrator on 2017/4/14.         */        public class HiveCallLogService {            //hiveserver2连接串            private static String url = &quot;jdbc:hive2://s201:10000/mydb&quot; ;            //驱动程序类            private static String driverClass = &quot;org.apache.hive.jdbc.HiveDriver&quot; ;            static{                try {                    Class.forName(driverClass);                } catch (Exception e) {                    e.printStackTrace();                }            }            /**             * 查询最近的通话记录,使用hive进行mr查询.             */            public CallLog findLatestCallLog(){                try {                    Connection conn = DriverManager.getConnection(url);                    System.out.println(conn);                } catch (Exception e) {                    e.printStackTrace();                }                return null ;            }        }    c.启动hiveserver2服务器        $&gt;hive/bin/hiveserver2 &amp;    d.验证hiveserver2端口        $&gt;netstat -anop | grep 100004.测试类    package com.it18zhang.ssm.hive;    import com.it18zhang.ssm.domain.CallLog;    import org.apache.hadoop.hbase.client.Result;    import java.sql.Connection;    import java.sql.DriverManager;    import java.sql.ResultSet;    import java.sql.Statement;    /**     *     */    public class HiveCallLogService {        //hiveserver2连接串        private static String url = &quot;jdbc:hive2://s201:10000/&quot; ;        //驱动程序类        private static String driverClass = &quot;org.apache.hive.jdbc.HiveDriver&quot; ;        static{            try {                Class.forName(driverClass);            } catch (Exception e) {                e.printStackTrace();            }        }        /**         * 查询最近的通话记录,使用hive进行mr查询.         */        public CallLog findLatestCallLog(){            try {                Connection conn = DriverManager.getConnection(url);                Statement st = conn.createStatement();                ResultSet rs = st.executeQuery(&quot;select * from ext_calllogs_in_hbase&quot;);                while(rs.next()){                    String id = rs.getString(&quot;id&quot;);                    String caller = rs.getString(&quot;caller&quot;);                    String callee = rs.getString(&quot;callee&quot;);                    String callTime = rs.getString(&quot;callTime&quot;);                    String callDuration = rs.getString(&quot;callDuration&quot;);                    System.out.println(id + &quot; :  &quot; + caller);                }                rs.close();                System.out.println(conn);            } catch (Exception e) {                e.printStackTrace();            }            return null ;        }    }5.注意事项    SSM集成hive-jdbc访问hive的hiveserver2时，需要如下处理:    5.1)使用hive-jdbc-1.2.1的依赖版本        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;            &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;            &lt;version&gt;1.2.1&lt;/version&gt;        &lt;/dependency&gt;    5.5)需要集成apache-tomcat-9.0.0.M19版本，否则报编译器错误。</code></pre><h2 id="添加人员信息"><a href="#添加人员信息" class="headerlink" title="添加人员信息"></a>添加人员信息</h2><pre><code>1.建表create table persons(id ...) ;2.domainpublic class Person {    private Integer id ;    private String name ;    private String phone  ;    ...}3.dao4.service5.</code></pre><h2 id="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制-1"><a href="#MR运行参数配置，关闭物理内存和虚拟内存对容器的限制-1" class="headerlink" title="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制"></a>MR运行参数配置，关闭物理内存和虚拟内存对容器的限制</h2><pre><code>默认限制是开启的，最多分配给容器8G的物理内存，虚拟内存是物理内存的2.1倍。[yarn-site.xml]&lt;property&gt;    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;    &lt;value&gt;8192&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;    &lt;value&gt;2.1&lt;/value&gt;&lt;/property&gt;</code></pre><h2 id="实现局部实时刷新通话记录的功能"><a href="#实现局部实时刷新通话记录的功能" class="headerlink" title="实现局部实时刷新通话记录的功能"></a>实现局部实时刷新通话记录的功能</h2><pre><code>1.引入pom.xml    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;        &lt;version&gt;1.2.24&lt;/version&gt;    &lt;/dependency&gt;2.编写Controller，增加方法    @RequestMapping(&quot;/callLog/json/findAll&quot;)    public String findAllJson(HttpServletResponse response) {        List&lt;CallLog&gt; list = cs.findAll();        String json = JSON.toJSONString(list);        //内容类型        response.setContentType(&quot;application/json&quot;);        try {            OutputStream out = response.getOutputStream();            out.write(json.getBytes());            out.flush();            out.close();        } catch (IOException e) {            e.printStackTrace();        }        return  null;    }</code></pre><p>1.启动顺序<br>    a)1.zookeeper<br>    b)2.hadoop<br>    c)3.hbase<br>    d)4.kakfa<br>    e)5.HbaseConsumer<br>    f)6.flume<br>    g)7.web程序<br>    h)8.数据生成程序.<br>2.<br>3.<br>4.<br>5.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前段请求和hive交互，在hive之中创建外部表，映射到Hbase当中&lt;br&gt;一般hive在远端通过jdbc方式来交互，要想走jdbc协议hive还需要打开hiveserver2，其实就是启动thrift服务器，端口是10000.而ssm是在controller里面，交互s
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（二）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（二）/</id>
    <published>2019-01-11T07:56:27.000Z</published>
    <updated>2019-01-14T03:07:13.834Z</updated>
    
    <content type="html"><![CDATA[<p>按照时间段查询通话记录：</p><p>1.按照时间段查询通话记录，设置startRow+endRow。<br>2.web部分设置一个电话号码输入起始时间输入结束时间输入，然后在SSMweb层controller设置一个查询使用hbaseapi。重点在月份值取出来哈希构造rowkey。</p><p>设置一个表单的查询的jsp界面，action是动态嵌套打印的用url标识库，提交给/callLog/finCallLog通过Post方式，返回输入值起始时间和结束时间到controller层接受参数，</p><p>传值到controller层之后，controller层拿到了参数，拿到starttime callerid endtie。</p><p>对起始日期和结束日期进行一个calendar.getinstance()，日历这个可以计算天数月份数，有多少东西都可以算出来。</p><p>编程：在得到的起始时间和结束时间对2个时间点做操作：得到一个结束的endpoint=开始的前6个数字是年和月+最后2个数字是天+1。</p><p>如果是同年月，起始点就是起始串，结束点是天+1的endpoint。<br>    public static List<calllogrange> getCallLogRanges(String startStr ,String endStr){<br>            try{<br>                SimpleDateFormat sdfYMD = new SimpleDateFormat(“yyyyMMdd”);<br>                SimpleDateFormat sdfYM = new SimpleDateFormat(“yyyyMM”);<br>                DecimalFormat df00 = new DecimalFormat(“00”);</calllogrange></p><pre><code>            //            List&lt;CallLogRange&gt; list = new ArrayList&lt;CallLogRange&gt;();            //字符串时间            String startPrefix = startStr.substring(0, 6);            String endPrefix = endStr.substring(0, 6);            int endDay = Integer.parseInt(endStr.substring(6, 8));            //结束点            String endPoint = endPrefix + df00.format(endDay + 1);            //日历对象            Calendar c = Calendar.getInstance();            //同年月            if (startPrefix.equals(endPrefix)) {                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);          //设置起始点                range.setEndPoint(endPoint);            //设置结束点                list.add(range);            } else {                //1.起始月                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);                //设置日历的时间对象                c.setTime(sdfYMD.parse(startStr));                c.add(Calendar.MONTH, 1);                range.setEndPoint(sdfYM.format(c.getTime()));                list.add(range);                //是否是最后一月                while (true) {                    //到了结束月份                    if (endStr.startsWith(sdfYM.format(c.getTime()))) {                        range = new CallLogRange();                        range.setStartPoint(sdfYM.format(c.getTime()));                        range.setEndPoint(endPoint);                        list.add(range);                        break;                    } else {                        range = new CallLogRange();                        //起始时间                        range.setStartPoint(sdfYM.format(c.getTime()));                        //增加月份                        c.add(Calendar.MONTH, 1);                        range.setEndPoint(sdfYM.format(c.getTime()));                        list.add(range);                    }                }            }            return list ;        }        catch(Exception e){            e.printStackTrace();        }        return null ;    }    /**     * 对时间进行格式化     */    public static String formatDate(String timeStr){        try {            return sdfFriend.format(sdf.parse(timeStr));        } catch (Exception e) {            e.printStackTrace();        }        return null ;    }}</code></pre><p>上图是工具类时间的代码。</p><p>下面代码是service层的具体实现内容：<br>    /**</p><pre><code>     * 按照范围查询通话记录     */    public List&lt;CallLog&gt; findCallogs(String call , List&lt;CallLogRange&gt; ranges){        List&lt;CallLog&gt; logs = new ArrayList&lt;CallLog&gt;();        try {            for(CallLogRange range : ranges){                Scan scan = new Scan();                //设置扫描起始行                scan.setStartRow(Bytes.toBytes(CallLogUtil.getStartRowkey(call, range.getStartPoint(),100)));                //设置扫描结束行                scan.setStopRow(Bytes.toBytes(CallLogUtil.getStopRowkey(call, range.getStartPoint(), range.getEndPoint(),100)));                ResultScanner rs = table.getScanner(scan);                Iterator&lt;Result&gt; it = rs.iterator();                byte[] f = Bytes.toBytes(&quot;f1&quot;);                byte[] caller = Bytes.toBytes(&quot;caller&quot;);                byte[] callee = Bytes.toBytes(&quot;callee&quot;);                byte[] callTime = Bytes.toBytes(&quot;callTime&quot;);                byte[] callDuration = Bytes.toBytes(&quot;callDuration&quot;);                CallLog log = null;                while (it.hasNext()) {                    log = new CallLog();                    Result r = it.next();                    //rowkey                    String rowkey = Bytes.toString(r.getRow());                    String flag = rowkey.split(&quot;,&quot;)[3] ;                    log.setFlag(flag.equals(&quot;0&quot;)?true:false);                    //caller                    log.setCaller(Bytes.toString(r.getValue(f, caller)));                    //callee                    log.setCallee(Bytes.toString(r.getValue(f, callee)));                    //callTime                    log.setCallTime(Bytes.toString(r.getValue(f, callTime)));                    //callDuration                    log.setCallDuration(Bytes.toString(r.getValue(f, callDuration)));                    logs.add(log);                }            }            return logs;        } catch (Exception e) {            e.printStackTrace();        }        return null;    }}</code></pre><p>在查询的controller层里面写调用工具类里面对时间进行格式化。格式化之后的List集合作为参数传入到service层的findCallogs（）里面查询到hbase内容集合logs，将logs传入Model.addAttribute里面（向模型中传入数据也就是让前台可以调用）。下面是controller层的内容：</p><pre><code>    /**     * 进入查询通话记录的页面,form     */    @RequestMapping(&quot;/callLog/toFindCallLogPage&quot;)    public String toFindCallLogPage(){        return &quot;callLog/findCallLog&quot; ;    }    @RequestMapping(value = &quot;/callLog/findCallLog&quot;,method = RequestMethod.POST)    public String findCallLog(Model m , @RequestParam(&quot;caller&quot;) String caller, @RequestParam(&quot;startTime&quot;) String startTime, @RequestParam(&quot;endTime&quot;) String endTime){        List&lt;CallLogRange&gt; list = CallLogUtil.getCallLogRanges(startTime, endTime);        List&lt;CallLog&gt; logs = cs.findCallogs(caller,list);        m.addAttribute(&quot;callLogs&quot;, logs);        return &quot;callLog/callLogList&quot; ;    }}</code></pre><p>上述就完成了主叫查询功能。但是查询的只有主叫功能，没有被叫功能，我们在编写一个协处理器处理被叫查询功能：<br>      /**</p><pre><code> * Put后处理 */public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {    super.postPut(e, put, edit, durability);    //    String tableName0 = TableName.valueOf(CALL_LOG_TABLE_NAME).getNameAsString();    //得到当前的TableName对象    String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();    //判断是否是ns1:calllogs表    if (!tableName0.equals(tableName1)) {        return;    }    //得到主叫的rowkey,    String rowkey = Bytes.toString(put.getRow());    //如果被叫就放行    String[] arr = rowkey.split(&quot;,&quot;);    if (arr[3].equals(&quot;1&quot;)) {        return;    }    //hashcode,caller,time,flag,callee,duration    String caller = arr[1] ;        //主叫    String callTime = arr[2] ;      //通话时间    String callee = arr[4] ;        //被叫    String callDuration = arr[5] ;  //通话时长    //被叫hashcode    String hashcode = CallLogUtil.getHashcode(callee,callTime,100);    //被叫rowkey    String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;    Put newPut = new Put(Bytes.toBytes(calleeRowKey));    newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(REF_ROW_ID), Bytes.toBytes(rowkey));    TableName tn = TableName.valueOf(CALL_LOG_TABLE_NAME);    Table t = e.getEnvironment().getTable(tn);    t.put(newPut);}</code></pre><p>也就是创建协处理器，在postput的方法下（这个方法本来是用于在添加一条主叫信息后在添加一条被叫信息）重写之后，在添加主叫信息后，在添加一条被叫信息，该被叫信息的value值插入到f2列族，refrowid列。然后value值就是 原来主叫的rowkey,这个也就是二级索引的思想，避免了原来的主叫的value重复存储，减少了冗余。所以是重写postput方法。</p><p>在没有重写postgetOp()方法的时候返回的是这种情况：</p><p><img src="https://i.imgur.com/gB8tQaU.png" alt=""></p><p>发现里面是被叫的时候没有电话1和电话2为什么呢？<br>因为在检索时候的是这样子写的：检索填充的值是通过getvalue方法，而通过协处理器填进去的是一个被叫信息是控制，所以get不到value信息。</p><p><img src="https://i.imgur.com/0EPdPzM.png" alt=""></p><p>但是查询的时候，还是不能查询到主叫，所以重写检索方法,在协处理器中重写    postscannerNext（）方法。完成被叫查询返回主叫的rowkey值。</p><pre><code>/**     *     */    public boolean postScannerNext(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, InternalScanner s, List&lt;Result&gt; results, int limit, boolean hasMore) throws IOException {        boolean b = super.postScannerNext(e, s, results, limit, hasMore);        //新集合        List&lt;Result&gt; newList = new ArrayList&lt;Result&gt;();        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if (tableName.equals(CALL_LOG_TABLE_NAME)) {            Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));            for(Result r : results){                //rowkey                String rowkey = Bytes.toString(r.getRow());                String flag = rowkey.split(&quot;,&quot;)[3] ;                //主叫                if(flag.equals(&quot;0&quot;)){                    newList.add(r) ;                }                //被叫                else{                    //取出主叫号码                    byte[] refrowkey = r.getValue(Bytes.toBytes(&quot;f2&quot;),Bytes.toBytes(REF_ROW_ID)) ;                    Get newGet = new Get(refrowkey);                    newList.add(tt.get(newGet));                }            }            results.clear();            results.addAll(newList);        }        return b ;    }}</code></pre><p><img src="https://i.imgur.com/cJBPeDB.png" alt=""></p><pre><code>1.hbase交互    Scan : 设置startRow + endRow    rowkey : hashcode , + callerid , + callTime, 0 , callee , duration.</code></pre><p>2.<br>3.</p><h2 id="编写CallLogController-java"><a href="#编写CallLogController-java" class="headerlink" title="编写CallLogController.java"></a>编写CallLogController.java</h2><pre><code>/** * 进入查询通话记录的页面,form */@RequestMapping(&quot;/callLog/toFindCallLogPage&quot;)public String toFindCallLogPage(){    return &quot;callLog/findCallLog&quot; ;}@RequestMapping(value = &quot;/callLog/findCallLog&quot;,method = RequestMethod.POST)public String findCallLog(@RequestParam(&quot;caller&quot;) String caller, @RequestParam(&quot;startTime&quot;) String startTime, @RequestParam(&quot;endTime&quot;) String endTime){    Calendar startCalendar = Calendar.getInstance();    Calendar endCalendar = Calendar.getInstance();    return &quot;callLog/callLogList&quot; ;}</code></pre><h2 id="编写jsp"><a href="#编写jsp" class="headerlink" title="编写jsp"></a>编写jsp</h2><pre><code>&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;查询通话记录&lt;/title&gt;    &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&apos;&lt;c:url value=&quot;/callLog/findCallLog&quot; /&gt;&apos; method=&quot;post&quot;&gt;    &lt;table&gt;        &lt;tr&gt;            &lt;td&gt;电话号码 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;caller&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;起始时间 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;startTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;结束时间:&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;endTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td colspan=&quot;2&quot;&gt;                &lt;input type=&quot;submit&quot; value=&quot;查询&quot;/&gt;            &lt;/td&gt;        &lt;/tr&gt;    &lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="实现时间段查询"><a href="#实现时间段查询" class="headerlink" title="实现时间段查询"></a>实现时间段查询</h2><pre><code>1.提取时间范围    [CallLogUtil.java]    /**     * 起始时间     */    public static String getStartRowkey(String caller, String startTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + startTime ;    }    /**     * 结束时间     */    public static String getStopRowkey(String caller, String startTime,String endTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + endTime ;    }    /**     * 计算查询时间范围     */    public static List&lt;CallLogRange&gt; getCallLogRanges(String startStr ,String endStr){        try{            SimpleDateFormat sdfYMD = new SimpleDateFormat(&quot;yyyyMMdd&quot;);            SimpleDateFormat sdfYM = new SimpleDateFormat(&quot;yyyyMM&quot;);            DecimalFormat df00 = new DecimalFormat(&quot;00&quot;);            //            List&lt;CallLogRange&gt; list = new ArrayList&lt;CallLogRange&gt;();            //字符串时间            String startPrefix = startStr.substring(0, 6);            String endPrefix = endStr.substring(0, 6);            int endDay = Integer.parseInt(endStr.substring(6, 8));            //结束点            String endPoint = endPrefix + df00.format(endDay + 1);            //日历对象            Calendar c = Calendar.getInstance();            //同年月            if (startPrefix.equals(endPrefix)) {                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);          //设置起始点                range.setEndPoint(endPoint);            //设置结束点                list.add(range);            } else {                //1.起始月                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);                //设置日历的时间对象                c.setTime(sdfYMD.parse(startStr));                c.add(Calendar.MONTH, 1);                range.setEndPoint(sdfYM.format(c.getTime()));                list.add(range);                //是否是最后一月                while (true) {                    //到了结束月份                    if (endStr.startsWith(sdfYM.format(c.getTime()))) {                        range = new CallLogRange();                        range.setStartPoint(sdfYM.format(c.getTime()));                        range.setEndPoint(endPoint);                        list.add(range);                        break;                    } else {                        range = new CallLogRange();                        //起始时间                        range.setStartPoint(sdfYM.format(c.getTime()));                        //增加月份                        c.add(Calendar.MONTH, 1);                        range.setEndPoint(sdfYM.format(c.getTime()));                        list.add(range);                    }                }            }            return list ;        }        catch(Exception e){            e.printStackTrace();        }        return null ;    }2.编写service.3.4.</code></pre><h2 id="实现hbase的协处理器"><a href="#实现hbase的协处理器" class="headerlink" title="实现hbase的协处理器"></a>实现hbase的协处理器</h2><pre><code>0.说明    HBaseConsumer put的数据都是主叫，被叫数据在Coprossor中完成。1.创建协处理器    package com.it18zhang.calllog.coprossor;    import org.apache.hadoop.hbase.TableName;    import org.apache.hadoop.hbase.client.Durability;    import org.apache.hadoop.hbase.client.Put;    import org.apache.hadoop.hbase.client.Table;    import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;    import org.apache.hadoop.hbase.coprocessor.ObserverContext;    import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;    import org.apache.hadoop.hbase.regionserver.wal.WALEdit;    import org.apache.hadoop.hbase.util.Bytes;    import java.io.IOException;    /**     * 协处理器,     */    public class CallLogRegionObserver extends BaseRegionObserver {        /**         * Put后处理         */        public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {            super.postPut(e, put, edit, durability);            //            String tableName0 = TableName.valueOf(&quot;ns1:calllogs&quot;).getNameAsString();            //得到当前的TableName对象            String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();            //判断是否是ns1:calllogs表            if (!tableName0.equals(tableName1)) {                return;            }            //得到主叫的rowkey,            String rowkey = Bytes.toString(put.getRow());            //如果被叫就放行            String[] arr = rowkey.split(&quot;,&quot;);            if (arr[3].equals(&quot;1&quot;)) {                return;            }            //hashcode,caller,time,flag,callee,duration            String caller = arr[1] ;        //主叫            String callTime = arr[2] ;      //通话时间            String callee = arr[4] ;        //被叫            String callDuration = arr[5] ;  //通话时长            //被叫hashcode            String hashcode = CallLogUtil.getHashcode(callee,callTime,100);            //被叫rowkey            String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;            Put newPut = new Put(Bytes.toBytes(calleeRowKey));            newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;refrowid&quot;), Bytes.toBytes(rowkey));            TableName tn = TableName.valueOf(&quot;ns1:calllogs&quot;);            Table t = e.getEnvironment().getTable(tn);            t.put(newPut);        }    }2.注册协处理器    a)导出jar包,分到集群.        ...    b)修改hbase配置文件并分发.        [hbase-site.xml]        &lt;property&gt;                &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;                &lt;value&gt;com.it18zhang.calllog.coprossor.CallLogRegionObserver&lt;/value&gt;        &lt;/property&gt;    c)停止hbase集群    d)重新启动        ...    e)进入hbase shell,重建ns1:calllogs        $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;,&apos;f2&apos;</code></pre><h2 id="主叫"><a href="#主叫" class="headerlink" title="主叫"></a>主叫</h2><pre><code>rowkey:12,1234,xxx,0,5678,60,.,.,.,.,</code></pre><h2 id="被叫"><a href="#被叫" class="headerlink" title="被叫"></a>被叫</h2><pre><code>rowkey:                        f2:refrowkey98,5678,xxxx,1,1234,60   --&gt; 12,1234,xxx,0,5678,60,.</code></pre><h2 id="重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录"><a href="#重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录" class="headerlink" title="重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录"></a>重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录</h2><pre><code>1.重写[CallLogRegionObserver.java]package com.it18zhang.calllog.coprossor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;import org.apache.hadoop.hbase.coprocessor.ObserverContext;import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;import org.apache.hadoop.hbase.regionserver.InternalScanner;import org.apache.hadoop.hbase.regionserver.wal.WALEdit;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * 协处理器, */public class CallLogRegionObserver extends BaseRegionObserver {    //被叫引用id    private static final String REF_ROW_ID = &quot;refrowid&quot; ;    //通话记录表名    private static final String CALL_LOG_TABLE_NAME = &quot;ns1:calllogs&quot; ;    /**     * Put后处理     */    public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {        super.postPut(e, put, edit, durability);        //        String tableName0 = TableName.valueOf(CALL_LOG_TABLE_NAME).getNameAsString();        //得到当前的TableName对象        String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断是否是ns1:calllogs表        if (!tableName0.equals(tableName1)) {            return;        }        //得到主叫的rowkey,        String rowkey = Bytes.toString(put.getRow());        //如果被叫就放行        String[] arr = rowkey.split(&quot;,&quot;);        if (arr[3].equals(&quot;1&quot;)) {            return;        }        //hashcode,caller,time,flag,callee,duration        String caller = arr[1] ;        //主叫        String callTime = arr[2] ;      //通话时间        String callee = arr[4] ;        //被叫        String callDuration = arr[5] ;  //通话时长        //被叫hashcode        String hashcode = CallLogUtil.getHashcode(callee,callTime,100);        //被叫rowkey        String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;        Put newPut = new Put(Bytes.toBytes(calleeRowKey));        newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(REF_ROW_ID), Bytes.toBytes(rowkey));        TableName tn = TableName.valueOf(CALL_LOG_TABLE_NAME);        Table t = e.getEnvironment().getTable(tn);        t.put(newPut);    }    /**     * 重写方法，完成被叫查询，返回主叫结果。     */    public void postGetOp(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Get get, List&lt;Cell&gt; results) throws IOException {        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if(!tableName.equals(CALL_LOG_TABLE_NAME)){            super.preGetOp(e, get, results);        }        else{            //得到rowkey            String rowkey = Bytes.toString(get.getRow());            //            String[] arr = rowkey.split(&quot;,&quot;);            //主叫            if(arr[3].equals(&quot;0&quot;)){                super.postGetOp(e, get, results);            }            //被叫            else{                //得到主叫方的rowkey                String refrowid = Bytes.toString(CellUtil.cloneValue(results.get(0)));                //                Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));                Get g = new Get(Bytes.toBytes(refrowid));                Result r = tt.get(g);                List&lt;Cell&gt; newList = r.listCells();                results.clear();                results.addAll(newList);            }        }    }    /**     *     */    public boolean postScannerNext(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, InternalScanner s, List&lt;Result&gt; results, int limit, boolean hasMore) throws IOException {        boolean b = super.postScannerNext(e, s, results, limit, hasMore);        //新集合        List&lt;Result&gt; newList = new ArrayList&lt;Result&gt;();        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if (tableName.equals(CALL_LOG_TABLE_NAME)) {            Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));            for(Result r : results){                //rowkey                String rowkey = Bytes.toString(r.getRow());                String flag = rowkey.split(&quot;,&quot;)[3] ;                //主叫                if(flag.equals(&quot;0&quot;)){                    newList.add(r) ;                }                //被叫                else{                    //取出主叫号码                    byte[] refrowkey = r.getValue(Bytes.toBytes(&quot;f2&quot;),Bytes.toBytes(REF_ROW_ID)) ;                    Get newGet = new Get(refrowkey);                    newList.add(tt.get(newGet));                }            }            results.clear();            results.addAll(newList);        }        return b ;    }}1&apos;.修改jsp页面    [callLogList.jsp]    &lt;c:if test=&quot;${log.caller == param.caller}&quot;&gt;主叫&lt;/c:if&gt;    &lt;c:if test=&quot;${log.caller != param.caller}&quot;&gt;被叫&lt;/c:if&gt;2.部署jar包3.测试    ...4.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;按照时间段查询通话记录：&lt;/p&gt;
&lt;p&gt;1.按照时间段查询通话记录，设置startRow+endRow。&lt;br&gt;2.web部分设置一个电话号码输入起始时间输入结束时间输入，然后在SSMweb层controller设置一个查询使用hbaseapi。重点在月份值取出来哈希构造r
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（一）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（一）/</id>
    <published>2019-01-11T07:56:21.000Z</published>
    <updated>2019-01-13T07:38:32.377Z</updated>
    
    <content type="html"><![CDATA[<p>0.rowkey的设计<br>因为通过rowkey查询，吧尽可能多的数据放到rowkey里面去。</p><p>考虑的问题：</p><p>从通话记录整个来考虑，记录量比较大。让记录分散，吧主叫被叫编写进去时间编进去，就是一个rowkey的构成，如果用主叫被叫时间做rowkey的话。 </p><p>每个服务器承载的数据量。hbase没经过10G就切割成2个区域，分成2个区域服务器，一条记录是1k10G是多少行可以算出来，可以设计出来区间。要知道rowkey的范围 。</p><p>如果数据都在一台服务器吧请求都发送给一台服务器，压力很大。</p><p>对于服务器来说，每个服务器应该多少数据量的问题。怎么衡量？</p><p>对于单张表是10G就切割。切割出来的区域分成2个区域服务器上去了是10G的数据量。可以算一下一条记录是1K那么10G的数据量是多少行，根据这个法则设定空间，要知道rowkey的范围。加入1个区域存放10G要是有10个区域存放10G是100G。存放就是10G、1k=1亿数据量。</p><p>rowkey是排序的，所以排序最好是等长度的，因为如果从1-10000情况下8是大于10000的。</p><p> 可以通过预切割避免切割风暴。<br> 139。。。。<br>137.。。。<br>切割成区域，如果定了10个区域，要把所有的数据分散到10个区域里面去就是00-09，所以在编写rowkey里面，139，137的都有很多，所以在前面加一个前缀，也就是说盐析。</p><p>rowkey设计的长度原则。一般是定长，越短越好，不超过1个字节：因为目前都是64位系统，内存是8字节对其，控制在16字节8字节的整数倍利用了操作系统的最佳特性。</p><p>建议用rowkey的高位进行散列处理，由程序随机生成，低位放时间字段，这样提高数据均衡分布在每个regionServer来实现负载均衡。</p><p>如果不进行散列，如果用时间片编写开头。起始的Rowkey的弊端就会集中在一个regionserver上，光是交换机写入就已经爆掉hbase了。因为数据量太大了。</p><p>以电话号码编写开头的话，所有数据都在</p><p>rowkey设计原则由于rowkey是字典排序的所以要将常用的放到一个region但是又不能量太大。</p><p>热点：<br><img src="https://i.imgur.com/fYWGFDr.png" alt=""></p><p>总结来说就是在整个数据rowkey前面加个2位数的随机数也就是通过盐析的方式避免热点问题。2位数的随机数是通过一个hash算法实现0-100散列。分布在0-100的不通的region里面。协处理器相当于一个区域观察期，类似于zookeeper的观察者。也就是插入了一条数据他就观察的到通过该preput 和postput重写这些方法来实现在插入前和插入后的动作，和插入的时候类似，通过哈希算法实现前面的随机数。完成新的rowkey的重组。这个地方根据业务场景的需要，每次查询的时候主叫和被叫都要查询出来，所以他的设计是将两个电话的主叫和被叫同时分布在一个区域里面。使得查询的效率更加高效分布更加合理。通过在协处理器哈希算法的时候通过被叫号码+时间片来哈希，主动插入的时候通过主叫号码+时间片来哈希。就可以实现主叫和被叫一个号码的都在同一个区域里面。</p><p>在查询几月到几月的通话详单的时候，通过设置scan.startKey和scan.stopRow查询到开始日期和结束日期。打印是通过resultscanner</p><p>如果查询某一个号码作为被叫的信息，我们可以在设计一张表calleelog被叫记录日志。rowkey设计：呼叫时间吧calltime和calleeid作为rowkey的设计什么时候被叫的但是他的value就是之前设计的callerlog表的rowkey的值，然后通过被叫表的value，这个value就是主叫表的rowkey通过这个也就是通过被叫表查询到了主叫表。这个场景还有2中可能，一种是设计2张表，然后查询，要是不设计2张表的话就是通过上文说过的通过设计一个被叫表指向主叫表的rowkey来完成这个业务场景。</p><p>主叫表查询的rowkey设计：因为主要查询的时候都是通过主叫电话号码和时间来查询通过清单的，所以rowkey设计为hash,callerid,time,0,calleeid，然后value里面放一些其他诸如基站，手机信息等等其他无关紧要的信息，吧主要要查询的内容放到rowkey里面可以增加效率，直接查询rowkey就可以查询到所需要的内容。</p><p>被叫表rowkey设计：设计一个另外一个表。calleeid,callertime里面的value放主叫表的rowkey即可。是为了避免第二张表大量冗余。</p><p>1.按照时间段查询通话记录</p><p><img src="https://i.imgur.com/2vxKcC0.png" alt=""><br>    1.hbase交互<br>        Scan : 设置startRow + endRow<br>        rowkey : hashcode , + callerid , + callTime, 0 , callee , duration.</p><p>2.<br>3.</p><h2 id="编写CallLogController-java"><a href="#编写CallLogController-java" class="headerlink" title="编写CallLogController.java"></a>编写CallLogController.java</h2><pre><code>/** * 进入查询通话记录的页面,form */@RequestMapping(&quot;/callLog/toFindCallLogPage&quot;)public String toFindCallLogPage(){    return &quot;callLog/findCallLog&quot; ;}@RequestMapping(value = &quot;/callLog/findCallLog&quot;,method = RequestMethod.POST)public String findCallLog(@RequestParam(&quot;caller&quot;) String caller, @RequestParam(&quot;startTime&quot;) String startTime, @RequestParam(&quot;endTime&quot;) String endTime){    Calendar startCalendar = Calendar.getInstance();    Calendar endCalendar = Calendar.getInstance();    return &quot;callLog/callLogList&quot; ;}</code></pre><h2 id="编写jsp界面"><a href="#编写jsp界面" class="headerlink" title="编写jsp界面"></a>编写jsp界面</h2><pre><code>&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;查询通话记录&lt;/title&gt;    &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&apos;&lt;c:url value=&quot;/callLog/findCallLog&quot; /&gt;&apos; method=&quot;post&quot;&gt;    &lt;table&gt;        &lt;tr&gt;            &lt;td&gt;电话号码 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;caller&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;起始时间 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;startTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;结束时间:&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;endTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td colspan=&quot;2&quot;&gt;                &lt;input type=&quot;submit&quot; value=&quot;查询&quot;/&gt;            &lt;/td&gt;        &lt;/tr&gt;    &lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="实现时间段查询"><a href="#实现时间段查询" class="headerlink" title="实现时间段查询"></a>实现时间段查询</h2><pre><code>1.提取时间范围    [CallLogUtil.java]    /**     * 起始时间     */    public static String getStartRowkey(String caller, String startTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + startTime ;    }    /**     * 结束时间     */    public static String getStopRowkey(String caller, String startTime,String endTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + endTime ;    }    /**     * 计算查询时间范围     */    public static List&lt;CallLogRange&gt; getCallLogRanges(String startStr ,String endStr){        try{            SimpleDateFormat sdfYMD = new SimpleDateFormat(&quot;yyyyMMdd&quot;);            SimpleDateFormat sdfYM = new SimpleDateFormat(&quot;yyyyMM&quot;);            DecimalFormat df00 = new DecimalFormat(&quot;00&quot;);            //            List&lt;CallLogRange&gt; list = new ArrayList&lt;CallLogRange&gt;();            //字符串时间            String startPrefix = startStr.substring(0, 6);            String endPrefix = endStr.substring(0, 6);            int endDay = Integer.parseInt(endStr.substring(6, 8));            //结束点            String endPoint = endPrefix + df00.format(endDay + 1);            //日历对象            Calendar c = Calendar.getInstance();            //同年月            if (startPrefix.equals(endPrefix)) {                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);          //设置起始点                range.setEndPoint(endPoint);            //设置结束点                list.add(range);            } else {                //1.起始月                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);                //设置日历的时间对象                c.setTime(sdfYMD.parse(startStr));                c.add(Calendar.MONTH, 1);                range.setEndPoint(sdfYM.format(c.getTime()));                list.add(range);                //是否是最后一月                while (true) {                    //到了结束月份                    if (endStr.startsWith(sdfYM.format(c.getTime()))) {                        range = new CallLogRange();                        range.setStartPoint(sdfYM.format(c.getTime()));                        range.setEndPoint(endPoint);                        list.add(range);                        break;                    } else {                        range = new CallLogRange();                        //起始时间                        range.setStartPoint(sdfYM.format(c.getTime()));                        //增加月份                        c.add(Calendar.MONTH, 1);                        range.setEndPoint(sdfYM.format(c.getTime()));                        list.add(range);                    }                }            }            return list ;        }        catch(Exception e){            e.printStackTrace();        }        return null ;    }2.编写service.3.4.</code></pre><h2 id="实现hbase的协处理器"><a href="#实现hbase的协处理器" class="headerlink" title="实现hbase的协处理器"></a>实现hbase的协处理器</h2><pre><code>0.说明    HBaseConsumer put的数据都是主叫，被叫数据在Coprossor中完成。1.创建协处理器    package com.it18zhang.calllog.coprossor;    import org.apache.hadoop.hbase.TableName;    import org.apache.hadoop.hbase.client.Durability;    import org.apache.hadoop.hbase.client.Put;    import org.apache.hadoop.hbase.client.Table;    import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;    import org.apache.hadoop.hbase.coprocessor.ObserverContext;    import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;    import org.apache.hadoop.hbase.regionserver.wal.WALEdit;    import org.apache.hadoop.hbase.util.Bytes;    import java.io.IOException;    /**     * 协处理器,     */    public class CallLogRegionObserver extends BaseRegionObserver {        /**         * Put后处理         */        public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {            super.postPut(e, put, edit, durability);            //            String tableName0 = TableName.valueOf(&quot;ns1:calllogs&quot;).getNameAsString();            //得到当前的TableName对象            String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();            //判断是否是ns1:calllogs表            if (!tableName0.equals(tableName1)) {                return;            }            //得到主叫的rowkey,            String rowkey = Bytes.toString(put.getRow());            //如果被叫就放行            String[] arr = rowkey.split(&quot;,&quot;);            if (arr[3].equals(&quot;1&quot;)) {                return;            }            //hashcode,caller,time,flag,callee,duration            String caller = arr[1] ;        //主叫            String callTime = arr[2] ;      //通话时间            String callee = arr[4] ;        //被叫            String callDuration = arr[5] ;  //通话时长            //被叫hashcode            String hashcode = CallLogUtil.getHashcode(callee,callTime,100);            //被叫rowkey            String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;            Put newPut = new Put(Bytes.toBytes(calleeRowKey));            newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;refrowid&quot;), Bytes.toBytes(rowkey));            TableName tn = TableName.valueOf(&quot;ns1:calllogs&quot;);            Table t = e.getEnvironment().getTable(tn);            t.put(newPut);        }    }2.注册协处理器    a)导出jar包,分到集群.        ...    b)修改hbase配置文件并分发.        [hbase-site.xml]        &lt;property&gt;                &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;                &lt;value&gt;com.it18zhang.calllog.coprossor.CallLogRegionObserver&lt;/value&gt;        &lt;/property&gt;    c)停止hbase集群    d)重新启动        ...    e)进入hbase shell,重建ns1:calllogs        $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;,&apos;f2&apos;</code></pre><h2 id="主叫"><a href="#主叫" class="headerlink" title="主叫"></a>主叫</h2><pre><code>rowkey:12,1234,xxx,0,5678,60,.,.,.,.,</code></pre><h2 id="被叫"><a href="#被叫" class="headerlink" title="被叫"></a>被叫</h2><pre><code>rowkey:                        f2:refrowkey98,5678,xxxx,1,1234,60   --&gt; 12,1234,xxx,0,5678,60,.</code></pre><h2 id="重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录"><a href="#重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录" class="headerlink" title="重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录"></a>重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录</h2><pre><code>1.重写[CallLogRegionObserver.java]package com.it18zhang.calllog.coprossor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;import org.apache.hadoop.hbase.coprocessor.ObserverContext;import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;import org.apache.hadoop.hbase.regionserver.InternalScanner;import org.apache.hadoop.hbase.regionserver.wal.WALEdit;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * 协处理器, */public class CallLogRegionObserver extends BaseRegionObserver {    //被叫引用id    private static final String REF_ROW_ID = &quot;refrowid&quot; ;    //通话记录表名    private static final String CALL_LOG_TABLE_NAME = &quot;ns1:calllogs&quot; ;    /**     * Put后处理     */    public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {        super.postPut(e, put, edit, durability);        //        String tableName0 = TableName.valueOf(CALL_LOG_TABLE_NAME).getNameAsString();        //得到当前的TableName对象        String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断是否是ns1:calllogs表        if (!tableName0.equals(tableName1)) {            return;        }        //得到主叫的rowkey,        String rowkey = Bytes.toString(put.getRow());        //如果被叫就放行        String[] arr = rowkey.split(&quot;,&quot;);        if (arr[3].equals(&quot;1&quot;)) {            return;        }        //hashcode,caller,time,flag,callee,duration        String caller = arr[1] ;        //主叫        String callTime = arr[2] ;      //通话时间        String callee = arr[4] ;        //被叫        String callDuration = arr[5] ;  //通话时长        //被叫hashcode        String hashcode = CallLogUtil.getHashcode(callee,callTime,100);        //被叫rowkey        String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;        Put newPut = new Put(Bytes.toBytes(calleeRowKey));        newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(REF_ROW_ID), Bytes.toBytes(rowkey));        TableName tn = TableName.valueOf(CALL_LOG_TABLE_NAME);        Table t = e.getEnvironment().getTable(tn);        t.put(newPut);    }    /**     * 重写方法，完成被叫查询，返回主叫结果。     */    public void postGetOp(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Get get, List&lt;Cell&gt; results) throws IOException {        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if(!tableName.equals(CALL_LOG_TABLE_NAME)){            super.preGetOp(e, get, results);        }        else{            //得到rowkey            String rowkey = Bytes.toString(get.getRow());            //            String[] arr = rowkey.split(&quot;,&quot;);            //主叫            if(arr[3].equals(&quot;0&quot;)){                super.postGetOp(e, get, results);            }            //被叫            else{                //得到主叫方的rowkey                String refrowid = Bytes.toString(CellUtil.cloneValue(results.get(0)));                //                Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));                Get g = new Get(Bytes.toBytes(refrowid));                Result r = tt.get(g);                List&lt;Cell&gt; newList = r.listCells();                results.clear();                results.addAll(newList);            }        }    }    /**     *     */    public boolean postScannerNext(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, InternalScanner s, List&lt;Result&gt; results, int limit, boolean hasMore) throws IOException {        boolean b = super.postScannerNext(e, s, results, limit, hasMore);        //新集合        List&lt;Result&gt; newList = new ArrayList&lt;Result&gt;();        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if (tableName.equals(CALL_LOG_TABLE_NAME)) {            Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));            for(Result r : results){                //rowkey                String rowkey = Bytes.toString(r.getRow());                String flag = rowkey.split(&quot;,&quot;)[3] ;                //主叫                if(flag.equals(&quot;0&quot;)){                    newList.add(r) ;                }                //被叫                else{                    //取出主叫号码                    byte[] refrowkey = r.getValue(Bytes.toBytes(&quot;f2&quot;),Bytes.toBytes(REF_ROW_ID)) ;                    Get newGet = new Get(refrowkey);                    newList.add(tt.get(newGet));                }            }            results.clear();            results.addAll(newList);        }        return b ;    }}1&apos;.修改jsp页面    [callLogList.jsp]    &lt;c:if test=&quot;${log.caller == param.caller}&quot;&gt;主叫&lt;/c:if&gt;    &lt;c:if test=&quot;${log.caller != param.caller}&quot;&gt;被叫&lt;/c:if&gt;2.部署jar包3.测试    ...4.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;0.rowkey的设计&lt;br&gt;因为通过rowkey查询，吧尽可能多的数据放到rowkey里面去。&lt;/p&gt;
&lt;p&gt;考虑的问题：&lt;/p&gt;
&lt;p&gt;从通话记录整个来考虑，记录量比较大。让记录分散，吧主叫被叫编写进去时间编进去，就是一个rowkey的构成，如果用主叫被叫时间做rowk
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>SSM第四天</title>
    <link href="http://erichunn.github.io/2019/01/10/SSM%E7%AC%AC%E5%9B%9B%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/01/10/SSM第四天/</id>
    <published>2019-01-10T09:11:25.000Z</published>
    <updated>2019-01-10T09:22:13.251Z</updated>
    
    <content type="html"><![CDATA[<p>新建SSM模块，添加完之后再加入maven支持，刷新  </p><p><img src="https://i.imgur.com/p9PS1Gs.png" alt=""></p><h2 id="session数据访问"><a href="#session数据访问" class="headerlink" title="session数据访问"></a>session数据访问</h2><pre><code>1.java    @RequestMapping(&quot;/toLogin&quot;)    public String doLogin() {        return &quot;login&quot;;    }    @RequestMapping(&quot;/doLogin&quot;)    public String doLogin(User u ,HttpSession s){        //将数据存放到session范围。        s.setAttribute(&quot;user&quot;,u);        return &quot;index&quot; ;    }2.jsp    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;    &lt;%@ page session=&quot;true&quot; %&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;login.jsp&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;    &lt;c:out value=&quot;${sessionScope.user.name}&quot;/&gt;    &lt;c:if test=&quot;${sessionScope.user != null}&quot;&gt;        欢迎 &lt;c:out value=&quot;${sessionScope.user.name}&quot;/&gt;    &lt;/c:if&gt;    &lt;c:if test=&quot;${sessionScope.user == null}&quot;&gt;       您尚未登录,请登录!!    &lt;/c:if&gt;    &lt;c:out value=&quot;${sessionScope.user.name}&quot;/&gt;    &lt;form action=&apos;&lt;c:url value=&quot;/doLogin&quot; /&gt;&apos; method=&quot;post&quot;&gt;        UserName : &lt;input type=&quot;text&quot; name=&quot;name&quot;&gt;&lt;br&gt;        Password : &lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br&gt;        &lt;input type=&quot;submit&quot;/&gt;    &lt;/form&gt;    &lt;/body&gt;    &lt;/html&gt;</code></pre><h2 id="整合SSM-springmvc-spring-mybatis"><a href="#整合SSM-springmvc-spring-mybatis" class="headerlink" title="整合SSM(springmvc + spring + mybatis)"></a>整合SSM(springmvc + spring + mybatis)</h2><pre><code>1.创建模块    ssm(javaee)2.添加maven支持3.添加依赖。    mysql驱动    c3p0数据源    mybatis    spring(tx | aop | context))包括事务AOP上下文。    mybatis-spring    spring mvc    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;ssm&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;mysql&lt;/groupId&gt;                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;                &lt;version&gt;5.1.17&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;c3p0&lt;/groupId&gt;                &lt;artifactId&gt;c3p0&lt;/artifactId&gt;                &lt;version&gt;0.9.1.2&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.mybatis&lt;/groupId&gt;                &lt;artifactId&gt;mybatis&lt;/artifactId&gt;                &lt;version&gt;3.2.1&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;junit&lt;/groupId&gt;                &lt;artifactId&gt;junit&lt;/artifactId&gt;                &lt;version&gt;4.11&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.mybatis&lt;/groupId&gt;                &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;                &lt;version&gt;1.3.0&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.aspectj&lt;/groupId&gt;                &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;                &lt;version&gt;1.8.10&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;4.创建包    com.it18zhang.ssm.dao.impl    com.it18zhang.ssm.service.impl    com.it18zhang.ssm.domain    com.it18zhang.ssm.util    com.it18zhang.ssm.web.controller5.创建基本类库    com.it18zhang.ssm.domain.User    com.it18zhang.ssm.domain.Order    com.it18zhang.ssm.domain.Item    ...6.复制beans.xml + mybatis-cconfig.xml+UserMapper.xml + OrderMapper.xml + ItemMapper.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;           xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;           xmlns:context=&quot;http://www.springframework.org/schema/context&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                               http://www.springframework.org/schema/beans/spring-beans.xsd                               http://www.springframework.org/schema/context                               http://www.springframework.org/schema/context/spring-context-4.3.xsd                               http://www.springframework.org/schema/tx                               http://www.springframework.org/schema/tx/spring-tx-4.3.xsd                               http://www.springframework.org/schema/aop                               http://www.springframework.org/schema/aop/spring-aop-4.3.xsd&quot; default-autowire=&quot;byType&quot;&gt;        &lt;!-- 配置事务特征 --&gt;        &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;txManager&quot;&gt;            &lt;tx:attributes&gt;                &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot; isolation=&quot;DEFAULT&quot;/&gt;            &lt;/tx:attributes&gt;        &lt;/tx:advice&gt;        &lt;!-- 配置事务切面 --&gt;        &lt;aop:config&gt;            &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut=&quot;execution(* *..*Service.*(..))&quot; /&gt;        &lt;/aop:config&gt;        &lt;!-- 扫描包 --&gt;        &lt;context:component-scan base-package=&quot;com.it18zhang.ssm.dao,com.it18zhang.ssm.service&quot; /&gt;        &lt;!-- 数据源 --&gt;        &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;            &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;            &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?user=root&amp;amp;password=root&quot;/&gt;            &lt;property name=&quot;user&quot; value=&quot;root&quot;/&gt;            &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;property name=&quot;maxPoolSize&quot; value=&quot;10&quot;/&gt;            &lt;property name=&quot;minPoolSize&quot; value=&quot;2&quot;/&gt;            &lt;property name=&quot;initialPoolSize&quot; value=&quot;3&quot;/&gt;            &lt;property name=&quot;acquireIncrement&quot; value=&quot;2&quot;/&gt;        &lt;/bean&gt;        &lt;!-- mybatis整合spring的核心类。 --&gt;        &lt;bean id=&quot;sf&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;            &lt;!-- 指定数据源 --&gt;            &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;            &lt;!-- 指定mybatis配置文件 --&gt;            &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt;        &lt;/bean&gt;        &lt;!-- 数据源事务管理器 --&gt;        &lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;            &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;        &lt;/bean&gt;    &lt;/beans&gt;    ...7.创建UserController.java    package com.it18zhang.ssm.web.controller;    import com.it18zhang.ssm.domain.User;    import com.it18zhang.ssm.service.UserService;    import org.springframework.stereotype.Controller;    import org.springframework.ui.Model;    import org.springframework.web.bind.annotation.RequestMapping;    import javax.annotation.Resource;    import java.util.List;    /**     *     */    @Controller    public class UserController {        @Resource(name=&quot;userService&quot;)        private UserService us ;        /**         * 查看全部user         */        @RequestMapping(&quot;/user/findall&quot;)        public String findAll(Model m ){            List&lt;User&gt; list = us.selectAll();            m.addAttribute(&quot;allUsers&quot;,list);            return &quot;user/userList&quot; ;        }    }8.编写web.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot;             version=&quot;3.1&quot;&gt;        &lt;!-- 指定spring的配置文件beans.xml --&gt;        &lt;context-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath*:beans.xml&lt;/param-value&gt;        &lt;/context-param&gt;        &lt;!-- 确保web服务器启动时，完成spring的容器初始化 --&gt;        &lt;listener&gt;            &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;        &lt;/listener&gt;        &lt;!-- 配置分发器Servlet --&gt;        &lt;servlet&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;/servlet&gt;        &lt;servlet-mapping&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;url-pattern&gt;/&lt;/url-pattern&gt;        &lt;/servlet-mapping&gt;    &lt;/web-app&gt;9.编写WEB-INF/dispatcher-servlet.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;           xmlns:context=&quot;http://www.springframework.org/schema/context&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd                            http://www.springframework.org/schema/mvc                            http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd                            http://www.springframework.org/schema/context                            http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt;        &lt;!-- 配置扫描路径 --&gt;        &lt;context:component-scan base-package=&quot;com.it18zhang.ssm.web.controller&quot; /&gt;        &lt;!-- 使用注解驱动 --&gt;        &lt;mvc:annotation-driven   /&gt;        &lt;!-- 内部资源视图解析器 --&gt;        &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;            &lt;property name=&quot;prefix&quot; value=&quot;/&quot; /&gt;            &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;        &lt;/bean&gt;    &lt;/beans&gt;</code></pre><h2 id="spring-mvc静态资源部分"><a href="#spring-mvc静态资源部分" class="headerlink" title="spring mvc静态资源部分"></a>spring mvc静态资源部分</h2><pre><code>1.描述    html    image    css    js2.在[dispatcher-servlet.xml]添加如下元素    &lt;mvc:resources mapping=&quot;/jsssss/**&quot; location=&quot;/js/&quot;/&gt;    &lt;mvc:resources mapping=&quot;/css/**&quot; location=&quot;/css/&quot;/&gt;    &lt;mvc:resources mapping=&quot;/images/**&quot; location=&quot;/images/&quot;/&gt;    &lt;mvc:resources mapping=&quot;/html/**&quot; location=&quot;/html/&quot;/&gt;3.常见相关目录    /web/js    /web/css    /web/images    /web/html4.放置相应文件    /web/html/hello.html    &lt;!DOCTYPE html&gt;    &lt;html lang=&quot;en&quot;&gt;    &lt;head&gt;        &lt;meta charset=&quot;UTF-8&quot;&gt;        &lt;title&gt;Hello.html&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div&gt;hello&lt;/div&gt;        &lt;table&gt;            &lt;tr&gt;                &lt;td&gt;ID&lt;/td&gt;                &lt;td&gt;name&lt;/td&gt;                &lt;td&gt;age&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;1&lt;/td&gt;                &lt;td&gt;tom&lt;/td&gt;                &lt;td&gt;12&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;2&lt;/td&gt;                &lt;td&gt;tomas&lt;/td&gt;                &lt;td&gt;13&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;3&lt;/td&gt;                &lt;td&gt;tomasLee&lt;/td&gt;                &lt;td&gt;4&lt;/td&gt;            &lt;/tr&gt;        &lt;/table&gt;    &lt;/body&gt;    &lt;/html&gt;5.启动程序访问    http://localhost:9090/html/hello.html</code></pre><h2 id="css选择器"><a href="#css选择器" class="headerlink" title="css选择器"></a>css选择器</h2><pre><code>table            //标签选择#id                //id选择.class-name        //类选择tabble td        //后台选择</code></pre><h2 id="中文乱码"><a href="#中文乱码" class="headerlink" title="中文乱码"></a>中文乱码</h2><pre><code>1.jsp页面使用&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; language=&quot;java&quot; %&gt;进行utf8码声明。2.在web.xml文件中，加入filter。    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot;             version=&quot;3.1&quot;&gt;        &lt;!-- 指定spring的配置文件beans.xml --&gt;        &lt;context-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath*:beans.xml&lt;/param-value&gt;        &lt;/context-param&gt;        &lt;!-- 确保web服务器启动时，完成spring的容器初始化 --&gt;        &lt;listener&gt;            &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;        &lt;/listener&gt;        &lt;filter&gt;            &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;            &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;            &lt;init-param&gt;                &lt;param-name&gt;encoding&lt;/param-name&gt;                &lt;param-value&gt;UTF-8&lt;/param-value&gt;            &lt;/init-param&gt;            &lt;init-param&gt;                &lt;param-name&gt;forceEncoding&lt;/param-name&gt;                &lt;param-value&gt;true&lt;/param-value&gt;            &lt;/init-param&gt;        &lt;/filter&gt;        &lt;filter-mapping&gt;            &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;            &lt;url-pattern&gt;/*&lt;/url-pattern&gt;        &lt;/filter-mapping&gt;        &lt;!-- 配置分发器Servlet --&gt;        &lt;servlet&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;/servlet&gt;        &lt;servlet-mapping&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;url-pattern&gt;/&lt;/url-pattern&gt;        &lt;/servlet-mapping&gt;    &lt;/web-app&gt;3.确认mysql使用utf8编码，可以修改mysql的编码.    [mysql安装目录/my.ini]    uft84.spring中的数据库连接地址url中显式指定编码.    [beans.xml]    &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?user=root&amp;amp;password=root&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&quot;/&gt;</code></pre><p>unicode : 2        //两个字节</p><p>ascii    : 1        //7<br>iso8859 : 1        //8<br>utf8            //3<br>gbk                //2</p><h2 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h2><pre><code>0.技术背景    mysql:    select * from users limit 10 101.dao + service2.userList.jsp3.4.5.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;新建SSM模块，添加完之后再加入maven支持，刷新  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/p9PS1Gs.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;session数据访问&quot;&gt;&lt;a href=&quot;#session数据访问&quot; cl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>电信项目第一天</title>
    <link href="http://erichunn.github.io/2019/01/05/%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/01/05/电信项目第一天/</id>
    <published>2019-01-05T02:44:38.000Z</published>
    <updated>2019-01-05T14:42:44.415Z</updated>
    
    <content type="html"><![CDATA[<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化:"></a>可视化:</h2><pre><code>1.2.3.4.5.</code></pre><p>package com.it18zhang.callloggen;</p><p>import java.util.HashMap;<br>import java.util.Map;</p><p>/*<em> </em><br> */<br>public class App {<br>    public static Map&lt;String,String&gt; caller = new HashMap&lt;String, String&gt;();<br>    static{<br>        caller.put(“15810092493”, “史玉龙”);<br>        caller.put(“18000696806”, “赵贺彪”);<br>        caller.put(“15151889601”, “张倩 “);<br>        caller.put(“13269361119”, “王世昌”);<br>        caller.put(“15032293356”, “张涛”);<br>        caller.put(“17731088562”, “张阳”);<br>        caller.put(“15338595369”, “李进全”);<br>        caller.put(“15733218050”, “杜泽文”);<br>        caller.put(“15614201525”, “任宗阳”);<br>        caller.put(“15778423030”, “梁鹏”);<br>        caller.put(“18641241020”, “郭美彤”);<br>        caller.put(“15732648446”, “刘飞飞”);<br>        caller.put(“13341109505”, “段光星”);<br>        caller.put(“13560190665”, “唐会华”);<br>        caller.put(“18301589432”, “杨力谋”);<br>        caller.put(“13520404983”, “温海英”);<br>        caller.put(“18332562075”, “朱尚宽”);<br>        caller.put(“18620192711”, “刘能宗”);<br>    }</p><pre><code>public static void main(String[] args) {    genCallLog();}public static void genCallLog(){}</code></pre><h2 id="生成jar包，部署到centos执行"><a href="#生成jar包，部署到centos执行" class="headerlink" title="生成jar包，部署到centos执行"></a>生成jar包，部署到centos执行</h2><pre><code>1.使用maven生成jar文件    ...2.部署到centos3.执行    $&gt;mkdir /home/centos/calllog    java -cp xxx.jar com.it18zhang.callloggen.App /home/centos/calllog/calllog.log4.创建centos上的执行脚本    [calllog.sh]    #!/bin/bash    java -cp Calllog.jar com.it18zhang.callloggen.App /home/centos/calllog/calllog.log5.修改权限    $&gt;chmod a+x calllog.sh6.执行脚本    $&gt;cd ~/calllog    $&gt;./calllog.sh</code></pre><h2 id="手机号"><a href="#手机号" class="headerlink" title="手机号"></a>手机号</h2><pre><code>0755-67568979186----------</code></pre><p>086+0755-67568979</p><h2 id="固话"><a href="#固话" class="headerlink" title="固话"></a>固话</h2><pre><code>0755-675689790755-67568979</code></pre><h2 id="网络电话"><a href="#网络电话" class="headerlink" title="网络电话"></a>网络电话</h2><pre><code>12358757575765656565</code></pre><h2 id="启动zk集群-s201-s202-s203"><a href="#启动zk集群-s201-s202-s203" class="headerlink" title="启动zk集群[s201 + s202 + s203]"></a>启动zk集群[s201 + s202 + s203]</h2><pre><code>$&gt;zkServer.sh start </code></pre><h2 id="启动kafka集群-s202-s203-s204"><a href="#启动kafka集群-s202-s203-s204" class="headerlink" title="启动kafka集群[s202 + s203 + s204]"></a>启动kafka集群[s202 + s203 + s204]</h2><pre><code>$&gt;cd /soft/kafka/config$&gt;kafka-server-start.sh -daemon server.properties</code></pre><h2 id="创建kafka主题"><a href="#创建kafka主题" class="headerlink" title="创建kafka主题"></a>创建kafka主题</h2><pre><code>//创建主题$&gt;kafka-topics.sh --zookeeper s202:2181 --topic calllog --create --replication-factor 3 --partitions 4//查看主题列表$&gt;kafka-topics.sh --zookeeper s202:2181 --list//启动控制台消费者,消费calllog主题,用于测试.测试flume有没有取得到。</code></pre><p>消费者需要连接到zk主题需要连接到zk生产者不用连接zk<br>    $&gt;kafka-console-consumer.sh –zookeeper s201:2181 –topic calllog</p><h2 id="s201上编写flume配置文件件，实时收集calllog-log日志"><a href="#s201上编写flume配置文件件，实时收集calllog-log日志" class="headerlink" title="s201上编写flume配置文件件，实时收集calllog.log日志"></a>s201上编写flume配置文件件，实时收集calllog.log日志</h2><pre><code>1.配置文件    [/soft/flume/conf/calllog.conf]    a1.sources = r1    a1.sinks = k1    a1.channels = c1    a1.sources.r1.type=exec    #-F 最后10行,如果从头开始收集 -c +0 -F:持续收集后续数据,否则进程停止。    a1.sources.r1.command=tail -F -c +0 /home/centos/calllog/calllog.log    a1.channels.c1.type=memory    a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink    a1.sinks.k1.kafka.topic = calllog    #三台节点，启动的时候连接座初始化    a1.sinks.k1.kafka.bootstrap.servers = s202:9092 s203:9092 s204:9092    a1.sinks.k1.kafka.flumeBatchSize = 20    a1.sinks.k1.kafka.producer.acks = 1    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c12.启动flume收集程序    $&gt;flume-ng agent -f /soft/flume/conf/calllog.conf -n a1 &amp;</code></pre><h2 id="在s202主机安装flume软件"><a href="#在s202主机安装flume软件" class="headerlink" title="在s202主机安装flume软件"></a>在s202主机安装flume软件</h2><pre><code>...</code></pre><p>启动hadoop hdfs集群[s201 ~ s206]<br>角色划分:<br>NameNode        //s201,s206<br>DataNode        //s202,s203,s204,s205<br>JournalNode        //s202,s203,s204</p><h2 id="ZK-s201-s206"><a href="#ZK-s201-s206" class="headerlink" title="ZK                //s201,s206"></a>ZK                //s201,s206</h2><pre><code>1.启动hadoop(完全分布式 + HA,HA是s201 + s206作为主备名称节点namenode的2个节点)    在s201上启动dfs集群.    $&gt;start-dfs.sh2.webui        http://s201:50070/3.查看节点状态    $&gt;hdfs haadmin -getServiceState nn14.容灾切换    $&gt;hdfs haadmin -failover nn1 nn2</code></pre><h2 id="启动hbase集群"><a href="#启动hbase集群" class="headerlink" title="启动hbase集群"></a>启动hbase集群</h2><pre><code>1.[角色划分]对hbase做高可用    master            //s201,s204    regsionServer    //s202,s203,s2042.启动hbase集群    //s201    $&gt;start-hbase.sh3.查看进程和webui    http://s201:160104.启动备份master节点    //s204    $&gt;hbase-daemon.sh start master</code></pre><h2 id="创建hbase名字空间-表"><a href="#创建hbase名字空间-表" class="headerlink" title="创建hbase名字空间+表"></a>创建hbase名字空间+表</h2><pre><code>1.创建名字空间    $&gt;hbase shell                        //进入hbase shell    $hbase&gt;create_namespace &apos;ns1&apos;        //创建空间    $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;    //创建表    $hbase&gt;truncate &apos;ns1:calllogs&apos;        //重建表</code></pre><h2 id="IBM-Power720-210000"><a href="#IBM-Power720-210000" class="headerlink" title="IBM Power720(210000) "></a>IBM Power720(210000) </h2><pre><code>基本规格    处理器类型POWER7+处理器主频3.6GHz处理器缓存每个内核256KB二级缓存，4MB三级缓存最大处理器个数8内存类型DDR3标准内存容量32GB最大内存容量128GB4颗CPU</code></pre><h2 id="去IOE"><a href="#去IOE" class="headerlink" title="去IOE"></a>去IOE</h2><pre><code>IBM:        //ibm小型机Oracle:        //oracle数据EMC            //网络存储设备</code></pre><h2 id="戴尔（DELL）13900-100-140万"><a href="#戴尔（DELL）13900-100-140万" class="headerlink" title="戴尔（DELL）13900 * 100 = 140万 "></a>戴尔（DELL）13900 * 100 = 140万 </h2><pre><code>商品名称：戴尔（DELL）R730服务器 机架式主机    2U 至强        E5处理器 内存类型    ECC硬盘总容量：8T以上 8T x 100 = 800T = 副本(3) 800/3 = 250  80%(4/5) =  150T类型：机架服务器电源：冗余操作系统：    DOS内存        总容量：64G及以上硬盘转速：其他支持CPU颗数    2颗机箱规格    2U机架式显存        集成显卡硬盘类型    SASRaid卡        缓存：        无缓存处理器：    至强Xeon-E5</code></pre><h2 id="创建kafka消费者，订阅calllog主题"><a href="#创建kafka消费者，订阅calllog主题" class="headerlink" title="创建kafka消费者，订阅calllog主题"></a>创建kafka消费者，订阅calllog主题</h2><pre><code>1.设计rowkey    业务数据: caller , callee , date , duration    分区号    号码     时间,标记  (对方号码),时长    regionNo, caller,date , flag,callee,duration    caller(11) + 通话时间(201701) =     (后四位) + 201701 = % 1002.3.4.</code></pre><p>11 - 4 = 7</p><p>hbase(main):001:0&gt; scan ‘ns1:calllogs’<br>ROW                             COLUMN+CELL<br> 39,15032293356,20170313140201,0,18620192711,297 column=f1:callDuration, timestamp=1491896679156, value=297</p><p> 39,15032293356,20170313140201,0,18620192711,297 column=f1:callTime, timestamp=1491896679156, value=20170313140201</p><p> 39,15032293356,20170313140201,0,18620192711,297 column=f1:callee, timestamp=1491896679156, value=18620192711</p><p> 39,15032293356,20170313140201,0,18620192711,297 column=f1:caller, timestamp=1491896679156, value=15032293356</p><p> 93,18620192711,20170313140201,1,15032293356,297 column=f1:dummy, timestamp=1491896679184, value=no</p><h2 id="使用mvn命令，下载工件的所有依赖软件包"><a href="#使用mvn命令，下载工件的所有依赖软件包" class="headerlink" title="使用mvn命令，下载工件的所有依赖软件包"></a>使用mvn命令，下载工件的所有依赖软件包</h2><pre><code>mvn -DoutputDirectory=./lib     -DgroupId=com.it18zhang     -DartifactId=CallLogConsumerModule     -Dversion=1.0-SNAPSHOT     dependency:copy-dependencies</code></pre><h2 id="导入kafka消费者，放置以上面的lib下，使用命令行方式运行"><a href="#导入kafka消费者，放置以上面的lib下，使用命令行方式运行" class="headerlink" title="导入kafka消费者，放置以上面的lib下，使用命令行方式运行"></a>导入kafka消费者，放置以上面的lib下，使用命令行方式运行</h2><pre><code>java -cp CallLogConsumerModule.jar;./lib/activation-1.1.jar;./lib/apacheds-i18n-2.0.0-M15.jar;./lib/apacheds-kerberos-codec-2.0.0-M15.jar;./lib/api-asn1-api-1.0.0-M20.jar;./lib/api-util-1.0.0-M20.jar;./lib/avro-1.7.4.jar;./lib/commons-beanutils-1.7.0.jar;./lib/commons-beanutils-core-1.8.0.jar;./lib/commons-cli-1.2.jar;./lib/commons-codec-1.9.jar;./lib/commons-collections-3.2.2.jar;./lib/commons-compress-1.4.1.jar;./lib/commons-configuration-1.6.jar;./lib/commons-digester-1.8.jar;./lib/commons-el-1.0.jar;./lib/commons-httpclient-3.1.jar;./lib/commons-io-2.4.jar;./lib/commons-lang-2.6.jar;./lib/commons-logging-1.2.jar;./lib/commons-math3-3.1.1.jar;./lib/commons-net-3.1.jar;./lib/findbugs-annotations-1.3.9-1.jar;./lib/guava-12.0.1.jar;./lib/hadoop-annotations-2.5.1.jar;./lib/hadoop-auth-2.5.1.jar;./lib/hadoop-common-2.5.1.jar;./lib/hadoop-mapreduce-client-core-2.5.1.jar;./lib/hadoop-yarn-api-2.5.1.jar;./lib/hadoop-yarn-common-2.5.1.jar;./lib/hamcrest-core-1.3.jar;./lib/hbase-annotations-1.2.4.jar;./lib/hbase-client-1.2.4.jar;./lib/hbase-common-1.2.4.jar;./lib/hbase-protocol-1.2.4.jar;./lib/htrace-core-3.1.0-incubating.jar;./lib/httpclient-4.2.5.jar;./lib/httpcore-4.2.4.jar;./lib/jackson-core-asl-1.9.13.jar;./lib/jackson-mapper-asl-1.9.13.jar;./lib/jaxb-api-2.2.2.jar;./lib/jcodings-1.0.8.jar;./lib/jdk.tools-1.6.jar;./lib/jetty-util-6.1.26.jar;./lib/jline-0.9.94.jar;./lib/joni-2.1.2.jar;./lib/jopt-simple-4.9.jar;./lib/jsch-0.1.42.jar;./lib/jsr305-1.3.9.jar;./lib/junit-4.12.jar;./lib/kafka-clients-0.10.0.1.jar;./lib/kafka_2.11-0.10.0.1.jar;./lib/log4j-1.2.15.jar;./lib/lz4-1.3.0.jar;./lib/mail-1.4.jar;./lib/metrics-core-2.2.0.jar;./lib/netty-3.7.0.Final.jar;./lib/netty-all-4.0.23.Final.jar;./lib/paranamer-2.3.jar;./lib/protobuf-java-2.5.0.jar;./lib/scala-library-2.11.8.jar;./lib/scala-parser-combinators_2.11-1.0.4.jar;./lib/slf4j-api-1.6.1.jar;./lib/slf4j-log4j12-1.7.21.jar;./lib/snappy-java-1.1.2.6.jar;./lib/stax-api-1.0-2.jar;./lib/xmlenc-0.52.jar;./lib/xz-1.0.jar;./lib/zkclient-0.8.jar;./lib/zookeeper-3.4.6.jar com.it18zhang.calllog.consumer.HbaseConsumer</code></pre><h2 id="编写web程序，从hbase中提取所有进行展示，可视化"><a href="#编写web程序，从hbase中提取所有进行展示，可视化" class="headerlink" title="编写web程序，从hbase中提取所有进行展示，可视化"></a>编写web程序，从hbase中提取所有进行展示，可视化</h2><pre><code>1.导入ssm项目    ...2.创建CallLog    ...3.创建CallLogService.java + CallLogServiceImpl.java    ...4.</code></pre><p>=======================================</p><p>在windows下编写的.sh文件到了linux上变成不可用了什么原因：<br><img src="https://i.imgur.com/5aOaIic.png" alt=""></p><p>因为换行符的原因，windows下的换行符和Linux下的换行符不一样。所以要在linux下编写.sh文件即可解决。</p><p>=================</p><p>kafka同一个组下只能有一个消费者。被消费一次就不能再次消费了</p><p>所以修改配置文件里面的group.id=5。这是kafka里面的具体问题了。</p><p>==================</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;可视化&quot;&gt;&lt;a href=&quot;#可视化&quot; class=&quot;headerlink&quot; title=&quot;可视化:&quot;&gt;&lt;/a&gt;可视化:&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;1.
2.
3.
4.
5.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;package com.it18zhang.cal
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Java视频中的面试题</title>
    <link href="http://erichunn.github.io/2018/12/10/Java%E8%A7%86%E9%A2%91%E4%B8%AD%E7%9A%84%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <id>http://erichunn.github.io/2018/12/10/Java视频中的面试题/</id>
    <published>2018-12-10T15:53:38.000Z</published>
    <updated>2018-12-15T07:32:34.549Z</updated>
    
    <content type="html"><![CDATA[<h1 id="集合中的面试题"><a href="#集合中的面试题" class="headerlink" title="集合中的面试题"></a>集合中的面试题</h1><h2 id="ArrayList和LinkList的区别"><a href="#ArrayList和LinkList的区别" class="headerlink" title="ArrayList和LinkList的区别"></a>ArrayList和LinkList的区别</h2><p>1、ArrayList和LinkedList可想从名字分析，它们一个是Array(动态数组)的数据结构，一个是Link(链表)的数据结构，此外，它们两个都是对List接口的实现。</p><p>前者是数组队列，相当于动态数组；后者为双向链表结构，也可当作堆栈、队列、双端队列</p><p>2、当随机访问List时（get和set操作），ArrayList比LinkedList的效率更高，因为LinkedList是线性的数据存储方式，所以需要移动指针从前往后依次查找。</p><p>3、当对数据进行增加和删除的操作时(add和remove操作)，LinkedList比ArrayList的效率更高，因为ArrayList是数组，所以在其中进行增删操作时，会对操作点之后所有数据的下标索引造成影响，需要进行数据的移动。</p><p>4、从利用效率来看，ArrayList自由性较低，因为它需要手动的设置固定大小的容量，但是它的使用比较方便，只需要创建，然后添加数据，通过调用下标进行使用；而LinkedList自由性较高，能够动态的随数据量的变化而变化，但是它不便于使用。</p><p>5、ArrayList主要控件开销在于需要在lList列表预留一定空间；而LinkList主要控件开销在于需要存储结点信息以及结点指针信息。</p><h2 id="Java对象的创建过程"><a href="#Java对象的创建过程" class="headerlink" title="Java对象的创建过程"></a>Java对象的创建过程</h2><p>从new指令(我说的是JVM的层面)开始的(具体请看图1)，JVM首先对<strong>符号引用进行解析</strong>，如果找不到对应的符号引用，那么这个类还没有被加载，因此JVM便会进行<strong>类加载过程</strong>（具体加载过程可参见我的另一篇博文）。符号引用解析完毕之后，JVM会为对象在堆中<strong>分配内存</strong>，HotSpot虚拟机实现的JAVA对象包括三个部分：<strong>对象头、实例字段和对齐填充字段</strong>，其中要注意的是，实例字段包括自身定义的和从父类继承下来的（即使父类的实例字段被子类覆盖或者被private修饰，都照样为其分配内存）。相信很多人在刚接触面向对象语言时，总把继承看成简单的“复制”，这其实是完全错误的。JAVA中的继承仅仅是类之间的一种逻辑关系（具体如何保存记录这种逻辑关系，则设计到Class文件格式的知识，具体请看我的另一篇博文），唯有创建对象时的实例字段，可以简单的看成“复制”。</p><p>为对象分配完堆内存之后，JVM会将该内存（除了对象头区域）进行<strong>零值初始化</strong>，这也就解释了为什么JAVA的属性字段无需显示初始化就可以被使用，而方法的局部变量却必须要显示初始化后才可以访问。最后，JVM会<strong>调用对象的构造函数</strong>，当然，调用顺序会一直上溯到Object类。</p><p>至此，一个对象就被创建完毕，此时，一般会有一个引用指向这个对象。在JAVA中，存在两种数据类型，一种就是诸如int、double等基本类型，另一种就是引用类型，比如类、接口、内部类、枚举类、数组类型的引用等。引用的实现方式一般有两种，具体请看图3。</p><p><img src="https://i.imgur.com/MT1d3Sd.png" alt=""></p><p><img src="https://i.imgur.com/3hstOCV.png" alt=""></p><p><img src="https://i.imgur.com/wvA2E0S.png" alt=""></p><p><img src="https://i.imgur.com/1ptUYtl.png" alt=""></p><h2 id="接口类和抽象类"><a href="#接口类和抽象类" class="headerlink" title="接口类和抽象类"></a>接口类和抽象类</h2><h3 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h3><p>在了解抽象类之前，先来了解一下抽象方法。抽象方法是一种特殊的方法：它只有声明，而没有具体的实现。抽象方法的声明格式为：</p><pre><code>abstract void fun();</code></pre><p>抽象方法必须用abstract关键字进行修饰。如果一个类含有抽象方法，则称这个类为抽象类，抽象类必须在类前用abstract关键字修饰。<strong>因为抽象类中含有无具体实现的方法，所以不能用抽象类创建对象</strong>。</p><p>下面要注意一个问题：在《JAVA编程思想》一书中，将抽象类定义为“包含抽象方法的类”，但是后面发现如果一个类不包含抽象方法，只是用abstract修饰的话也是抽象类。也就是说抽象类不一定必须含有抽象方法。个人觉得这个属于钻牛角尖的问题吧，因为如果一个抽象类不包含任何抽象方法，为何还要设计为抽象类？所以暂且记住这个概念吧，不必去深究为什么。</p><pre><code>[public] abstract class ClassName {    abstract void fun();    }</code></pre><p>从这里可以看出，抽象类就是为了继承而存在的，如果你定义了一个抽象类，却不去继承它，那么等于白白创建了这个抽象类，因为你不能用它来做任何事情。对于一个父类，如果它的某个方法在父类中实现出来没有任何意义，必须根据子类的实际需求来进行不同的实现，那么就可以将这个方法声明为abstract方法，此时这个类也就成为abstract类了。</p><p>包含抽象方法的类称为抽象类，但并不意味着抽象类中只能有抽象方法，它和普通类一样，同样可以拥有成员变量和普通的成员方法。注意，<strong>抽象类和普通类的主要有三点区别</strong>：</p><p>　　1）抽象方法必须为public或者protected（因为如果为private，则不能被子类继承，子类便无法实现该方法），缺省情况下默认为public。</p><p>　　2）抽象类不能用来创建对象；</p><p>　　3）如果一个类继承于一个抽象类，则子类必须实现父类的抽象方法。如果子类没有实现父类的抽象方法，则必须将子类也定义为为abstract类。</p><p>在其他方面，抽象类和普通的类并没有区别。</p><h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>接口，英文称作interface，在软件工程中，接口泛指供别人调用的方法或者函数。从这里，我们可以体会到Java语言设计者的初衷，它是对行为的抽象。在Java中，定一个接口的形式如下：</p><pre><code>[public] interface InterfaceName {}</code></pre><p><strong>接口中可以含有 变量和方法</strong>。但是要注意，接口中的<strong>变量会被隐式地指定为public static final变量</strong>（并且只能是public static final变量，用private修饰会报编译错误），而方法会被隐式地指定为public abstract方法且只能是public abstract方法（用其他关键字，比如private、protected、static、 final等修饰会报编译错误），并且<strong>接口中所有的方法不能有具体的实现，也就是说，接口中的方法必须都是抽象方法</strong>。从这里可以隐约看出接口和抽象类的区别，接口是一种极度抽象的类型，它比抽象类更加“抽象”，并且一般情况下不在接口中定义变量。</p><p>要让一个类遵循某组特地的接口需要使用implements关键字，具体格式如下：</p><pre><code>class ClassName implements Interface1,Interface2,[....]{}</code></pre><p>可以看出，允许一个类遵循多个特定的接口。如果一个<strong>非抽象类遵循了某个接口，就必须实现该接口中的所有方法</strong>。对于遵循某个接口的抽象类，可以不实现该接口中的抽象方法。</p><h3 id="抽象类和接口的区别"><a href="#抽象类和接口的区别" class="headerlink" title="抽象类和接口的区别"></a>抽象类和接口的区别</h3><p>1.语法层面上的区别</p><p>　　1）抽象类可以提供成员方法的实现细节，而接口中只能存在public abstract 方法；</p><p>　　2）抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是public static final类型的；</p><p>　　3）接口中不能含有静态代码块以及静态方法，而抽象类可以有静态代码块和静态方法；</p><p>　　4）一个类只能继承一个抽象类，而一个类却可以实现多个接口。</p><p>2.设计层面上的区别</p><p>1）<strong>抽象类是对一种事物的抽象，即对类抽象，而接口是对行为的抽象。抽象类是对整个类整体进行抽象，包括属性、行为，但是接口却是对类局部（行为）进行抽象</strong>。举个简单的例子，飞机和鸟是不同类的事物，但是它们都有一个共性，就是都会飞。那么在设计的时候，可以将飞机设计为一个类Airplane，将鸟设计为一个类Bird，但是不能将 飞行 这个特性也设计为类，因此它只是一个行为特性，并不是对一类事物的抽象描述。此时可以将 飞行 设计为一个接口Fly，包含方法fly( )，然后Airplane和Bird分别根据自己的需要实现Fly这个接口。然后至于有不同种类的飞机，比如战斗机、民用飞机等直接继承Airplane即可，对于鸟也是类似的，不同种类的鸟直接继承Bird类即可。从这里可以看出，继承是一个 “是不是”的关系，而 接口 实现则是 “有没有”的关系。如果一个类继承了某个抽象类，则子类必定是抽象类的种类，而接口实现则是有没有、具备不具备的关系，比如鸟是否能飞（或者是否具备飞行这个特点），能飞行则可以实现这个接口，不能飞行就不实现这个接口。</p><p>2）<strong>设计层面不同，抽象类作为很多子类的父类，它是一种模板式设计。而接口是一种行为规范，它是一种辐射式设计</strong>。什么是模板式设计？最简单例子，大家都用过ppt里面的模板，如果用模板A设计了ppt B和ppt C，ppt B和ppt C公共的部分就是模板A了，如果它们的公共部分需要改动，则只需要改动模板A就可以了，不需要重新对ppt B和ppt C进行改动。而辐射式设计，比如某个电梯都装了某种报警器，一旦要更新报警器，就必须全部更新。也就是说对于抽象类，如果需要添加新的方法，可以直接在抽象类中添加具体的实现，子类可以不进行变更；而对于接口则不行，如果接口进行了变更，则所有实现这个接口的类都必须进行相应的改动。</p><p>　　下面看一个网上流传最广泛的例子：门和警报的例子：门都有open( )和close( )两个动作，此时我们可以定义通过抽象类和接口来定义这个抽象概念：</p><pre><code>abstract class Door {    public abstract void open();    public abstract void close();}</code></pre><p>或者：</p><pre><code>interface Door {    public abstract void open();    public abstract void close();}</code></pre><p>　　但是现在如果我们需要门具有报警alarm( )的功能，那么该如何实现？下面提供两种思路：</p><p>　　1）将这三个功能都放在抽象类里面，但是这样一来所有继承于这个抽象类的子类都具备了报警功能，但是有的门并不一定具备报警功能；</p><p>　　2）将这三个功能都放在接口里面，需要用到报警功能的类就需要实现这个接口中的open( )和close( )，也许这个类根本就不具备open( )和close( )这两个功能，比如火灾报警器。</p><p>　　从这里可以看出， Door的open() 、close()和alarm()根本就属于两个不同范畴内的行为，open()和close()属于门本身固有的行为特性，而alarm()属于延伸的附加行为。因此最好的解决办法是单独将报警设计为一个接口，包含alarm()行为,Door设计为单独的一个抽象类，包含open和close两种行为。再设计一个报警门继承Door类和实现Alarm接口。</p><pre><code>interface Alram {    void alarm();        }abstract class Door {        void open();        void close();        }class AlarmDoor extends Door implements Alarm {        void oepn() {          //....        }    void close() {          //....        }    void alarm() {          //....        }}</code></pre><h2 id="重写和重载的区别"><a href="#重写和重载的区别" class="headerlink" title="重写和重载的区别"></a>重写和重载的区别</h2><h3 id="1-重写-Override"><a href="#1-重写-Override" class="headerlink" title="1.重写(Override)"></a>1.重写(Override)</h3><p>从字面上看，重写就是 重新写一遍的意思。其实就是在子类中把父类本身有的方法重新写一遍。子类继承了父类原有的方法，但有时子类并不想原封不动的继承父类中的某个方法，所以在方法名，参数列表，返回类型(除过子类中方法的返回值是父类中方法返回值的子类时)都相同的情况下， 对方法体进行修改或重写，这就是重写。但要注意子类函数的访问修饰权限不能少于父类的。<br>例如：</p><pre><code>public class Father {    public static void main(String[] args) {        // TODO Auto-generated method stub        Son s = new Son();        s.sayHello();    }    public void sayHello() {        System.out.println(&quot;Hello&quot;);    }}class Son extends Father{    @Override    public void sayHello() {        // TODO Auto-generated method stub        System.out.println(&quot;hello by &quot;);    }}</code></pre><p><strong>重写 总结：</strong><br>1.发生在父类与子类之间 </p><p>2.方法名，参数列表，返回类型（除过子类中方法的返回类型是父类中返回类型的子类）必须相同 </p><p>3.访问修饰符的限制一定要大于被重写方法的访问修饰符（public&gt;protected&gt;default&gt;private) </p><p>4.重写方法一定不能抛出新的检查异常或者比被重写方法申明更加宽泛的检查型异常</p><h3 id="2-重载-Overload"><a href="#2-重载-Overload" class="headerlink" title="2.重载(Overload)"></a>2.重载(Overload)</h3><p>在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同甚至是参数顺序不同）则视为重载。同时，重载对返回类型没有要求，可以相同也可以不同，但不能通过返回类型是否相同来判断重载。<br>例如：</p><pre><code>public class Father {public static void main(String[] args) {    // TODO Auto-generated method stub    Father s = new Father();    s.sayHello();    s.sayHello(&quot;wintershii&quot;);    }    public void sayHello() {    System.out.println(&quot;Hello&quot;);    }public void sayHello(String name) {    System.out.println(&quot;Hello&quot; + &quot; &quot; + name);    }}</code></pre><p><strong>重载 总结：</strong><br>1.重载Overload是一个类中多态性的一种表现<br>2.重载要求同名方法的参数列表不同(参数类型，参数个数甚至是参数顺序)<br>3.重载的时候，返回值类型可以相同也可以不相同。无法以返回型别作为重载函数的区分标准</p><h2 id="面试时，问：重载（Overload）和重写（Override）的区别？-（这部分吴锦峰大数据数讲解好）"><a href="#面试时，问：重载（Overload）和重写（Override）的区别？-（这部分吴锦峰大数据数讲解好）" class="headerlink" title="面试时，问：重载（Overload）和重写（Override）的区别？ （这部分吴锦峰大数据数讲解好）"></a>面试时，问：重载（Overload）和重写（Override）的区别？ （这部分吴锦峰大数据数讲解好）</h2><p>答：方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。</p><p>重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的参数列表，有兼容的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。重载对返回类型没有特殊的要求，不能根据返回类型进行区分。</p><h2 id="为什么要使用内部类？"><a href="#为什么要使用内部类？" class="headerlink" title="为什么要使用内部类？"></a>为什么要使用内部类？</h2><h2 id="HashMap与HashSet的区别"><a href="#HashMap与HashSet的区别" class="headerlink" title="HashMap与HashSet的区别"></a>HashMap与HashSet的区别</h2><p>　　先了解一下HashMap跟HashSet</p><p> HashSet：</p><p>HashSet实现了Set接口，它不允许集合中出现重复元素。当我们提到HashSet时，第一件事就是在将对象存储在</p><p>HashSet之前，要确保重写hashCode（）方法和equals（）方法，这样才能比较对象的值是否相等，确保集合中没有</p><p>储存相同的对象。如果不重写上述两个方法，那么将使用下面方法默认实现：</p><p>　public boolean add(Object obj)方法用在Set添加元素时，如果元素值重复时返回 “false”，如果添加成功则返回”true”</p><p>HashMap：</p><p>　　HashMap实现了Map接口，Map接口对键值对进行映射。Map中不允许出现重复的键（Key）。Map接口有两个基本的实现</p><p>TreeMap和HashMap。TreeMap保存了对象的排列次序，而HashMap不能。HashMap可以有空的键值对（Key（null）-Value（null））</p><p>HashMap是非线程安全的（非Synchronize），要想实现线程安全，那么需要调用collections类的静态方法synchronizeMap（）实现。</p><p>public Object put(Object Key,Object value)方法用来将元素添加到map中。</p><p>HashSet与HashMap的区别：</p><p><img src="https://i.imgur.com/ufx3vZv.png" alt=""></p><h2 id="一个字节的数据大小范围为什么是-128-127"><a href="#一个字节的数据大小范围为什么是-128-127" class="headerlink" title="一个字节的数据大小范围为什么是-128~127"></a>一个字节的数据大小范围为什么是-128~127</h2><p>一个字节是8位，最高位是符号位，最高位为0则是正数。最高位为1则是负数</p><p>如果一个数是正数，最大数则为：01111111，转为十进制为127，</p><p>如果一个数是负数，按照一般人都会觉得是11111111，转为十进制为-127，</p><p>但是：一个+0表示为：00000000，一个-0表示为：1000000，因为符号位不算在里面，所以就会有两个0，所以从一开始发明二进制的时候，就把-0规定为-128，如此二进制的补码就刚好在计算机中运作中吻合。</p><p>公式：计算一个数据类型的数据大小范围：-2^（字节数<em>8-1）~2^(字节数</em>8-1)-1</p><h2 id="异或运算符"><a href="#异或运算符" class="headerlink" title="异或运算符"></a>异或运算符</h2><p>异或运算符（^）</p><p>参加运算的两个数据，按二进制位进行“异或”运算。</p><p>运算规则：0^0=0；  0^1=1；  1^0=1；   1^1=0；</p><p>   即：参加运算的两个对象，如果两个相应位为“异”（值不同），则该位结果为1，否则为0。</p><h2 id="关于Treeset和Treemap"><a href="#关于Treeset和Treemap" class="headerlink" title="关于Treeset和Treemap:"></a>关于Treeset和Treemap:</h2><p>这两个方法其实是通过二叉树进行比较的，也就是说通过二叉树来存储，时间复杂度为0(logn)</p><p>二叉树是小的放在左边，打的放在右边子叶</p><p>然后，每次添加的时候都要通过一个一个比较大小来进行选择添加的位置。那么这时候，就出现一个问题，怎么比较大小</p><p>正常情况下如果泛型是Integer的时候Integer实现了Comparable方法，所以在添加的时候就可以通过自带的比较直接比较添加。但是如果泛型是其他自定义的类的时候就需要重写compare方法。</p><p>treeset和treeset就像hashmap和hashset是一个道理的。都是本质上是一样的。treeset也是通过通过treemap的键值对里面的其中一个存放present一个垃圾值来计算的</p><p>在实现Comparator的时候本来要重写2个方法一个是equlas一个是compare方法，但是由于Comparator的父类是Object已经给重写好了，所以只需要重写Compar的方法即可</p><pre><code>public void testAddDog(){    Set&lt;Dog&gt; set = new Treeeset&lt;Dog&gt;(new DogComparator());    set.add(new Dog(&quot;大黄“));}//需要重写的对比器Class DogComparator implements Comparator&lt;Dog&gt;{......}Class Dog{    private Sring name;    publi void DOg(String name){    super;    this.name =name}}</code></pre><h2 id="关于hashmap和hashset"><a href="#关于hashmap和hashset" class="headerlink" title="关于hashmap和hashset"></a>关于hashmap和hashset</h2><p>hashmap和hashset都采用hash方法来添加内容里面的结构是桶+链表的形式，桶类似于arraylist是内存连续的。</p><p>put方法的流程，拿到E之后先做一个判断判断e在不在这个桶里面，看下桶是不是空的，如果是空的直接放里面，如果是空的，还需要判断是不是跟桶里面的元素相等。</p><p>因为Hashset不能相等，通过三个步骤判断。1看hashcode判断判断x和y的哈希码是否相同，相同不能说明是相等的，但是不同肯定是不等的，以为哈希码可能通过同一个算法计算出同一个值，但是不同的肯定是不等的，2如果是相同的哈希码则再去判断是不是同一个对象，3如果是同一个对象，则是相同的，就不往里放了，同时判断equals方法，这地方考虑equals是否重写没重写还是比较内存地址。</p><p>这个时候equals方法和hashcode方法并没有重写， 所以说，equals方法比较的还是内存地址。hashcode默认取得是内存地址。一般重写equals方法的时候都要重写hashcode方法。</p><h2 id="并发编程有哪些缺点"><a href="#并发编程有哪些缺点" class="headerlink" title="并发编程有哪些缺点"></a>并发编程有哪些缺点</h2><h4 id="1-频繁的上下文切换"><a href="#1-频繁的上下文切换" class="headerlink" title="1 频繁的上下文切换"></a>1 频繁的上下文切换</h4><p>时间片是CPU分配给各个线程的时间，因为时间非常短，所以CPU不断通过切换线程，让我们觉得多个线程是同时执行的，时间片一般是几十毫秒。而每次切换时，需要保存当前的状态起来，以便能够进行恢复先前状态，而这个切换时非常损耗性能，过于频繁反而无法发挥出多线程编程的优势。通常减少上下文切换可以采用无锁并发编程，CAS算法，使用最少的线程和使用协程。</p><p>无锁并发编程：可以参照concurrentHashMap锁分段的思想，不同的线程处理不同段的数据，这样在多线程竞争的条件下，可以减少上下文切换的时间。<br>CAS算法，利用Atomic下使用CAS算法来更新数据，使用了乐观锁，可以有效的减少一部分不必要的锁竞争带来的上下文切换<br>使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多的线程，这样会造成大量的线程都处于等待状态<br>协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换</p><h4 id="2-线程安全"><a href="#2-线程安全" class="headerlink" title="2 线程安全"></a>2 线程安全</h4><p>那么，通常可以用如下方式避免死锁的情况：</p><p>避免一个线程同时获得多个锁；<br>避免一个线程在锁内部占有多个资源，尽量保证每个锁只占用一个资源；<br>尝试使用定时锁，使用lock.tryLock(timeOut)，当超时等待时当前线程不会阻塞；<br>对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况</p><h2 id="需要了解的概念"><a href="#需要了解的概念" class="headerlink" title="需要了解的概念"></a>需要了解的概念</h2><h3 id="3-1-同步VS异步"><a href="#3-1-同步VS异步" class="headerlink" title="3.1 同步VS异步"></a>3.1 同步VS异步</h3><p>同步和异步通常用来形容一次方法调用。同步方法调用一开始，调用者必须等待被调用的方法结束后，调用者后面的代码才能执行。而异步调用，指的是，调用者不用管被调用方法是否完成，都会继续执行后面的代码，当被调用的方法完成后会通知调用者。比如，在超时购物，如果一件物品没了，你得等仓库人员跟你调货，直到仓库人员跟你把货物送过来，你才能继续去收银台付款，这就类似同步调用。而异步调用了，就像网购，你在网上付款下单后，什么事就不用管了，该干嘛就干嘛去了，当货物到达后你收到通知去取就好。</p><h3 id="3-2-并发与并行"><a href="#3-2-并发与并行" class="headerlink" title="3.2 并发与并行"></a>3.2 并发与并行</h3><p>并发和并行是十分容易混淆的概念。并发指的是多个任务交替进行，而并行则是指真正意义上的“同时进行”。实际上，如果系统内只有一个CPU，而使用多线程时，那么真实系统环境下不能并行，只能通过切换时间片的方式交替进行，而成为并发执行任务。真正的并行也只能出现在拥有多个CPU的系统中。</p><h3 id="3-3-阻塞和非阻塞"><a href="#3-3-阻塞和非阻塞" class="headerlink" title="3.3 阻塞和非阻塞"></a>3.3 阻塞和非阻塞</h3><p>阻塞和非阻塞通常用来形容多线程间的相互影响，比如一个线程占有了临界区资源，那么其他线程需要这个资源就必须进行等待该资源的释放，会导致等待的线程挂起，这种情况就是阻塞，而非阻塞就恰好相反，它强调没有一个线程可以阻塞其他线程，所有的线程都会尝试地往前运行。</p><h3 id="3-4-临界区"><a href="#3-4-临界区" class="headerlink" title="3.4 临界区"></a>3.4 临界区</h3><p>临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每个线程使用时，一旦临界区资源被一个线程占有，那么其他线程必须等待。</p><p><img src="https://i.imgur.com/kNOJ5Hs.png" alt=""></p><h2 id="volatile讲解"><a href="#volatile讲解" class="headerlink" title="volatile讲解"></a>volatile讲解</h2><p>更详细地说是要符合以下两个规则：</p><p>线程对变量进行修改之后，要立刻回写到主内存。</p><p>线程对变量读取的时候，要从主内存中读，而不是缓存。</p><p>上面提到volatile的两条语义保证了线程间共享变量的及时可见性，但整个过程并没有保证同步</p><p>对于共享普通变量来说，约定了变量在工作内存中发生变化了之后，必须要回写到工作内存(迟早要回写但并非马上回写)，但对于volatile变量则要求工作内存中发生变化之后，必须马上回写到工作内存，而线程读取volatile变量的时候，必须马上到工作内存中去取最新值而不是读取本地工作内存的副本，此规则保证了前面所说的“当线程A对变量X进行了修改后，在线程A后面执行的其他线程能看到变量X的变动”。</p><p>大部分网上的文章对于volatile的解释都是到此为止，但我觉得还是有遗漏的，提出来探讨。工作内存可以说是主内存的一份缓存，为了避免缓存的不一致性，所以volatile需要废弃此缓存。但除了内存缓存之外，在CPU硬件级别也是有缓存的，即寄存器。假如线程A将变量X由0修改为1的时候，CPU是在其缓存内操作，没有及时回写到内存，那么JVM是无法X=1是能及时被之后执行的线程B看到的，所以我觉得JVM在处理volatile变量的时候，也同样用了硬件级别的缓存一致性原则(CPU的缓存一致性原则参见《Java的多线程机制系列：(二）缓存一致性和CAS》。</p><p>如本文开头时只有在while死循环时才体现出volatile的作用，哪怕只是加了System.out.println(1)这么一小段，普通变量也能达到volatile的效果，这是什么原因呢？原来只有在对变量读取频率很高的情况下，虚拟机才不会及时回写主内存，而当频率没有达到虚拟机认为的高频率时，普通变量和volatile是同样的处理逻辑。如在每个循环中执行System.out.println(1)加大了读取变量的时间间隔，使虚拟机认为读取频率并不那么高，所以实现了和volatile的效果(本文开头的例子只在HotSpot24上测试过，没有在JRockit之类其余版本JDK上测过)。volatile的效果在jdk1.2及之前很容易重现，但随着虚拟机的不断优化，如今的普通变量的可见性已经不是那么严重的问题了</p><h2 id="为什么volatile不能保证原子性？"><a href="#为什么volatile不能保证原子性？" class="headerlink" title="为什么volatile不能保证原子性？"></a>为什么volatile不能保证原子性？</h2><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>锁提供了两种主要特性：原子性和可见性。</p><blockquote><p>原子性即一次只允许一个线程持有某个特定的锁，一次就只有一个线程能够使用共享数据。可见性是必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 。</p></blockquote><p>Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。<br>当一个变量定义为 volatile 之后，将具备：</p><blockquote><p>1.保证此变量对所有的线程的可见性，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，其它线程每次使用前立即从主内存刷新。但普通变量做不到这点，普通变量的值在线程间传递均需要通过主内存来完成。<br>2.禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个“load addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置）</p></blockquote><p><img src="https://i.imgur.com/qfs2pVf.png" alt=""></p><p>假如说线程A在做了i+1，但未赋值的时候，线程B就开始读取i，那么当线程A赋值i=1，并回写到主内存，而此时线程B已经不再需要i的值了，而是直接交给处理器去做+1的操作，于是当线程B执行完并回写到主内存，i的值仍然是1，而不是预期的2。也就是说，volatile缩短了普通变量在不同线程之间执行的时间差，但仍然存有漏洞，依然不能保证原子性。</p><h2 id="什么是指令重排序？"><a href="#什么是指令重排序？" class="headerlink" title="什么是指令重排序？"></a>什么是指令重排序？</h2><p>有两个层面：</p><h3 id="在虚拟机层面"><a href="#在虚拟机层面" class="headerlink" title="在虚拟机层面"></a>在虚拟机层面</h3><p>为了尽可能减少内存操作速度远慢于CPU运行速度所带来的CPU空置的影响，虚拟机会按照自己的一些规则(这规则后面再叙述)将程序编写顺序打乱——即写在后面的代码在时间顺序上可能会先执行，而写在前面的代码会后执行——以尽可能充分地利用CPU。拿上面的例子来说：假如不是a=1的操作，而是a=new byte<a href="分配1M空间">1024*1024</a>，那么它会运行地很慢，此时CPU是等待其执行结束呢，还是先执行下面那句flag=true呢？显然，先执行flag=true可以提前使用CPU，加快整体效率，当然这样的前提是不会产生错误(什么样的错误后面再说)。虽然这里有两种情况：后面的代码先于前面的代码开始执行；前面的代码先开始执行，但当效率较慢的时候，后面的代码开始执行并先于前面的代码执行结束。不管谁先开始，总之后面的代码在一些情况下存在先结束的可能。</p><h3 id="在硬件层面"><a href="#在硬件层面" class="headerlink" title="在硬件层面"></a>在硬件层面</h3><p>CPU会将接收到的一批指令按照其规则重排序，同样是基于CPU速度比缓存速度快的原因，和上一点的目的类似，只是硬件处理的话，每次只能在接收到的有限指令范围内重排序，而虚拟机可以在更大层面、更多指令范围内重排序。硬件的重排序机制参见《从JVM并发看CPU内存指令重排序(Memory Reordering)》</p><h2 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>内存屏障分为两种：<strong>Load Barrier</strong> 和 <strong>Store Barrier</strong>即读屏障和写屏障。</p><p>内存屏障有两个作用：</p><blockquote><p>1.阻止屏障两侧的指令重排序；<br>2.强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。</p></blockquote><blockquote><p>对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；<br>对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。</p></blockquote><p>java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。</p><blockquote><p><strong>LoadLoad屏障</strong>：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。<br><strong>StoreStore屏障</strong>：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。<br><strong>LoadStore屏障</strong>：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。<br><strong>StoreLoad屏障</strong>：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能</p></blockquote><p>volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态：</p><blockquote><p>在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；</p></blockquote><blockquote><p>在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；</p></blockquote><p>由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;集合中的面试题&quot;&gt;&lt;a href=&quot;#集合中的面试题&quot; class=&quot;headerlink&quot; title=&quot;集合中的面试题&quot;&gt;&lt;/a&gt;集合中的面试题&lt;/h1&gt;&lt;h2 id=&quot;ArrayList和LinkList的区别&quot;&gt;&lt;a href=&quot;#ArrayList和Li
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>剑指offer面试题Java版</title>
    <link href="http://erichunn.github.io/2018/12/01/%E5%89%91%E6%8C%87offer%E9%9D%A2%E8%AF%95%E9%A2%98Java%E7%89%88/"/>
    <id>http://erichunn.github.io/2018/12/01/剑指offer面试题Java版/</id>
    <published>2018-12-01T08:56:56.000Z</published>
    <updated>2018-12-01T08:58:08.877Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="算法" scheme="http://erichunn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
      <category term="面试" scheme="http://erichunn.github.io/categories/%E7%AE%97%E6%B3%95/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="剑指offer" scheme="http://erichunn.github.io/categories/%E7%AE%97%E6%B3%95/%E9%9D%A2%E8%AF%95/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="Java" scheme="http://erichunn.github.io/tags/Java/"/>
    
      <category term="面试" scheme="http://erichunn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="剑指offer" scheme="http://erichunn.github.io/tags/%E5%89%91%E6%8C%87offer/"/>
    
      <category term="算法" scheme="http://erichunn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer面试题Java版(一)</title>
    <link href="http://erichunn.github.io/2018/12/01/%E5%89%91%E6%8C%87offer%E9%9D%A2%E8%AF%95%E9%A2%98Java%E7%89%88(%E4%B8%80)/"/>
    <id>http://erichunn.github.io/2018/12/01/剑指offer面试题Java版(一)/</id>
    <published>2018-12-01T08:56:56.000Z</published>
    <updated>2018-12-01T12:28:15.406Z</updated>
    
    <content type="html"><![CDATA[<p>数组基础：</p><pre><code>import java.util.Arrays;import java.util.Scanner;public class jichu {public static void main(String args[]) {    int[][] array = {{1, 3, 4,}, {123, 23, 4}};    int target = 3;    jichu offer = new jichu();    boolean b = offer.find(array, target);    System.out.println(b);    System.out.println(array[0][0]);    System.out.println(array[0][1]);    System.out.println(array[0][2]);    System.out.println(array[1][0]);    System.out.println(array[1][1]);    System.out.println(array[1][2]);    System.out.println(&quot;一维数组转换成String,一维数组按大小排序，以为数组取最大值最小值&quot;);    offer.chaxun();    System.out.println(&quot;遍历数组的几种方式==================&quot;);    offer.bianli1(array);    offer.bianli2(array);    offer.bianli3(array);    System.out.println(&quot;实现数组交换----------------&quot;);    offer.jiaohuan(array);    System.out.println(&quot;打印杨辉三角=========================&quot;);    offer.yanghhui();}public void chaxun() {    int[] a = new int[]{80, 23, 46, 26};    System.out.println(Arrays.toString(a));    Arrays.sort(a);    System.out.println(Arrays.toString(a));    System.out.println(&quot;最小值：&quot; + a[0] + &quot;, 最大值&quot; + a[a.length - 1]);    System.out.println(Arrays.binarySearch(a, 450));}//遍历二维数组public void bianli1(int[][] arr) {    for (int i = 0; i &lt; arr.length; i++) {        for (int j = 0; j &lt; arr[i].length; j++) {            System.out.print(arr[i][j] + &quot; &quot;);        }        System.out.println();    //换行    }}public void bianli2(int[][] arr) {    for (int[] a : arr) {        for (int b : a) {            System.out.print(b + &quot; &quot;);        }        System.out.println();    }}public void bianli3(int[][] arr) {    System.out.println(Arrays.toString(arr[0]));    for (int i = 0; i &lt; arr.length; i++)        System.out.println(Arrays.toString(arr[i]));}//二维数组所有的都头尾交换public void jiaohuan(int[][] arr) {    for (int i = 0; i &lt; arr.length; i++) {        for (int j = 0; j &lt; arr[i].length; j++) {            System.out.print(arr[i][j] + &quot; &quot;);        }        System.out.println();    //换行    }    for (int start = 0, end = arr.length - 1; start &lt; end; start++, end--) {        int[] temp = arr[start];        arr[start] = arr[end];        arr[end] = temp;    }    for (int i = 0; i &lt; arr.length; i++) {        for (int j = 0; j &lt; arr[i].length; j++) {            System.out.print(arr[i][j] + &quot; &quot;);        }        System.out.println();    //换行    }}public void yanghhui() {    //从控制台获取行数    Scanner s = new Scanner(System.in);    int row = s.nextInt();    //根据行数定义好二维数组，由于每一行的元素个数不同，所以不定义每一行的个数    int[][] arr = new int[row][];    //遍历二维数组    for (int i = 0; i &lt; row; i++) {        //初始化每一行的这个一维数组        arr[i] = new int[i + 1];        //遍历这个一维数组，添加元素        for (int j = 0; j &lt;= i; j++) {            //每一列的开头和结尾元素为1，开头的时候，j=0，结尾的时候，j=i            if (j == 0 || j == i) {                arr[i][j] = 1;            } else {//每一个元素是它上一行的元素和斜对角元素之和                arr[i][j] = arr[i - 1][j] + arr[i - 1][j - 1];            }            System.out.print(arr[i][j] + &quot;\t&quot;);        }        System.out.println(&quot;&quot;);    }}public void yanghuipra() {    Scanner scanner = new Scanner(System.in);    int row = scanner.nextInt();    int[][] arr = new int[row][];    for (int i = 0; i &lt; row; i++) {        arr[i] = new int[i + 1];        for (int j = 0; j &lt; row; j++) {            if (j == 0 || j == i) {                arr[i][j] = 1;            } else {                arr[i][j] = arr[i - 1][j - 1] + arr[i - 1][j];            }            System.out.println(arr[i][j] + &quot;\n&quot;);        }    }}</code></pre><p>}</p><hr><pre><code>public static void main(String[] args) {//// write your code here    int[][] A=new  int[][]{{1,2},{4,5},{7,8,10,11,12},{}};    System.out.println(A.length);//4,表示数组的行数    System.out.println(A[0].length);//2，表示对应行的长度    System.out.println(A[1].length);//2    System.out.println(A[2].length);//5}</code></pre><hr><p>if语句基础：</p><p><img src="https://i.imgur.com/OxiJEES.png" alt=""></p><hr><p>第一个个算法</p><p>在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完<br>成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数</p><pre><code> public static void main(String args[]) {    int[][] array = {{1, 3, 4,}, {123, 23, 4}};    int target = 3;    jichu offer = new jichu();    offer.find();}public boolean find(int[][] array, int target) {    if (array == null) {        return false;    }    int row = 0;    int column = array[0].length - 1;    while (row &lt; array.length &amp;&amp; column &gt;= 0) {        if (array[row][column] == target) {            return true;        }        if (array[row][column] &gt; target) {            column--;        } else {            row++;        }    }    return false;}</code></pre><p>第二个算法：<br>将一个字符串中的空格替换成“%20”。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数组基础：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.util.Arrays;
import java.util.Scanner;
public class jichu {

public static void main(String args[]) {
  
      
    
    </summary>
    
      <category term="面试" scheme="http://erichunn.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="剑指offer" scheme="http://erichunn.github.io/categories/%E9%9D%A2%E8%AF%95/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="Java" scheme="http://erichunn.github.io/tags/Java/"/>
    
      <category term="面试" scheme="http://erichunn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="剑指offer" scheme="http://erichunn.github.io/tags/%E5%89%91%E6%8C%87offer/"/>
    
      <category term="算法" scheme="http://erichunn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>SSM第三天</title>
    <link href="http://erichunn.github.io/2018/11/29/SSM%E7%AC%AC%E4%B8%89%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2018/11/29/SSM第三天/</id>
    <published>2018-11-29T13:16:19.000Z</published>
    <updated>2018-11-30T07:45:45.333Z</updated>
    
    <content type="html"><![CDATA[<h2 id="部署tomcat服务器"><a href="#部署tomcat服务器" class="headerlink" title="部署tomcat服务器"></a>部署tomcat服务器</h2><pre><code>1.下载apache-tomcat-7.0.70-windows-x64.zip2.解压文件，不要放到中文或者空格目录下。3.进入加压目录.    cmd&gt;cd {tomcat_home}/bin4.执行命令    cmd&gt;startup.bat5.通过浏览器访问页面，查看是否启动成功。    http://localhost:8080/</code></pre><h2 id="tomcat目录结构"><a href="#tomcat目录结构" class="headerlink" title="tomcat目录结构"></a>tomcat目录结构</h2><pre><code>bin        //执行文件conf    //配置文件目录,server.xml,修改8080.webapps    //项目部署目录,项目打成war包，运行期间自行解压。work    //临时目录logs    //日志目录</code></pre><h2 id="在idea中开发web项目"><a href="#在idea中开发web项目" class="headerlink" title="在idea中开发web项目"></a>在idea中开发web项目</h2><pre><code>1.在idea中配置tomcat服务器    settings &gt; applications server -&gt; + --&gt; 定位到tomcat解压目录 -&gt;ok2.创建java模块 + javaEE支持 + maven支持.3.运行web程序</code></pre><h2 id="配置idea中tomcat热部署"><a href="#配置idea中tomcat热部署" class="headerlink" title="配置idea中tomcat热部署"></a>配置idea中tomcat热部署</h2><pre><code>0.关闭tomcat服务器1.run --&gt; edit configuration2.Server选项卡--&gt; VM options部分    on &quot;Update&quot; action : update Classes and resources    on Frame deactivation : update Classes and resources3.启动服务器要选择&quot;debug&quot;模式.</code></pre><h2 id="在web模块中添加mvn支持"><a href="#在web模块中添加mvn支持" class="headerlink" title="在web模块中添加mvn支持"></a>在web模块中添加mvn支持</h2><p>这个地方controller返回的是modelandview然后在返回给分发器程序的。返回的是模型视图的逻辑名。而且还需要配置一个视图解析器。</p><p><img src="https://i.imgur.com/kxi323W.png" alt=""></p><p>handlemapping controller viewresolve需要配置到beans.xml里面，这个文件可以随意配置名字。</p><pre><code>1.在pom.xml引入springmvc的依赖    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;myspringmvc&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;2.在web/WEB-INF/web.xml文件中配置DispatcherServlet分发器.    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot;             version=&quot;3.1&quot;&gt;        &lt;!-- 配置分发器Servlet --&gt;        &lt;servlet&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;/servlet&gt;        &lt;servlet-mapping&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;url-pattern&gt;/&lt;/url-pattern&gt;        &lt;/servlet-mapping&gt;    &lt;/web-app&gt;3.配置springmvc配置文件，使用注解驱动配置项(默认名称就是dispatcher-servlet.xml)    [web/WEB-INF/dispatcher-servlet.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd                            http://www.springframework.org/schema/mvc                            http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd&quot;&gt;        &lt;!-- 使用注解驱动 --&gt;        &lt;mvc:annotation-driven  /&gt;    &lt;/beans&gt;4.编写控制器类    [HomeController.java]    package com.it18zhang.springmvc.web.controller;    import org.springframework.stereotype.Controller;    import org.springframework.web.bind.annotation.RequestMapping;    /**     * HomeController     */    @Controller    public class HomeController {        /**         * 打开主页         */        @RequestMapping(&quot;/home&quot;)        public String openHome(){            System.out.println(&quot;hello world&quot;);            return null ;        }    }5.配置dispatcher-servlet.xml文件，增加扫描路径配置。    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;           xmlns:context=&quot;http://www.springframework.org/schema/context&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd                            http://www.springframework.org/schema/mvc                            http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd                            http://www.springframework.org/schema/context                            http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt;        &lt;!-- 配置扫描路径 --&gt;        &lt;context:component-scan base-package=&quot;com.it18zhang.springmvc.web.controller&quot; /&gt;        &lt;!-- 使用注解驱动 --&gt;        &lt;mvc:annotation-driven  /&gt;    &lt;/beans&gt;6.启动程序，访问地址    http://localhost:9090/7.出现类找不到的原因。    idea的web项目默认不会将依赖类库放置到web-inf/lib下，需要手动设置详情见PPT。    project structure -&gt; artifacts -&gt; myspringmvc:war exploded -&gt; 选择 output layout选项卡 -&gt;    选择右侧的available elements下myspringmvc条目的所有类库 -&gt;右键 -&gt; put into WEB-INF/lib即可。8.运行程序。9.配置Spring MVC是视图解析器.    [web/WEB-INF/dispatcher-servlet.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;           xmlns:context=&quot;http://www.springframework.org/schema/context&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd                            http://www.springframework.org/schema/mvc                            http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd                            http://www.springframework.org/schema/context                            http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt;        &lt;!-- 配置扫描路径 --&gt;        &lt;context:component-scan base-package=&quot;com.it18zhang.springmvc.web.controller&quot; /&gt;        &lt;!-- 使用注解驱动 --&gt;        &lt;mvc:annotation-driven  /&gt;        &lt;!-- 内部资源视图解析器 --&gt;        &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;            &lt;property name=&quot;prefix&quot; value=&quot;/&quot; /&gt;            &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;        &lt;/bean&gt;    &lt;/beans&gt;10.添加jsp页面和控制代码    [HomeController.java]    package com.it18zhang.springmvc.web.controller;    import org.springframework.stereotype.Controller;    import org.springframework.web.bind.annotation.RequestMapping;    /**     * HomeController     */    @Controller    public class HomeController {        /**         * 打开主页         */        @RequestMapping(&quot;/home&quot;)        public String openHome(){            System.out.println(&quot;hello world&quot;);            return &quot;index&quot;;        }        /**         * 打开主页         */        @RequestMapping(&quot;/home2&quot;)        public String home2(){            System.out.println(&quot;how are you???&quot;);            return &quot;index2&quot;;        }    }11./web/index.jsp + /web/index2.jsp    [/web/index2.jsp]    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;html&gt;      &lt;head&gt;        &lt;title&gt;index2.jsp&lt;/title&gt;      &lt;/head&gt;      &lt;body&gt;        welcome to spring mvc !!!      &lt;/body&gt;    &lt;/html&gt;</code></pre><h2 id="html"><a href="#html" class="headerlink" title="html:"></a>html:</h2><pre><code>标签类型inline            //行内标签,自己不占一行,和其他标签可以在一行.&lt;br&gt;block            //块标签,自己占一行。&lt;a href=&quot;&quot;&gt;百度&lt;/a&gt;</code></pre><h2 id="模拟注册行为"><a href="#模拟注册行为" class="headerlink" title="模拟注册行为"></a>模拟注册行为</h2><pre><code>1.创建/web/reg.jsp    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;html&gt;    &lt;head&gt;      &lt;title&gt;reg.jsp&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;    &lt;form action=&quot;/doReg2&quot; method=&quot;post&quot;&gt;      UserName : &lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt;      Password : &lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br&gt;      &lt;input type=&quot;submit&quot;/&gt;    &lt;/form&gt;    &lt;/body&gt;    &lt;/html&gt;2&apos;.引入Servlet API类库    [pom.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;myspringmvc&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;javax.servlet&lt;/groupId&gt;                &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;                &lt;version&gt;2.5&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;2.创建RegController.java    package com.it18zhang.springmvc.web.controller;    import org.springframework.stereotype.Controller;    import org.springframework.web.bind.annotation.RequestMapping;    import org.springframework.web.bind.annotation.RequestParam;    import javax.servlet.http.HttpServletRequest;    /**     *     */    @Controller    public class RegController {        @RequestMapping(&quot;/toReg&quot;)        public String toRegView(){            return &quot;reg&quot; ;        }        @RequestMapping(&quot;/doReg&quot;)        public String doReg(@RequestParam(&quot;username&quot;) String username, @RequestParam(&quot;password&quot;) String password){            System.out.println(&quot;插入数据&quot;);            System.out.println(username + &quot;,&quot; + password);            return &quot;index&quot; ;        }        @RequestMapping(&quot;/doReg2&quot;)        public String doReg(HttpServletRequest req) {            System.out.println(&quot;插入数据222&quot;);            String user = req.getParameter(&quot;username&quot;);            System.out.println(user);            return &quot;index&quot;;        }    }</code></pre><h2 id="引入jstl标签库-jee标准标签库。"><a href="#引入jstl标签库-jee标准标签库。" class="headerlink" title="引入jstl标签库,jee标准标签库。"></a>引入jstl标签库,jee标准标签库。</h2><pre><code>1.添加pom.xml依赖    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;        &lt;artifactId&gt;jstl&lt;/artifactId&gt;        &lt;version&gt;1.2&lt;/version&gt;    &lt;/dependency&gt;2.修改jsp页面,声明标签库并使用标签    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;reg.jsp&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;    &lt;form action=&apos;&lt;c:url value=&quot;/reg.jsp&quot; /&gt;&apos; method=&quot;post&quot;&gt;        UserName : &lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt;        Password : &lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br&gt;        &lt;input type=&quot;submit&quot;/&gt;    &lt;/form&gt;    &lt;/body&gt;    &lt;/html&gt;3.修改上下文名称    project structure --&gt; artifacts --&gt; edit4.5.</code></pre><h2 id="模拟查询-查询一个User对象"><a href="#模拟查询-查询一个User对象" class="headerlink" title="模拟查询-查询一个User对象"></a>模拟查询-查询一个User对象</h2><pre><code>1.添加方法    class RegController{        ...        /*****从请求中提取uid参数******/        @RequestMapping(&quot;/selectOne&quot;)        public String selectOne(Model model , @RequestParam(&quot;uid&quot;) int uid){            System.out.println(&quot;接受到了参数 : uid = &quot; + uid);            String username =&quot;tomson&quot; ;            //将数据存放到model中，向jsp传递.            model.addAttribute(&quot;myusername&quot;, username);            return &quot;selectOne&quot; ;        }    }2.创建selectOne.jsp    [selectOne.jsp]    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;selectOne.jsp&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        username : &lt;c:out value=&quot;${myusername}&quot; /&gt;    &lt;/body&gt;    &lt;/html&gt;3.打开浏览器输入地址;    http://localhost:9090/selectOne?uid=100</code></pre><h2 id="模拟查询-查询全部信息"><a href="#模拟查询-查询全部信息" class="headerlink" title="模拟查询-查询全部信息"></a>模拟查询-查询全部信息</h2><pre><code>1.定义User类。    public class User {        private Integer id;        private String name;        private int age;        ...        //get/set    }2.在RegController中添加方法    class RegController{        ...    @RequestMapping(&quot;/selectAll&quot;)    public String selectAll(Model m){        List&lt;User&gt; list = new ArrayList&lt;User&gt;();        for(int i = 1  ; i &lt;= 50 ; i ++){            User u = new User();            u.setId(i);            u.setName(&quot;tom&quot; + i);            u.setAge(i % 20);            list.add(u) ;        }        //        m.addAttribute(&quot;allUsers&quot;,list);        return &quot;userList&quot; ;    }3.创建userList.jsp    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;selectOne.jsp&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;table border=&quot;1px&quot;&gt;            &lt;tr&gt;                &lt;td&gt;ID&lt;/td&gt;                &lt;td&gt;NAME&lt;/td&gt;                &lt;td&gt;AGE&lt;/td&gt;            &lt;/tr&gt;            &lt;c:forEach items=&quot;${allUsers}&quot; var=&quot;u&quot;&gt;                &lt;tr&gt;                    &lt;td&gt;&lt;c:out value=&quot;${u.id}&quot;/&gt;&lt;/td&gt;                    &lt;td&gt;&lt;c:out value=&quot;${u.name}&quot;/&gt;&lt;/td&gt;                    &lt;td&gt;&lt;c:out value=&quot;${u.age}&quot;/&gt;&lt;/td&gt;                &lt;/tr&gt;            &lt;/c:forEach&gt;        &lt;/table&gt;    &lt;/body&gt;    &lt;/html&gt;4.启动服务器,输入地址    http://localhost:9090/selectAll</code></pre><h2 id="forward"><a href="#forward" class="headerlink" title="forward:"></a>forward:</h2><pre><code>请求转发，在服务器内部完成。客户端不参与，地址栏不改变。而且只能转发到本应用的其他路径上。共享请求参数。</code></pre><p>redirect<br>    重定向，客户端参与，地址栏变，可以重定向到任意url地址。<br>    不能共享变量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;部署tomcat服务器&quot;&gt;&lt;a href=&quot;#部署tomcat服务器&quot; class=&quot;headerlink&quot; title=&quot;部署tomcat服务器&quot;&gt;&lt;/a&gt;部署tomcat服务器&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;1.下载apache-tomcat-7.0.70-w
      
    
    </summary>
    
    
      <category term="SSM" scheme="http://erichunn.github.io/tags/SSM/"/>
    
  </entry>
  
  <entry>
    <title>Java基础（关于面试）</title>
    <link href="http://erichunn.github.io/2018/11/28/Java%E5%9F%BA%E7%A1%80%EF%BC%88%E5%85%B3%E4%BA%8E%E9%9D%A2%E8%AF%95%EF%BC%89/"/>
    <id>http://erichunn.github.io/2018/11/28/Java基础（关于面试）/</id>
    <published>2018-11-28T07:27:38.000Z</published>
    <updated>2018-11-28T11:37:56.389Z</updated>
    
    <content type="html"><![CDATA[<p>bit意为“位”或“比特”，是电子计算机中最小的数据单位，是计算机存储设备的最小单位，每一位的状态只能是0或1。</p><p>Byte意为“字节”，8个二进制位构成1个”字节(Byte)”，即1Byte=8bit,两者换算是1：8的关系，字节是计算机处理数据的基本单位，即以字节为单位解释信息。1个字节可以储存1个英文字母或者半个汉字，换句话说，1个汉字占据2个字节的存储空间。</p><p>发现 数据类型占内存的位数实际上与<strong><em>操作系统的位数和编译器</em></strong>（不同编译器支持的位数可能有所不同）都有关，具体某种数据类型占字节数得编译器根据操作系统位数两者之间进行协调好后分配内存大小。具体在使用的时候如想知道具体占内存的位数通过sizeof(int)可以得到准确的答案。</p><hr><h1 id="int-和byte-之间的转换"><a href="#int-和byte-之间的转换" class="headerlink" title="int 和byte[]之间的转换"></a>int 和byte[]之间的转换</h1><hr><h1 id="ArrayList和LinkedList的区别-完整总结"><a href="#ArrayList和LinkedList的区别-完整总结" class="headerlink" title="ArrayList和LinkedList的区别-完整总结"></a>ArrayList和LinkedList的区别-完整总结</h1><p>1.ArrayList是实现了基于动态数组的数据结构，每个元素在内存中存储地址是连续的；LinkedList基于链表的数据结构，每个元素内容包扩previous, next, element（其中，previous是该节点的上一个节点，next是该节点的下一个节点，element是该节点所包含的值），也是由于这一性质支持了每个元素在内存中分布存储。</p><p>2.为了使得突破动态长度数组而衍生的ArrayList初始容量为10，每次扩容会固定为之前的1.5倍，所以当你ArrayList达到一定量之后会是一种很大的浪费，并且每次扩容的过程是内部复制数组到新数组；LinkedList的每一个元素都需要消耗一定的空间</p><p>3.对于每个元素的检索，ArrayList要优于LinkedList。因为ArrayList从一定意义上来说，就是复杂的数组，所以基于数组index的  检索性能显然高于通过for循环来查找每个元素的LinkedList。</p><p>4.元素插入删除的效率对比，要视插入删除的位置来分析，各有优劣</p><p>在列表首位添加（删除）元素，LnkedList性能远远优于ArrayList,原因在于ArrayList要后移（前移）每个元素的索引和数组扩容（删除元素时则不需要扩容）。（测试的时候当然插入一次是看不出来什么的，我自己测试插入十万次，就会有数组扩容arraycopy的因素）而LinkedList则直接增加元素，修改原第一元素该节点的上一个节点即可，删除同理</p><p>在列表中间位置添加（删除）元素，总的来说位置靠前则LnkedList性能优于ArrayList，靠后则相反。出现这种情况的原因在于ArrayList性能主要损耗在后移（前移）该位置之后的元素索引，而LinkedList损耗在for循环从第一位检索该位置的元素。这个性能反转的临界点不固定，我自己测试插入十万次，在15000次左右损耗时间相比出现变化</p><p>在列表末尾位置添加（删除）元素，性能相差不大。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;bit意为“位”或“比特”，是电子计算机中最小的数据单位，是计算机存储设备的最小单位，每一位的状态只能是0或1。&lt;/p&gt;
&lt;p&gt;Byte意为“字节”，8个二进制位构成1个”字节(Byte)”，即1Byte=8bit,两者换算是1：8的关系，字节是计算机处理数据的基本单位，即
      
    
    </summary>
    
      <category term="Java基础" scheme="http://erichunn.github.io/categories/Java%E5%9F%BA%E7%A1%80/"/>
    
      <category term="面试" scheme="http://erichunn.github.io/categories/Java%E5%9F%BA%E7%A1%80/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="Java基础" scheme="http://erichunn.github.io/tags/Java%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Kafka</title>
    <link href="http://erichunn.github.io/2018/11/25/Kafka/"/>
    <id>http://erichunn.github.io/2018/11/25/Kafka/</id>
    <published>2018-11-25T07:37:41.000Z</published>
    <updated>2018-11-26T14:25:41.761Z</updated>
    
    <content type="html"><![CDATA[<h2 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h2><pre><code>收集日志、移动、聚合框架。基于事件。</code></pre><h2 id="agent"><a href="#agent" class="headerlink" title="agent"></a>agent</h2><pre><code>source        //接收数据,生产者            //put()            //NetcatSource            //ExecSource,实时收集 tail -F xxx.txt            //spooldir            //seq            //Stress            //avroSourcechannel        //暂存数据，缓冲区,            //非永久性:MemoryChannel            //永久性  :FileChannel,磁盘.             //SpillableMemoryChannel :Mem + FileChannel.Capacitysink        //输出数据,消费者            //从channel提取take()数据,write()destination.            //HdfsSink            //HbaseSink            //avroSink</code></pre><p>看一下一边都是存储到哪里，如果是电信的那种需要经常查询的就需要放到Hbase里面，如果是放到hdfs里面就只能是全表扫描了。hbase可以随机定位。瞬间定位。  </p><h2 id="JMS"><a href="#JMS" class="headerlink" title="JMS"></a>JMS</h2><pre><code>java message service,java消息服务。queue        //只有能有一个消费者。P2P模式(点对点).            //发布订阅(publish-subscribe,主题模式)，</code></pre><h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><pre><code>分布式流处理平台。在系统之间构建实时数据流管道。以topic分类对记录进行存储每个记录包含key-value+timestamp每秒钟百万消息吞吐量。producer            //消息生产者consumer            //消息消费者consumer group        //消费者组kafka server        //broker,kafka服务器也叫broker    topic                //主题,副本数,分区.zookeeper            //hadoop namenoade + RM HA | hbase | kafka</code></pre><h2 id="安装kafka"><a href="#安装kafka" class="headerlink" title="安装kafka"></a>安装kafka</h2><pre><code>0.选择s202 ~ s204三台主机安装kafka1.准备zk    略2.jdk    略3.tar文件4.环境变量    略5.配置kafka    [kafka/config/server.properties]    ...    broker.id=202    ...    listeners=PLAINTEXT://:9092    ...    log.dirs=/home/centos/kafka/logs    ...    zookeeper.connect=s201:2181,s202:2181,s203:21816.分发server.properties，同时修改每个文件的broker.id7.启动kafka服务器    a)先启动zk    b)启动kafka        [s202 ~ s204]        $&gt;bin/kafka-server-start.sh config/server.properties    c)验证kafka服务器是否启动        $&gt;netstat -anop | grep 90928.创建主题     $&gt;bin/kafka-topics.sh --create --zookeeper s201:2181 --replication-factor 3 --partitions 3 --topic test9.查看主题列表    $&gt;bin/kafka-topics.sh --list --zookeeper s201:218110.启动控制台生产者    $&gt;bin/kafka-console-producer.sh --broker-list s202:9092 --topic test111.启动控制台消费者    $&gt;bin/kafka-console-consumer.sh --bootstrap-server s202:9092 --topic test1 --from-beginning --zookeeper s202:218112.在生产者控制台输入hello world</code></pre><h2 id="kafka集群在zk的配置"><a href="#kafka集群在zk的配置" class="headerlink" title="kafka集群在zk的配置"></a>kafka集群在zk的配置</h2><pre><code>/controller            ===&gt;    {&quot;version&quot;:1,&quot;brokerid&quot;:202,&quot;timestamp&quot;:&quot;1490926369148&quot;/controller_epoch    ===&gt;    1/brokers/brokers/ids        //记载kfk集群每个服务器的信息/brokers/ids/202    ===&gt;    {&quot;jmx_port&quot;:-1,&quot;timestamp&quot;:&quot;1490926370304&quot;,&quot;endpoints&quot;:[&quot;PLAINTEXT://s202:9092&quot;],&quot;host&quot;:&quot;s202&quot;,&quot;version&quot;:3,&quot;port&quot;:9092}            //每个节点的连接信息/brokers/ids/203/brokers/ids/204        //每个主题下分区数据，主题是有分区的。/brokers/topics/test/partitions/0/state ===&gt;{&quot;controller_epoch&quot;:1,&quot;leader&quot;:203,&quot;version&quot;:1,&quot;leader_epoch&quot;:0,&quot;isr&quot;:[203,204,202]}/brokers/topics/test/partitions/1/state ===&gt;.../brokers/topics/test/partitions/2/state ===&gt;...</code></pre><p>leader是针对于主题来说的，是针对主题上的分区来说的。每个分区test主题下。controller也是kfk注册的他和broker是一个层级。说明在kfk集群里面s202是类似于Leader的身份。在</p><pre><code>/brokers/seqid        ===&gt; null/admin/admin/delete_topics/test        ===&gt;标记删除的主题/isr_change_notification/consumers/xxxx//config</code></pre><p>下图是生产者没有连接zk别的都是有连接zk的</p><p><img src="https://i.imgur.com/Kq3MmBF.png" alt=""></p><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><h2 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h2><pre><code>//2个副本5个分区，2乘以5对应了10个文件夹分配到3个节点所以s202里面有3个，repliation_factor 2 partitions 5$&gt;kafka-topic.sh --zookeeper s202:2181 --replication_factor 3 --partitions 4 --create --topic test32 x 5  = 10        //是个文件夹[s202]test2-1            //test2-2            //test2-3            //[s203]test2-0test2-2test2-3test2-4[s204]test2-0test2-1test2-4</code></pre><h2 id="重新布局分区和副本，手动再平衡"><a href="#重新布局分区和副本，手动再平衡" class="headerlink" title="重新布局分区和副本，手动再平衡"></a>重新布局分区和副本，手动再平衡</h2><pre><code>$&gt;kafka-topics.sh --alter --zookeeper s202:2181 --topic test2 --replica-assignment 203:204,203:204,203:204,203:204,203:204</code></pre><h2 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h2><pre><code>broker存放消息以消息达到顺序存放。生产和消费都是副本感知的。支持到n-1故障。每个分区都有leader，follow.leader挂掉时，消息分区写入到本地log或者，向生产者发送消息确认回执之前，生产者向新的leader发送消息。新leader的选举是通过isr进行，第一个注册的follower成为leader。</code></pre><h2 id="kafka支持副本模式"><a href="#kafka支持副本模式" class="headerlink" title="kafka支持副本模式"></a>kafka支持副本模式</h2><pre><code>[同步复制]    1.producer联系zk识别leader    2.向leader发送消息    3.leadr收到消息写入到本地log    4.follower从leader pull消息    5.follower向本地写入log    6.follower向leader发送ack消息    7.leader收到所有follower的ack消息    8.leader向producer回传ack[异步副本]    和同步复制的区别在与leader写入本地log之后，    直接向client回传ack消息，不需要等待所有follower复制完成。</code></pre><h2 id="通过java-API实现消息生产者，发送消息"><a href="#通过java-API实现消息生产者，发送消息" class="headerlink" title="通过java API实现消息生产者，发送消息"></a>通过java API实现消息生产者，发送消息</h2><pre><code>package com.it18zhang.kafkademo.test;import org.junit.Test;import kafka.javaapi.producer.Producer;import kafka.producer.KeyedMessage;import kafka.producer.ProducerConfig;import java.util.HashMap;import java.util.Properties;/** * Created by Administrator on 2017/3/31. */public class TestProducer {    @Test    public void testSend(){        Properties props = new Properties();        //broker列表        props.put(&quot;metadata.broker.list&quot;, &quot;s202:9092&quot;);        //串行化        props.put(&quot;serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;);        //        props.put(&quot;request.required.acks&quot;, &quot;1&quot;);        //创建生产者配置对象        ProducerConfig config = new ProducerConfig(props);        //创建生产者        Producer&lt;String, String&gt; producer = new Producer&lt;String, String&gt;(config);        KeyedMessage&lt;String, String&gt; msg = new KeyedMessage&lt;String, String&gt;(&quot;test3&quot;,&quot;100&quot; ,&quot;hello world tomas100&quot;);        producer.send(msg);        System.out.println(&quot;send over!&quot;);    }}</code></pre><h2 id="消息消费者"><a href="#消息消费者" class="headerlink" title="消息消费者"></a>消息消费者</h2><pre><code>/** * 消费者 */@Testpublic void testConumser(){    //    Properties props = new Properties();    props.put(&quot;zookeeper.connect&quot;, &quot;s202:2181&quot;);    props.put(&quot;group.id&quot;, &quot;g3&quot;);    props.put(&quot;zookeeper.session.timeout.ms&quot;, &quot;500&quot;);    props.put(&quot;zookeeper.sync.time.ms&quot;, &quot;250&quot;);    props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);    props.put(&quot;auto.offset.reset&quot;, &quot;smallest&quot;);    //创建消费者配置对象    ConsumerConfig config = new ConsumerConfig(props);    //    Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();    map.put(&quot;test3&quot;, new Integer(1));    Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; msgs = Consumer.createJavaConsumerConnector(new ConsumerConfig(props)).createMessageStreams(map);    List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt; msgList = msgs.get(&quot;test3&quot;);    for(KafkaStream&lt;byte[],byte[]&gt; stream : msgList){        ConsumerIterator&lt;byte[],byte[]&gt; it = stream.iterator();        while(it.hasNext()){            byte[] message = it.next().message();            System.out.println(new String(message));        }    }}</code></pre><h2 id="flume集成kafka"><a href="#flume集成kafka" class="headerlink" title="flume集成kafka"></a>flume集成kafka</h2><pre><code>1.KafkaSink    [生产者]    a1.sources = r1    a1.sinks = k1    a1.channels = c1    a1.sources.r1.type=netcat    a1.sources.r1.bind=localhost    a1.sources.r1.port=8888    a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink    a1.sinks.k1.kafka.topic = test3    a1.sinks.k1.kafka.bootstrap.servers = s202:9092    a1.sinks.k1.kafka.flumeBatchSize = 20    a1.sinks.k1.kafka.producer.acks = 1    a1.channels.c1.type=memory    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c12.KafkaSource    [消费者]    a1.sources = r1    a1.sinks = k1    a1.channels = c1    a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource    a1.sources.r1.batchSize = 5000    a1.sources.r1.batchDurationMillis = 2000    a1.sources.r1.kafka.bootstrap.servers = s202:9092    a1.sources.r1.kafka.topics = test3    a1.sources.r1.kafka.consumer.group.id = g4    a1.sinks.k1.type = logger    a1.channels.c1.type=memory    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c13.Channel    生产者 + 消费者    a1.sources = r1    a1.sinks = k1    a1.channels = c1    a1.sources.r1.type = avro    a1.sources.r1.bind = localhost    a1.sources.r1.port = 8888    a1.sinks.k1.type = logger    a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel    a1.channels.c1.kafka.bootstrap.servers = s202:9092    a1.channels.c1.kafka.topic = test3    a1.channels.c1.kafka.consumer.group.id = g6    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c1</code></pre><p>flume重启后会重新读取里面的内容，那么怎么解决重复读取？要引进行序号，每一行都是一个事件，所以在sink里面之后写入redis或者hbase里面因为是高速的，下次再启动flume，虽然从头开始读，也往通道里面放，但是对于sink来讲，会判断他的行号，如果序号比我的数据存的要早，就滤过。比这个大就往里写。相当于一个拦截器</p><p><img src="https://i.imgur.com/U1pTiwY.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;flume&quot;&gt;&lt;a href=&quot;#flume&quot; class=&quot;headerlink&quot; title=&quot;flume&quot;&gt;&lt;/a&gt;flume&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;收集日志、移动、聚合框架。
基于事件。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;agent&quot;&gt;&lt;a
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hbase第四天</title>
    <link href="http://erichunn.github.io/2018/11/22/Hbase%E7%AC%AC%E5%9B%9B%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2018/11/22/Hbase第四天/</id>
    <published>2018-11-22T01:26:56.000Z</published>
    <updated>2018-11-24T07:00:26.803Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h2><pre><code>协处理器.Observer            //触发器,基于事件激活的。Endpoint            //存储过程,客户端调用。RegionObserver        //system --&gt; user[加载顺序]10000-99callerId - 201703 : hashcode % 100 = 00-9901,139xxxx,138yyy,....</code></pre><h2 id="热点"><a href="#热点" class="headerlink" title="热点"></a>热点</h2><pre><code>让数据均匀分散。</code></pre><p>create ‘ns1:calllogs’ , SPLITS=&gt;[01,02,03,,…99,]</p><h2 id="rowkey"><a href="#rowkey" class="headerlink" title="rowkey"></a>rowkey</h2><pre><code>按照byte排序。</code></pre><p>create table xxx(){</p><p>}</p><h2 id="rowkey-1"><a href="#rowkey-1" class="headerlink" title="rowkey"></a>rowkey</h2><pre><code>分区编号xx,callerId,callTime,calleeIdstartkey = xx,19626675332,startkey = xx,19626675333,</code></pre><h1 id="对通话记录表的设计：（具体在HBase的设计原则2）"><a href="#对通话记录表的设计：（具体在HBase的设计原则2）" class="headerlink" title="对通话记录表的设计：（具体在HBase的设计原则2）"></a>对通话记录表的设计：（具体在HBase的设计原则2）</h1><p><img src="https://i.imgur.com/Zt5A1OI.png" alt=""></p><p>对于首先创建的主叫的表是上面这张表，在查询主叫的时候只需要指定xx，主叫时间,时间片。即可。但是查询被叫的时候就不行了。几乎要全表扫描。用00,138xx,2017010101,139xxx这样查询。所以每次向这个表写记录的时候，我们都知道被叫是谁，如果知道被叫的话。我们可以在设计一张表，叫calleeLog,他的rowkey有calleid，time,callerid构成。被叫表存的value存的是主叫表rowkey里面的被叫。然后根据这个查到主叫表后面的内容。但是如果只想知道谁给你打的电话，所以在被叫表的rowkey里面加了一个callerid，如果想查询谁给你打了电话，就在被叫表rowkey里面加了一个callerid。主叫表的rowkey里面都是作为主叫出现的，被叫表里面的数据都是作为被叫出现的。主叫表的内容被叫表里没有，被叫表的内容主叫表也没有的。而且应该吧时长duration也放在里面。也就是说要把最经常使用的信息都编入rowkey里面去，能不查具体的value就尽量不查询具体的value，但是如果要查询具体的数据，什么基站，那个口啊，就是要查询主叫表里面的value的值。这个下图所示的也就是叫二次索引。在写入主叫表的时候也在往被叫表里面写入，用什么写入？也就是用协处理器来处理，怎么处理呢，就是在你写入主叫表的时候，协处理器立刻截获，然后重写里面的方法，往被叫表里面写入就可以了。所以这个就是一个电信HBase的设计原则。    </p><p><img src="https://i.imgur.com/QLxuFNg.png" alt=""></p><h2 id="通化记录"><a href="#通化记录" class="headerlink" title="通化记录"></a>通化记录</h2><pre><code>1.创建表    create &apos;ns1:calllogs&apos;,&apos;f1&apos;2.创建单元测试    @Test    public void put() throws Exception {        Configuration conf = HBaseConfiguration.create();        Connection conn = ConnectionFactory.createConnection(conf);        TableName tname = TableName.valueOf(&quot;ns1:calllogs&quot;);        Table table = conn.getTable(tname);        String callerId = &quot;13845456767&quot; ;        String calleeId = &quot;139898987878&quot; ;        SimpleDateFormat sdf = new SimpleDateFormat();        sdf.applyPattern(&quot;yyyyMMddHHmmss&quot;);        String callTime = sdf.format(new Date());        int duration = 100 ;        DecimalFormat dff = new DecimalFormat();        dff.applyPattern(&quot;00000&quot;);        String durStr = dff.format(duration);        //区域00-99        int hash = (callerId + callTime.substring(0, 6)).hashCode();        hash = (hash &amp; Integer.MAX_VALUE) % 100 ;        //hash区域号        DecimalFormat df = new DecimalFormat();        df.applyPattern(&quot;00&quot;);        String regNo = df.format(hash);        //拼接rowkey        //xx , callerid , time ,  direction, calleid  ,duration        String rowkey = regNo + &quot;,&quot; + callerId + &quot;,&quot; + callTime + &quot;,&quot; + &quot;0,&quot; + calleeId + &quot;,&quot; + durStr  ;        byte[] rowid = Bytes.toBytes(rowkey);        Put put = new Put(rowid);        put.addColumn(Bytes.toBytes(&quot;f1&quot;),Bytes.toBytes(&quot;callerPos&quot;),Bytes.toBytes(&quot;河北&quot;));        put.addColumn(Bytes.toBytes(&quot;f1&quot;),Bytes.toBytes(&quot;calleePos&quot;),Bytes.toBytes(&quot;河南&quot;));        //执行插入        table.put(put);        System.out.println(&quot;over&quot;);    }3.创建协处理器    public class CalleeLogRegionObserver extends BaseRegionObserver{        public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {            super.postPut(e, put, edit, durability);            //            TableName callLogs = TableName.valueOf(&quot;calllogs&quot;);            //得到当前的TableName对象            TableName tableName = e.getEnvironment().getRegion().getRegionInfo().getTable();            if(!callLogs.equals(tableName)){                return  ;            }            //得到主叫的rowkey            //xx , callerid , time ,  direction, calleid  ,duration            //被叫:calleid,time,            String rowkey = Bytes.toString(put.getRow());            String[] arr = rowkey.split(&quot;,&quot;);            String hash = Util.getRegNo(arr[4],arr[2]);            //hash            String newRowKey = hash + &quot;,&quot; + arr[4] + &quot;,&quot; + arr[2] + &quot;,1,&quot; + arr[1] + &quot;,&quot; +  arr[5] ;            Put newPut = new Put(Bytes.toBytes(newRowKey));            Table t = e.getEnvironment().getTable(tableName);            t.put(newPut);        }    }4.配置hbase-site.xml并分发分发jar包。    &lt;property&gt;        &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;        &lt;value&gt;com.it18zhang.hbasedemo.coprocessor.CalleeLogRegionObserver&lt;/value&gt;    &lt;/property&gt;5.启动hbase集群.</code></pre><h2 id="BloomFilter"><a href="#BloomFilter" class="headerlink" title="BloomFilter"></a>BloomFilter</h2><pre><code>布隆过滤器。</code></pre><p><img src="https://i.imgur.com/c0wLF4w.png" alt=""></p><p>代码如下:</p><p><img src="https://i.imgur.com/Za6Pcr1.png" alt=""></p><h2 id="phonix"><a href="#phonix" class="headerlink" title="phonix"></a>phonix</h2><pre><code>1.安装phonix    a)下载apache-phoenix-4.10.0-HBase-1.2-bin.tar.gz    b)tar    c)复制xxx-server.jar到hbase的lib目录，并且分发,删除以前的phonixjar包。    d)重启hbase2.使用phonix的命令行程序    $&gt;phonix/bin/.sqlline.py s202    //连接的是zk服务器    $phonix&gt;!tables    $phonix&gt;!help                    //查看帮助</code></pre><p>phoenix在创建表的时候要使用大量的协处理器，他是在建表时候不区分大小写的，而且hbase不可以识别得出来他的表，但是hbase shell里面建的表他能识别。</p><pre><code>2.SQL Client安装    a)下载squirrel-sql-3.7.1-standard.jar        该文件是安装文件，执行的安装程序。        $&gt;jar -jar squirrel-sql-3.7.1-standard.jar        $&gt;下一步...    b)复制phoenix-4.10.0-HBase-1.2-client.jar到SQuerrel安装目录的lib下(c:\myprograms\squirrel)。    c)启动SQuirrel(GUI)        定位安装目录-&gt;执行squirrel-sql.bat    d)打开GUI界面    d)在左侧的边栏选中&quot;Drivers&quot;选项卡，        点击 &quot;+&quot; -&gt;        URL                : jdbc:phoenix:192.168.231.202        Driverclass        : org.apache.phoenix.jdbc.PhoenixDriver            jdbc:phoenix: s202    d)测试。3.SQLLine客户端操作    //建表    $jdbc:phoenix&gt;create table IF NOT EXISTS test.Person (IDCardNum INTEGER not null primary key, Name varchar(20),Age INTEGER);    //插入数据    $jdbc:phoenix&gt;UPSERT INTO test.PERSON(IDCardNum , Name,Age) VALUES (1,&apos;tom&apos;,12);    //删除数据    $jdbc:phoenix&gt;delete from test.persion where idcardnum = 1 ;    //更新数据    //upsert into test.PERSON(IDCardNum , Name,Age) VALUES (1,&apos;tom&apos;,12);</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;hbase&quot;&gt;&lt;a href=&quot;#hbase&quot; class=&quot;headerlink&quot; title=&quot;hbase&quot;&gt;&lt;/a&gt;hbase&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;协处理器.
Observer            //触发器,基于事件激活的。
Endpoint 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="http://erichunn.github.io/2018/11/21/Flume/"/>
    <id>http://erichunn.github.io/2018/11/21/Flume/</id>
    <published>2018-11-21T13:41:16.000Z</published>
    <updated>2018-11-25T04:19:48.800Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h2><pre><code>NoSQL.面向列族。随机定位实时读写。分布式可伸缩HAzookeeper                        version(列族)rowkey/famil+qualifier/timestamp = valuerowkey        //唯一性,散列性,定长,不要太长,加盐.二次索引byte[]</code></pre><h2 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h2><pre><code>离线计算。</code></pre><h2 id="MR-MapReduce"><a href="#MR-MapReduce" class="headerlink" title="MR:MapReduce"></a>MR:MapReduce</h2><pre><code>hadoop : DBWritable + WritableComparable :</code></pre><h2 id="将hbase的表影射到hive上，使用hive的查询语句。"><a href="#将hbase的表影射到hive上，使用hive的查询语句。" class="headerlink" title="将hbase的表影射到hive上，使用hive的查询语句。"></a>将hbase的表影射到hive上，使用hive的查询语句。</h2><pre><code>CREATE TABLE mydb.t11(key string, name string) STORED BY &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,cf:name&quot;)TBLPROPERTIES(&quot;hbase.table.name&quot; = &quot;ns1:t11&quot;);    select count(*) from mydb.t11 ;</code></pre><h2 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h2><pre><code>收集、移动、聚合大量日志数据的服务。基于流数据的架构，用于在线日志分析。基于事件。在生产和消费者之间启动协调作用。提供了事务保证，确保消息一定被分发。Source 多种sink多种.multihop        //多级跃点.可以从一个flume到另外一个flume水平扩展:        //加节点，竖直扩展        //增加硬件。</code></pre><h2 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h2><pre><code>接受数据，类型有多种。</code></pre><h2 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h2><pre><code>临时存放地，对Source中来的数据进行缓冲，直到sink消费掉。</code></pre><h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><pre><code>从channel提取数据存放到中央化存储(hadoop / hbase)。</code></pre><p><img src="https://i.imgur.com/DbIixF1.png" alt=""></p><p>实时产生的数据，</p><p>Flume的优点<br>以下是使用Flume的优点：<br>使用Apache Flume，我们可以将数据存储到任何集中存储中<br>（HBase，HDFS）。<br>当传入数据的速率超过可以写入数据的速率时<br>目的地，Flume充当数据生产者和数据生成者之间的中介<br>集中存储并在它们之间提供稳定的数据流。<br>Flume提供了上下文路由的功能。</p><ol><li>FLUME - 介绍App Flume<br>2<br>Flume中的交易是基于渠道的，其中两个交易（一个发件人<br>为每条消息维护一个接收器。它保证了可靠的信息<br>交货。<br>Flume具有可靠性，容错性，可扩展性，可管理性和可定制性。<br>水槽的特点<br>Flume的一些显着特征如下：<br>Flume将来自多个Web服务器的日志数据提取到集中存储（HDFS，<br>HBase）有效。<br>使用Flume，我们可以立即将来自多个服务器的数据导入Hadoop。<br>与日志文件一起，Flume还用于导入大量事件数据<br>由Facebook和Twitter等社交网站和电子商务制作<br>亚马逊和Flipkart等网站。<br>Flume支持大量源和目标类型。<br>Flume支持多跳流，扇入扇出流，上下文路由等。<br>水槽可以水平缩放</li></ol><h2 id="安装flume"><a href="#安装flume" class="headerlink" title="安装flume"></a>安装flume</h2><pre><code>1.下载2.tar3.环境变量4.验证flume是否成功      $&gt;flume-ng version            //next generation.下一代.</code></pre><h2 id="配置flume"><a href="#配置flume" class="headerlink" title="配置flume"></a>配置flume</h2><pre><code>1.创建配置文件[/soft/flume/conf/hello.conf]#声明三种组件a1.sources = r1a1.channels = c1a1.sinks = k1#定义source信息a1.sources.r1.type=netcata1.sources.r1.bind=localhosta1.sources.r1.port=8888#定义sink信息a1.sinks.k1.type=logger#定义channel信息a1.channels.c1.type=memory#绑定在一起a1.sources.r1.channels=c1a1.sinks.k1.channel=c12.运行    a)启动flume agent        $&gt;bin/flume-ng agent -f ../conf/helloworld.conf -n a1 -Dflume.root.logger=INFO,console    b)启动nc的客户端        $&gt;nc localhost 8888        $nc&gt;hello world    c)在flume的终端输出hello world.</code></pre><h2 id="安装nc"><a href="#安装nc" class="headerlink" title="安装nc"></a>安装nc</h2><pre><code>$&gt;sudo yum install nmap-ncat.x86_64</code></pre><h2 id="清除仓库缓存"><a href="#清除仓库缓存" class="headerlink" title="清除仓库缓存"></a>清除仓库缓存</h2><pre><code>$&gt;修改ali.repo --&gt; ali.repo.bak文件。$&gt;sudo yum clean all$&gt;sudo yum makecache#例如阿里基本源 $&gt;sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #阿里epel源$&gt;sudo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo</code></pre><h2 id="flume-source"><a href="#flume-source" class="headerlink" title="flume source"></a>flume source</h2><pre><code>1.netcat    nc ..2.exec    实时日志收集,实时收集日志。    a1.sources = r1    a1.sinks = k1    a1.channels = c1    a1.sources.r1.type=exec    a1.sources.r1.command=tail -F /home/centos/test.txt    a1.sinks.k1.type=logger    a1.channels.c1.type=memory    a1.sources.r1.channels=c1    a1.sinks.k1.channel=c13.批量收集    监控一个文件夹，静态文件。    收集完之后，会重命名文件成新文件。.compeleted.    a)配置文件        [spooldir_r.conf]        a1.sources = r1        a1.channels = c1        a1.sinks = k1        a1.sources.r1.type=spooldir        a1.sources.r1.spoolDir=/home/centos/spool        a1.sources.r1.fileHeader=true        a1.sinks.k1.type=logger        a1.channels.c1.type=memory        a1.sources.r1.channels=c1        a1.sinks.k1.channel=c1    b)创建目录        $&gt;mkdir ~/spool    c)启动flume        $&gt;bin/flume-ng agent -f ../conf/helloworld.conf -n a1 -Dflume.root.logger=INFO,console4.序列source    [seq]    a1.sources = r1    a1.channels = c1    a1.sinks = k1    a1.sources.r1.type=seq    a1.sources.r1.totalEvents=1000    a1.sinks.k1.type=logger    a1.channels.c1.type=memory    a1.sources.r1.channels=c1    a1.sinks.k1.channel=c1    [运行]    $&gt;bin/flume-ng agent -f ../conf/helloworld.conf -n a1 -Dflume.root.logger=INFO,console5.StressSource    a1.sources = stresssource-1    a1.channels = memoryChannel-1    a1.sources.stresssource-1.type = org.apache.flume.source.StressSource    a1.sources.stresssource-1.size = 10240    a1.sources.stresssource-1.maxTotalEvents = 1000000    a1.sources.stresssource-1.channels = memoryChannel-1</code></pre><h2 id="flume-sink"><a href="#flume-sink" class="headerlink" title="flume sink"></a>flume sink</h2><pre><code>1.hdfs    a1.sources = r1    a1.channels = c1    a1.sinks = k1    a1.sources.r1.type = netcat    a1.sources.r1.bind = localhost    a1.sources.r1.port = 8888    a1.sinks.k1.type = hdfs    a1.sinks.k1.hdfs.path = /flume/events/%y-%m-%d/%H/%M/%S    a1.sinks.k1.hdfs.filePrefix = events-    #是否是产生新目录,每十分钟产生一个新目录,一般控制的目录方面。round是决定是否产生新文件的，滚动是决定是否产生新文件的。    #2017-12-12 --&gt;    #2017-12-12 --&gt;%H%M%S    a1.sinks.k1.hdfs.round = true                a1.sinks.k1.hdfs.roundValue = 10    a1.sinks.k1.hdfs.roundUnit = second    a1.sinks.k1.hdfs.useLocalTimeStamp=true    #是否产生新文件。    a1.sinks.k1.hdfs.rollInterval=10    a1.sinks.k1.hdfs.rollSize=10    a1.sinks.k1.hdfs.rollCount=3    a1.channels.c1.type=memory    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c12.hive    略3.hbase    a1.sources = r1    a1.channels = c1    a1.sinks = k1    a1.sources.r1.type = netcat    a1.sources.r1.bind = localhost    a1.sources.r1.port = 8888    a1.sinks.k1.type = hbase    a1.sinks.k1.table = ns1:t12    a1.sinks.k1.columnFamily = f1    a1.sinks.k1.serializer = org.apache.flume.sink.hbase.RegexHbaseEventSerializer    a1.channels.c1.type=memory    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c14.kafka</code></pre><p>数据进入到源里面去，最终进入通道里面，有很多通道c1,c2,c3，这个取决于通道选择器，ChannelProcessor，对事件进行处理，先经过一堆拦截器也是有很多种 。拦截器在各个文件前加东西，拦截之后再回到选择器。拦截器是典型的批处理，把加到东西流水线似的加到头文件里面。不管是什么对象，通过什么source进来的，都被转换成envent对象。在拦截器这个地方是链式技术。把事件放到通道里面，每个通道放置事件都是一个事务，保证能成功，</p><p>这个图是source到通道的图<br><img src="https://i.imgur.com/bzQZ9yK.png" alt=""></p><p>sink的图：</p><p><img src="https://i.imgur.com/sb3F2lg.png" alt=""></p><h2 id="使用avroSource和AvroSink实现跃点agent处理"><a href="#使用avroSource和AvroSink实现跃点agent处理" class="headerlink" title="使用avroSource和AvroSink实现跃点agent处理"></a>使用avroSource和AvroSink实现跃点agent处理</h2><pre><code>1.创建配置文件    [avro_hop.conf]    #a1    a1.sources = r1    a1.sinks= k1    a1.channels = c1    a1.sources.r1.type=netcat    a1.sources.r1.bind=localhost    a1.sources.r1.port=8888    a1.sinks.k1.type = avro    a1.sinks.k1.hostname=localhost    a1.sinks.k1.port=9999    a1.channels.c1.type=memory    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c1    #a2    a2.sources = r2    a2.sinks= k2    a2.channels = c2    a2.sources.r2.type=avro    a2.sources.r2.bind=localhost    a2.sources.r2.port=9999    a2.sinks.k2.type = logger    a2.channels.c2.type=memory    a2.sources.r2.channels = c2    a2.sinks.k2.channel = c22.启动a2    $&gt;flume-ng agent -f /soft/flume/conf/avro_hop.conf -n a2 -Dflume.root.logger=INFO,console3.验证a2    $&gt;netstat -anop | grep 99994.启动a1    $&gt;flume-ng agent -f /soft/flume/conf/avro_hop.conf -n a15.验证a1    $&gt;netstat -anop | grep 8888</code></pre><h2 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h2><pre><code>1.MemoryChannel    略2.FileChannel</code></pre><p>a1.sources = r1<br>a1.sinks= k1<br>a1.channels = c1</p><p>a1.sources.r1.type=netcat<br>a1.sources.r1.bind=localhost<br>a1.sources.r1.port=8888</p><p>a1.sinks.k1.type=logger</p><pre><code>a1.channels.c1.type = filea1.channels.c1.checkpointDir = /home/centos/flume/fc_checka1.channels.c1.dataDirs = /home/centos/flume/fc_data</code></pre><p>a1.sources.r1.channels=c1<br>a1.sinks.k1.channel=c1</p><h2 id="可溢出文件通道"><a href="#可溢出文件通道" class="headerlink" title="可溢出文件通道"></a>可溢出文件通道</h2><p>a1.channels = c1<br>a1.channels.c1.type = SPILLABLEMEMORY</p><p>#0表示禁用内存通道，等价于文件通道<br>a1.channels.c1.memoryCapacity = 0</p><p>#0,禁用文件通道，等价内存通道。<br>a1.channels.c1.overflowCapacity = 2000</p><p>a1.channels.c1.byteCapacity = 800000<br>a1.channels.c1.checkpointDir = /user/centos/flume/fc_check<br>a1.channels.c1.dataDirs = /user/centos/flume/fc_data</p><h2 id="创建Flume模块"><a href="#创建Flume模块" class="headerlink" title="创建Flume模块"></a>创建Flume模块</h2><pre><code>1.添加pom.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;FluemDemo&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.apache.flume&lt;/groupId&gt;                &lt;artifactId&gt;flume-ng-core&lt;/artifactId&gt;                &lt;version&gt;1.7.0&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;junit&lt;/groupId&gt;                &lt;artifactId&gt;junit&lt;/artifactId&gt;                &lt;version&gt;4.11&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;hbase&quot;&gt;&lt;a href=&quot;#hbase&quot; class=&quot;headerlink&quot; title=&quot;hbase&quot;&gt;&lt;/a&gt;hbase&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;NoSQL.
面向列族。
随机定位
实时读写。
分布式
可伸缩
HA
zookeeper
     
      
    
    </summary>
    
    
      <category term="flume" scheme="http://erichunn.github.io/tags/flume/"/>
    
      <category term="source" scheme="http://erichunn.github.io/tags/source/"/>
    
      <category term="sink" scheme="http://erichunn.github.io/tags/sink/"/>
    
      <category term="channel" scheme="http://erichunn.github.io/tags/channel/"/>
    
      <category term="安装flume" scheme="http://erichunn.github.io/tags/%E5%AE%89%E8%A3%85flume/"/>
    
      <category term="avro跃点" scheme="http://erichunn.github.io/tags/avro%E8%B7%83%E7%82%B9/"/>
    
  </entry>
  
  <entry>
    <title>面试理论知识</title>
    <link href="http://erichunn.github.io/2018/11/21/%E9%9D%A2%E8%AF%95%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86/"/>
    <id>http://erichunn.github.io/2018/11/21/面试理论知识/</id>
    <published>2018-11-21T13:27:01.000Z</published>
    <updated>2018-11-21T13:39:15.175Z</updated>
    
    <content type="html"><![CDATA[<p>flume：<br>Apache Flume是一种工具/服务/数据提取机制，用于收集聚合和<br>从各种传输大量的流数据，如日志文件，事件（等等）<br>源集中数据存储。</p><p>Flume是一种高度可靠，分布式和可配置的工具。 它主要是为了设计的<br>将流数据（日志数据）从各种Web服务器复制到HDFS。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;flume：&lt;br&gt;Apache Flume是一种工具/服务/数据提取机制，用于收集聚合和&lt;br&gt;从各种传输大量的流数据，如日志文件，事件（等等）&lt;br&gt;源集中数据存储。&lt;/p&gt;
&lt;p&gt;Flume是一种高度可靠，分布式和可配置的工具。 它主要是为了设计的&lt;br&gt;将流数据（日
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>SSM第一天</title>
    <link href="http://erichunn.github.io/2018/11/19/SSM%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2018/11/19/SSM第一天/</id>
    <published>2018-11-19T14:35:23.000Z</published>
    <updated>2018-11-27T08:19:13.920Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SSM第二天"><a href="#SSM第二天" class="headerlink" title="SSM第二天"></a>SSM第二天</h1><p>三大框架的整合：</p><p>数据库层：<br>mybatis数据持久化层：dao在交互mybatis<br>dao:数据访问层：数据访问对象，存放简单的增删改查。每个表都有这个业务<br>service层：业务层，和dao交互，对dao的方法进行组合调用。形成套餐<br>springmvc展现层：做网页，做web开发的，springmvc应该和业务层交互，在springmvc里面的controller层和业务层交互，展现的东西就是jsp做web开发做网站的，做web应用的。通过web架构来实现。springmvc就是web架构里面的一个。</p><p><img src="https://i.imgur.com/ygpfvcz.png" alt=""></p><h1 id="Mybais和数据库整合"><a href="#Mybais和数据库整合" class="headerlink" title="Mybais和数据库整合"></a>Mybais和数据库整合</h1><p><img src="https://i.imgur.com/M8K3Sqr.png" alt=""></p><p>1.在pom中添加依赖：</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;    &lt;artifactId&gt;SpringmybatisDemo&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.11&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;            &lt;version&gt;3.4.6&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;5.1.17&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.mchange&lt;/groupId&gt;            &lt;artifactId&gt;c3p0&lt;/artifactId&gt;            &lt;version&gt;0.9.5.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;            &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;            &lt;version&gt;4.3.3.RElEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;            &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;            &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;            &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;            &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;        &lt;groupId&gt;org.mybatis&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;        &lt;version&gt;1.1.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><p>2.创建包</p><pre><code>com.it18zhang.springmybatis.daocom.it18zhang.springmybatis.servicecom.it18zhang.springmybatis.utils</code></pre><p>3.配置beans.xml在source下</p><hr><p>坑爹的错误：</p><p><img src="https://i.imgur.com/pu7CMME.png" alt=""></p><p>在上图的情下，看见下面的mybtis-spring是依赖于mybatis3.1.0，而上面有一个跟他一模一样的包，所以到下面这块，下面的这个版本的包就看不出来了。所以如果有的类仅仅是在下面这个版本下才有的，需要把上面的第一个包先删除掉。因为它只显示第一个依赖的包</p><h2 id="复杂应用"><a href="#复杂应用" class="headerlink" title="复杂应用"></a>复杂应用</h2><pre><code>1.准备数据    sql.sql2.创建java类.    [Order.java]    public class Order {        private Integer id ;        private String orderNo ;        //简历关联关系        private User user ;        //get/set    }    [Item.java]    public class Item {        private Integer id;        private String itemName;        //订单项和订单之间的关联关系        private Order order;        //get/set    }3.创建Order映射文件    [resource/OrderMapper.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;    &lt;!DOCTYPE mapper            PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;            &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;    &lt;mapper namespace=&quot;orders&quot;&gt;        &lt;insert id=&quot;insert&quot;&gt;          insert into orders(orderno,uid) values(#{orderNo},#{user.id})        &lt;/insert&gt;        &lt;!-- findById --&gt;        &lt;select id=&quot;selectOne&quot; parameterType=&quot;int&quot; resultMap=&quot;RM_Order&quot;&gt;          select            o.id oid ,            o.orderno oorderno ,            o.uid uid ,            u.name uname ,            u.age uage          from orders o            left outer join users u on o.uid = u.id where o.id = #{id}        &lt;/select&gt;        &lt;!-- findAll --&gt;        &lt;select id=&quot;selectAll&quot; resultMap=&quot;RM_Order&quot;&gt;          select            o.id oid ,            o.orderno oorderno ,            o.uid uid ,            u.name uname ,            u.age uage          from orders o            left outer join users u on o.uid = u.id        &lt;/select&gt;        &lt;!-- 自定义结果映射 --&gt;        &lt;resultMap id=&quot;RM_Order&quot; type=&quot;com.it18zhang.mybatisdemo.domain.Order&quot;&gt;            &lt;id property=&quot;id&quot; column=&quot;oid&quot;/&gt;            &lt;result property=&quot;orderNo&quot; column=&quot;oorderno&quot;/&gt;            &lt;association property=&quot;user&quot; javaType=&quot;com.it18zhang.mybatisdemo.domain.User&quot;&gt;                &lt;id property=&quot;id&quot; column=&quot;uid&quot; /&gt;                &lt;result property=&quot;name&quot; column=&quot;uname&quot; /&gt;                &lt;result property=&quot;age&quot; column=&quot;uage&quot; /&gt;            &lt;/association&gt;        &lt;/resultMap&gt;    &lt;/mapper&gt;4.修改配置文件,添加映射。    [resource/mybatis-config.xml]    &lt;!-- 引入映射文件 --&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;*Mapper.xml&quot;/&gt;    &lt;/mappers&gt;5.测试类    public class TestOrder {        /**         * insert         */        @Test        public void insert() throws Exception {            String resource = &quot;mybatis-config.xml&quot;;            InputStream inputStream = Resources.getResourceAsStream(resource);            SqlSessionFactory sf = new SqlSessionFactoryBuilder().build(inputStream);            SqlSession s = sf.openSession();            User u = new User();            u.setId(2);            Order o = new Order();            o.setOrderNo(&quot;No005&quot;);            o.setUser(u);            s.insert(&quot;orders.insert&quot;,o);            s.commit();            s.close();        }        @Test        public void selectOne() throws Exception {            String resource = &quot;mybatis-config.xml&quot;;            InputStream inputStream = Resources.getResourceAsStream(resource);            SqlSessionFactory sf = new SqlSessionFactoryBuilder().build(inputStream);            SqlSession s = sf.openSession();            Order order = s.selectOne(&quot;orders.selectOne&quot;,1);            System.out.println(order.getOrderNo());            s.commit();            s.close();        }        @Test        public void selectAll() throws Exception {            String resource = &quot;mybatis-config.xml&quot;;            InputStream inputStream = Resources.getResourceAsStream(resource);            SqlSessionFactory sf = new SqlSessionFactoryBuilder().build(inputStream);            SqlSession s = sf.openSession();            List&lt;Order&gt; list = s.selectList(&quot;orders.selectAll&quot;);            for(Order o : list){                System.out.println(o.getOrderNo() + &quot; : &quot; + o.getUser().getName());            }            s.commit();            s.close();        }    }</code></pre><h2 id="配置一对多"><a href="#配置一对多" class="headerlink" title="配置一对多"></a>配置一对多</h2><pre><code>1.在User中增加orders集合。    public class User {        ...        private List&lt;Order&gt; orders ;        //get/set    }2.改造UserMapper.xml</code></pre><h2 id="组合多对一和一对多关联关系到一个实体-Order-中"><a href="#组合多对一和一对多关联关系到一个实体-Order-中" class="headerlink" title="组合多对一和一对多关联关系到一个实体(Order)中"></a>组合多对一和一对多关联关系到一个实体(Order)中</h2><pre><code>1.关系    Order(*) -&gt; (1)User    Order(1) -&gt; (*)Item2.Order.java    class Order{        ...        List&lt;Item&gt; items ;        //get/set        }2&apos;.修改配置文件增加别名    [resources/mybatis-config.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;    &lt;!DOCTYPE configuration            PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;            &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;    &lt;configuration&gt;        &lt;typeAliases&gt;            &lt;typeAlias type=&quot;com.it18zhang.mybatisdemo.domain.User&quot; alias=&quot;_User&quot;/&gt;            &lt;typeAlias type=&quot;com.it18zhang.mybatisdemo.domain.Order&quot; alias=&quot;_Order&quot;/&gt;            &lt;typeAlias type=&quot;com.it18zhang.mybatisdemo.domain.Item&quot; alias=&quot;_Item&quot;/&gt;        &lt;/typeAliases&gt;        &lt;environments default=&quot;development&quot;&gt;            &lt;environment id=&quot;development&quot;&gt;                &lt;transactionManager type=&quot;JDBC&quot;/&gt;                &lt;dataSource type=&quot;POOLED&quot;&gt;                    &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;                    &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt;                    &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                    &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;                &lt;/dataSource&gt;            &lt;/environment&gt;        &lt;/environments&gt;        &lt;!-- 引入映射文件 --&gt;        &lt;mappers&gt;            &lt;mapper resource=&quot;UserMapper.xml&quot;/&gt;            &lt;mapper resource=&quot;OrderMapper.xml&quot;/&gt;        &lt;/mappers&gt;    &lt;/configuration&gt;3.OrderMapper.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;    &lt;!DOCTYPE mapper            PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;            &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;    &lt;mapper namespace=&quot;orders&quot;&gt;        &lt;insert id=&quot;insert&quot;&gt;          insert into orders(orderno,uid) values(#{orderNo},#{user.id})        &lt;/insert&gt;        &lt;!-- findById --&gt;        &lt;select id=&quot;selectOne&quot; parameterType=&quot;int&quot; resultMap=&quot;RM_Order&quot;&gt;          select            o.id      oid ,            o.orderno oorderno ,            o.uid     uid ,            u.name    uname ,            u.age     uage ,            i.id      iid,            i.itemname iitemname          from orders o            left outer join users u on o.uid = u.id            left outer join items i on o.id = i.oid          where o.id = #{id}        &lt;/select&gt;        &lt;!-- findAll --&gt;        &lt;select id=&quot;selectAll&quot; resultMap=&quot;RM_Order&quot;&gt;          select            o.id      oid ,            o.orderno oorderno ,            o.uid     uid ,            u.name    uname ,            u.age     uage ,            i.id      iid,            i.itemname iitemname          from orders o            left outer join users u on o.uid = u.id            left outer join items i on o.id = i.oid        &lt;/select&gt;        &lt;!-- 自定义结果映射 --&gt;        &lt;resultMap id=&quot;RM_Order&quot; type=&quot;com.it18zhang.mybatisdemo.domain.Order&quot;&gt;            &lt;id property=&quot;id&quot; column=&quot;oid&quot;/&gt;            &lt;result property=&quot;orderNo&quot; column=&quot;oorderno&quot;/&gt;            &lt;association property=&quot;user&quot; javaType=&quot;com.it18zhang.mybatisdemo.domain.User&quot;&gt;                &lt;id property=&quot;id&quot; column=&quot;uid&quot; /&gt;                &lt;result property=&quot;name&quot; column=&quot;uname&quot; /&gt;                &lt;result property=&quot;age&quot; column=&quot;uage&quot; /&gt;            &lt;/association&gt;            &lt;collection property=&quot;items&quot; ofType=&quot;_Item&quot;&gt;                &lt;id property=&quot;id&quot; column=&quot;iid&quot; /&gt;                &lt;result property=&quot;itemName&quot; column=&quot;iitemname&quot; /&gt;            &lt;/collection&gt;        &lt;/resultMap&gt;    &lt;/mapper&gt;4.测试    @Test    public void selectOne() throws Exception {        String resource = &quot;mybatis-config.xml&quot;;        InputStream inputStream = Resources.getResourceAsStream(resource);        SqlSessionFactory sf = new SqlSessionFactoryBuilder().build(inputStream);        SqlSession s = sf.openSession();        Order order = s.selectOne(&quot;orders.selectOne&quot;,1);        System.out.println(order.getOrderNo() + order.getUser().getName());        for(Item i : order.getItems()){            System.out.println(i.getId() + &quot;:&quot; + i.getItemName());        }        s.commit();        s.close();    }</code></pre><h2 id="改造项目"><a href="#改造项目" class="headerlink" title="改造项目"></a>改造项目</h2><pre><code>1.引入Util类    package com.it18zhang.mybatisdemo.util;    import org.apache.ibatis.io.Resources;    import org.apache.ibatis.session.SqlSession;    import org.apache.ibatis.session.SqlSessionFactory;    import org.apache.ibatis.session.SqlSessionFactoryBuilder;    import java.io.InputStream;    /**     * 工具类     */    public class Util {        //        private static SqlSessionFactory sf ;        static{            try {                String resource = &quot;mybatis-config.xml&quot;;                InputStream inputStream = Resources.getResourceAsStream(resource);                sf = new SqlSessionFactoryBuilder().build(inputStream);            } catch (Exception e) {                e.printStackTrace();            }        }        /**         * 开启会话         */        public static SqlSession openSession(){            return sf.openSession() ;        }        /**         * 关闭会话         */        public static void closeSession(SqlSession s){            if(s != null){                s.close();            }        }        /**         * 关闭会话         */        public static void rollbackTx(SqlSession s) {            if (s != null) {                s.rollback();            }        }    }2.设计模板类DaoTemplate和回调MybatisCallback接口    [DaoTemplate.java]    package com.it18zhang.mybatisdemo.dao;    import com.it18zhang.mybatisdemo.util.Util;    import org.apache.ibatis.session.SqlSession;    /**     * 模板类     */    public class DaoTemplate {        /**         * 执行         */        public static Object execute(MybatisCallback cb){            SqlSession s = null;            try {                s = Util.openSession();                Object ret = cb.doInMybatis(s);                s.commit();                return ret ;            } catch (Exception e) {                Util.rollbackTx(s);            } finally {                Util.closeSession(s);            }            return null ;        }    }    [MybatisCallback.java]    package com.it18zhang.mybatisdemo.dao;    import org.apache.ibatis.session.SqlSession;    /**     * 回调接口     */    public interface MybatisCallback {        public Object doInMybatis(SqlSession s);    }3.通过模板类+回调接口实现UserDao.java    [UserDao.java]    package com.it18zhang.mybatisdemo.dao;    import com.it18zhang.mybatisdemo.domain.User;    import com.it18zhang.mybatisdemo.util.Util;    import org.apache.ibatis.session.SqlSession;    import java.util.List;    /**     * UserDao     */    public class UserDao {        /**         * 插入操作         */        public void insert(final User user){            DaoTemplate.execute(new MybatisCallback() {                public Object doInMybatis(SqlSession s) {                    s.insert(&quot;users.insert&quot;,user);                    return null ;                }            });        }        /**         * 插入操作         */        public void update(final User user){            DaoTemplate.execute(new MybatisCallback() {                public Object doInMybatis(SqlSession s) {                    s.update(&quot;users.update&quot;, user);                    return null ;                }            });        }        public User selctOne(final Integer id){            return (User)DaoTemplate.execute(new MybatisCallback() {                public Object doInMybatis(SqlSession s) {                    return s.selectOne(&quot;users.selectOne&quot;,id);                }            });        }        public List&lt;User&gt; selctAll(){            return (List&lt;User&gt;)DaoTemplate.execute(new MybatisCallback() {                public Object doInMybatis(SqlSession s) {                    return s.selectList(&quot;users.selectAll&quot;);                }            });        }    }4.App测试    public static void main(String[] args) {        UserDao dao = new UserDao();        User u = dao.selctOne(1);        System.out.println(u.getName());    }</code></pre><hr><p>回调接口的一个画图分析：<br><img src="https://i.imgur.com/DufbOjZ.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SSM第二天&quot;&gt;&lt;a href=&quot;#SSM第二天&quot; class=&quot;headerlink&quot; title=&quot;SSM第二天&quot;&gt;&lt;/a&gt;SSM第二天&lt;/h1&gt;&lt;p&gt;三大框架的整合：&lt;/p&gt;
&lt;p&gt;数据库层：&lt;br&gt;mybatis数据持久化层：dao在交互mybatis&lt;b
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2018/11/19/Hbase%E7%AC%AC%E4%B8%89%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2018/11/19/Hbase第三天/</id>
    <published>2018-11-19T08:56:58.974Z</published>
    <updated>2019-01-16T07:22:41.866Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: Hbase第三天<br>tags:</p><ul><li>null<br>categories:</li><li>null<br>date: 2018-11-19 16:56:58<br>description:</li></ul><hr><h1 id="复习Hbase第二天"><a href="#复习Hbase第二天" class="headerlink" title="复习Hbase第二天"></a>复习Hbase第二天</h1><p>随机定位+实时读写</p><p>nosql:not only sql数据库</p><p>key-value对形式的存储</p><p>key: rowkey/family+col/timstamp = value</p><p>rowkey  排序,byte[]</p><p>客户端先联系zk找到元数据表hbae:meta，存放了整个数据库的表和区域服务器信息，相当于目录，类似于名称节点。当找到了之后就可以定位到区域服务器，所以hbase数据读写和HRegionServer来交互，有很多regionServer构成了一个集群。数据先进入到写前日志，写前日志用于容错，用于恢复，所以在交互的时候client先交互HRegionServer然后在网Hlog里写入数据，然后在溢出之后写入HRegion，对于HRegion来说有个内存储MemStore在内存中存储数据，用来提高速度，MemStore达到一定值溢出到磁盘，所以还有一个StoreFile存储，用来和底层交互，底层就是Hfile。通过Hfile对象来跟HDFS交互，就找到了HDFS客户端DFSClient了，这个DFSClient就是hdfs范畴了，最终数据存储到HDFS里面了。</p><p>表的切割指的是切割表或者切割区域，按照rowkey来切分，因为rowkey是有序的，相当于建立索引，通过切割可以实现负载均衡，如果所有东西都在一个点就会出现热点问题。</p><p>hbase的增删改查是：<br>    put(rowkey).addColumn().<br>    put(Put)</p><pre><code>deleteget()更新也是putscan()</code></pre><p>merge合并。</p><p>移动区域，目的减少某一个服务器的压力。可以任意配置区域所在地，由那个区域服务器承载。</p><p>切割风暴：达到10G之后同时到达临界点，同时切割，为了避免可以让这个10G的值变大再切割，也就是不让他自动切割了。可以手动切割避免。或者预切割来处理。 </p><p>hbase存储的荣誉量比较大，因为它存储的时候都是以kv的方式来存储，而key是三极坐标，rowkey，列，列族，时间戳+一个value，所以前三个值都要存放很多次。所以要求列族和列的名称和rowkey的名字不能太长。一旦过长，就会发现存储的时候被坐标占用了大量的空间，而value的很少，最好列和列族名字不要太长。</p><p>本天会涉及rowkey的设计问题。</p><h1 id="预先切割"><a href="#预先切割" class="headerlink" title="预先切割"></a>预先切割</h1><p>创建表时可以预先对表进行切割。</p><p>切割线就是rowkey</p><p> create ‘ns1:t2’,’f1’,SPLITES=&gt;[‘row3000’,’row6000]</p><h2 id="预先切割-1"><a href="#预先切割-1" class="headerlink" title="预先切割"></a>预先切割</h2><pre><code>创建表时，预先对表进行切割。切割线是rowkey.$hbase&gt;create &apos;ns1:t2&apos;,&apos;f1&apos;,SPLITS=&gt;[&apos;row3000&apos;,&apos;row6000&apos;]</code></pre><h2 id="创建表时指定列族的版本数-该列族的所有列都具有相同数量版本"><a href="#创建表时指定列族的版本数-该列族的所有列都具有相同数量版本" class="headerlink" title="创建表时指定列族的版本数,该列族的所有列都具有相同数量版本"></a>创建表时指定列族的版本数,该列族的所有列都具有相同数量版本</h2><pre><code>$hbase&gt;create &apos;ns1:t3&apos;,{NAME=&gt;&apos;f1&apos;,VERSIONS=&gt;3}            //创建表时，指定列族的版本数。$hbase&gt;get &apos;ns1:t3&apos;,&apos;row1&apos;,{COLUMN=&gt;&apos;f1&apos;,VERSIONS=&gt;4}    //检索的时候，查询多少个版本。$hbase&gt;put &apos;ns1:t3&apos;,&apos;row1&apos;,&apos;f1:name&apos;,&apos;tom&apos;</code></pre><p>关于查询的命令行：</p><p><img src="https://i.imgur.com/Qq9LDyE.png" alt=""></p><p>关于创建表的命令：</p><p><img src="https://i.imgur.com/r9yKelH.png" alt=""></p><pre><code>@Testpublic void getWithVersions() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t3&quot;);    Table table = conn.getTable(tname);    Get get = new Get(Bytes.toBytes(&quot;row1&quot;));    //检索所有版本    get.setMaxVersions();    Result r = table.get(get);    List&lt;Cell&gt; cells = r.getColumnCells(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;name&quot;));    for(Cell c : cells){        String f = Bytes.toString(c.getFamily());        String col = Bytes.toString(c.getQualifier());        long ts = c.getTimestamp();        String val = Bytes.toString(c.getValue());        System.out.println(f + &quot;/&quot; + col + &quot;/&quot; + ts + &quot;=&quot; + val);    }}</code></pre><h1 id="原生扫描-专家"><a href="#原生扫描-专家" class="headerlink" title="原生扫描(专家)"></a>原生扫描(专家)</h1><h2 id="1-原生扫描"><a href="#1-原生扫描" class="headerlink" title="1.原生扫描"></a>1.原生扫描</h2><pre><code>$hbase&gt;scan &apos;ns1:t3&apos;,{COLUMN=&gt;&apos;f1&apos;,RAW=&gt;true,VERSIONS=&gt;10}        //包含标记了delete的数据</code></pre><h2 id="2-删除数据"><a href="#2-删除数据" class="headerlink" title="2.删除数据"></a>2.删除数据</h2><pre><code>$hbase&gt;delete &apos;nd1:t3&apos;,&apos;row1&apos;,&apos;f1:name&apos;,148989875645            //删除数据，标记为删除.                                                                //小于该删除时间的数据都作废。</code></pre><h2 id="3-TTL"><a href="#3-TTL" class="headerlink" title="3.TTL"></a>3.TTL</h2><pre><code>time to live ,存活时间。影响所有的数据，包括没有删除的数据。超过该时间，原生扫描也扫不到数据。$hbase&gt;create &apos;ns1:tx&apos; , {NAME=&gt;&apos;f1&apos;,TTL=&gt;10,VERSIONS}</code></pre><h2 id="4-KEEP-DELETED-CELLS"><a href="#4-KEEP-DELETED-CELLS" class="headerlink" title="4.KEEP_DELETED_CELLS"></a>4.KEEP_DELETED_CELLS</h2><pre><code>删除key之后，数据是否还保留。$hbase&gt;create &apos;ns1:tx&apos; , {NAME=&gt;&apos;f1&apos;,TTL=&gt;10,VERSIONS,KEEP_DELETED_CELLS=&gt;true}</code></pre><p><img src="https://i.imgur.com/2WE38AX.png" alt=""></p><h1 id="缓存和批处理"><a href="#缓存和批处理" class="headerlink" title="缓存和批处理"></a>缓存和批处理</h1><p><img src="https://i.imgur.com/U8uyqrS.png" alt=""></p><pre><code>1.开启服务器端扫描器缓存    a)表层面(全局)只需要配置一个属性即可        &lt;property&gt;            &lt;name&gt;hbase.client.scanner.caching&lt;/name&gt;            &lt;!-- 整数最大值 --&gt;            &lt;value&gt;2147483647&lt;/value&gt;            &lt;source&gt;hbase-default.xml&lt;/source&gt;        &lt;/property&gt;    b)操作层面        //设置量        scan.setCaching(10);2.3.cache row nums : 1000            //632cache row nums : 5000            //423cache row nums : 1                //7359</code></pre><h1 id="扫描器缓存"><a href="#扫描器缓存" class="headerlink" title="扫描器缓存"></a>扫描器缓存</h1><pre><code>面向行级别的。@Testpublic void getScanCache() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t1&quot;);    Scan scan = new Scan();    scan.setCaching(5000);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    long start = System.currentTimeMillis() ;    Iterator&lt;Result&gt; it = rs.iterator();    while(it.hasNext()){        Result r = it.next();        System.out.println(r.getColumnLatestCell(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;name&quot;)));    }    System.out.println(System.currentTimeMillis() - start);}</code></pre><h1 id="批量扫描是面向列级别"><a href="#批量扫描是面向列级别" class="headerlink" title="批量扫描是面向列级别"></a>批量扫描是面向列级别</h1><p><img src="https://i.imgur.com/kzrUOiK.png" alt=""></p><pre><code>控制每次next()服务器端返回的列的个数。scan.setBatch(5);                //每次next返回5列。</code></pre><h2 id="测试缓存和批处理"><a href="#测试缓存和批处理" class="headerlink" title="测试缓存和批处理"></a>测试缓存和批处理</h2><pre><code> */@Testpublic void testBatchAndCaching() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t7&quot;);    Scan scan = new Scan();    scan.setCaching(2);    scan.setBatch(3);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        System.out.println(&quot;========================================&quot;);        //得到一行的所有map,key=f1,value=Map&lt;Col,Map&lt;Timestamp,value&gt;&gt;        NavigableMap&lt;byte[], NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt;&gt; map = r.getMap();        //        for (Map.Entry&lt;byte[], NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt;&gt; entry : map.entrySet()) {            //得到列族            String f = Bytes.toString(entry.getKey());            Map&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt; colDataMap = entry.getValue();            for (Map.Entry&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt; ets : colDataMap.entrySet()) {                String c = Bytes.toString(ets.getKey());                Map&lt;Long, byte[]&gt; tsValueMap = ets.getValue();                for (Map.Entry&lt;Long, byte[]&gt; e : tsValueMap.entrySet()) {                    Long ts = e.getKey();                    String value = Bytes.toString(e.getValue());                    System.out.print(f + &quot;/&quot; + c + &quot;/&quot; + ts + &quot;=&quot; + value + &quot;,&quot;);                }            }        }        System.out.println();    }}</code></pre><p>先插入数据<br><img src="https://i.imgur.com/aRdSViP.png" alt=""></p><p><img src="https://i.imgur.com/jMwoiQ6.png" alt=""></p><p>代码运行结果：</p><p><img src="https://i.imgur.com/0RNQJci.png" alt=""></p><p>上面代码和上图对应的。设置2个cach和3个batch视频上说是2行3列，但是我觉得应该是2个列族3个列的这样子去输出。然后最后这一行还剩下2个输出2个，也就是3个输出，2个输出，3个输出，2个输出，。</p><p>========================================</p><h1 id="f1-id-1490595148588-1-f2-addr-1490595182150-hebei-f2-age-1490595174760-12"><a href="#f1-id-1490595148588-1-f2-addr-1490595182150-hebei-f2-age-1490595174760-12" class="headerlink" title="f1/id/1490595148588=1,f2/addr/1490595182150=hebei,f2/age/1490595174760=12,"></a>f1/id/1490595148588=1,f2/addr/1490595182150=hebei,f2/age/1490595174760=12,</h1><p>f2/id/1490595164473=1,f2/name/1490595169589=tom,</p><p>========================================</p><h1 id="f1-id-1490595196410-2-f1-name-1490595213090-tom2-1-f2-addr-1490595264734-tangshan"><a href="#f1-id-1490595196410-2-f1-name-1490595213090-tom2-1-f2-addr-1490595264734-tangshan" class="headerlink" title="f1/id/1490595196410=2,f1/name/1490595213090=tom2.1,f2/addr/1490595264734=tangshan,"></a>f1/id/1490595196410=2,f1/name/1490595213090=tom2.1,f2/addr/1490595264734=tangshan,</h1><p>f2/age/1490595253996=13,f2/id/1490595233568=2,f2/name/1490595241891=tom2.2,</p><p>========================================</p><h1 id="f1-age-1490595295427-14-f1-id-1490595281251-3-f1-name-1490595289587-tom3-1"><a href="#f1-age-1490595295427-14-f1-id-1490595281251-3-f1-name-1490595289587-tom3-1" class="headerlink" title="f1/age/1490595295427=14,f1/id/1490595281251=3,f1/name/1490595289587=tom3.1,"></a>f1/age/1490595295427=14,f1/id/1490595281251=3,f1/name/1490595289587=tom3.1,</h1><p>f2/addr/1490595343690=beijing,f2/age/1490595336300=14,f2/id/1490595310966=3,</p><p>========================================<br>f2/name/1490595327531=tom3.2,</p><h1 id="Filter过滤器"><a href="#Filter过滤器" class="headerlink" title="Filter过滤器"></a>Filter过滤器</h1><p><img src="https://i.imgur.com/9jcHOUJ.png" alt=""><br>远程服务器收到scan对象进行反序列化，恢复成scan对象进行过滤，对每个区域进行过滤，每个区域服务器有很多区域，每个区域里面有区域扫描器， RegionScanner，会使用区域过滤器。 </p><pre><code>1.RowFilter    select * from ns1:t1 where rowkey &lt;= row100/** /** * 测试RowFilter过滤器 */@Testpublic void testRowFilter() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t1&quot;);    Scan scan = new Scan();    RowFilter rowFilter = new RowFilter(CompareFilter.CompareOp.LESS_OR_EQUAL, new BinaryComparator(Bytes.toBytes(&quot;row0100&quot;)));    scan.setFilter(rowFilter);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        System.out.println(Bytes.toString(r.getRow()));    }}/** * 测试FamilyFilter过滤器 */@Testpublic void testFamilyFilter() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t7&quot;);    Scan scan = new Scan();    FamilyFilter filter = new FamilyFilter(CompareFilter.CompareOp.LESS, new BinaryComparator(Bytes.toBytes(&quot;f2&quot;)));    scan.setFilter(filter);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        byte[] f1id = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f2id = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;id&quot;));        System.out.println(f1id + &quot; : &quot; + f2id);    }}/** * 测试QualifierFilter(列过滤器) */@Testpublic void testColFilter() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t7&quot;);    Scan scan = new Scan();    QualifierFilter colfilter = new QualifierFilter(CompareFilter.CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(&quot;id&quot;)));    scan.setFilter(colfilter);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        byte[] f1id = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f2id = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f2name = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;name&quot;));        System.out.println(f1id + &quot; : &quot; + f2id + &quot; : &quot; + f2name);    }}/** * 测试ValueFilter(值过滤器) * 过滤value的值，含有指定的字符子串 */@Testpublic void testValueFilter() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t7&quot;);    Scan scan = new Scan();    ValueFilter filter = new ValueFilter(CompareFilter.CompareOp.EQUAL, new SubstringComparator(&quot;to&quot;));    scan.setFilter(filter);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        byte[] f1id = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f2id = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f1name = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;name&quot;));        byte[] f2name = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;name&quot;));        System.out.println(f1id + &quot; : &quot; + f2id + &quot; : &quot; + Bytes.toString(f1name) + &quot; : &quot; + Bytes.toString(f2name));    }}/** * 依赖列过滤器 */@Testpublic void testDepFilter() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t7&quot;);    Scan scan = new Scan();    DependentColumnFilter filter = new DependentColumnFilter(Bytes.toBytes(&quot;f2&quot;),            Bytes.toBytes(&quot;addr&quot;),            true,            CompareFilter.CompareOp.NOT_EQUAL,            new BinaryComparator(Bytes.toBytes(&quot;beijing&quot;))            );    //ValueFilter filter = new ValueFilter(CompareFilter.CompareOp.EQUAL, new SubstringComparator(&quot;to&quot;));    scan.setFilter(filter);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        byte[] f1id = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f2id = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f1name = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;name&quot;));        byte[] f2name = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;name&quot;));        System.out.println(f1id + &quot; : &quot; + f2id + &quot; : &quot; + Bytes.toString(f1name) + &quot; : &quot; + Bytes.toString(f2name));    }}/** * 单列值value过滤， *   */@Testpublic void testSingleColumValueFilter() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t7&quot;);    Scan scan = new Scan();    SingleColumnValueFilter filter = new SingleColumnValueFilter(Bytes.toBytes(&quot;f2&quot;,            Bytes.toBytes(&quot;name&quot;),            CompareFilter.CompareOp.NOT_EQUAL),            new BinaryComparator(Bytes.toBytes(&quot;tom2.1&quot;)));    //ValueFilter filter = new ValueFilter(CompareFilter.CompareOp.EQUAL, new SubstringComparator(&quot;to&quot;));    scan.setFilter(filter);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        byte[] f1id = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f2id = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f1name = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;name&quot;));        byte[] f2name = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;name&quot;));        System.out.println(f1id + &quot; : &quot; + f2id + &quot; : &quot; + Bytes.toString(f1name) + &quot; : &quot; + Bytes.toString(f2name));    }}</code></pre><h2 id="复杂查询"><a href="#复杂查询" class="headerlink" title="复杂查询"></a>复杂查询</h2><pre><code>select * from t7 where ((age &lt;= 13) and (name like &apos;%t&apos;)                                    or                        (age &gt; 13) and (name like &apos;t%&apos;))</code></pre><p><img src="https://i.imgur.com/Z5AcN4v.png" alt=""></p><p>指定列族，指定列，指定对比方式，指定值(小于用二进制比较，等于用正则表达式串对比器)</p><p><img src="https://i.imgur.com/6EGrJ4V.png" alt=""></p><h1 id="复杂查询实现方式-FilterList"><a href="#复杂查询实现方式-FilterList" class="headerlink" title="复杂查询实现方式:FilterList"></a>复杂查询实现方式:FilterList</h1><pre><code>@Testpublic void testComboFilter() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t7&quot;);    Scan scan = new Scan();    //where ... f2:age &lt;= 13    SingleColumnValueFilter ftl = new SingleColumnValueFilter(            Bytes.toBytes(&quot;f2&quot;),            Bytes.toBytes(&quot;age&quot;),            CompareFilter.CompareOp.LESS_OR_EQUAL,            new BinaryComparator(Bytes.toBytes(&quot;13&quot;))    );    //where ... f2:name like %t    SingleColumnValueFilter ftr = new SingleColumnValueFilter(            Bytes.toBytes(&quot;f2&quot;),            Bytes.toBytes(&quot;name&quot;),            CompareFilter.CompareOp.EQUAL,            new RegexStringComparator(&quot;^t&quot;)//以t开头    );    //ft    FilterList ft = new FilterList(FilterList.Operator.MUST_PASS_ALL);    ft.addFilter(ftl);    ft.addFilter(ftr);    //where ... f2:age &gt; 13    SingleColumnValueFilter fbl = new SingleColumnValueFilter(            Bytes.toBytes(&quot;f2&quot;),            Bytes.toBytes(&quot;age&quot;),            CompareFilter.CompareOp.GREATER,            new BinaryComparator(Bytes.toBytes(&quot;13&quot;))    );    //where ... f2:name like %t    SingleColumnValueFilter fbr = new SingleColumnValueFilter(            Bytes.toBytes(&quot;f2&quot;),            Bytes.toBytes(&quot;name&quot;),            CompareFilter.CompareOp.EQUAL,            new RegexStringComparator(&quot;t$&quot;)//以t结尾    );    //ft    FilterList fb = new FilterList(FilterList.Operator.MUST_PASS_ALL);    fb.addFilter(fbl);    fb.addFilter(fbr);    FilterList fall = new FilterList(FilterList.Operator.MUST_PASS_ONE);    fall.addFilter(ft);    fall.addFilter(fb);    scan.setFilter(fall);    Table t = conn.getTable(tname);    ResultScanner rs = t.getScanner(scan);    Iterator&lt;Result&gt; it = rs.iterator();    while (it.hasNext()) {        Result r = it.next();        byte[] f1id = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f2id = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;id&quot;));        byte[] f1name = r.getValue(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;name&quot;));        byte[] f2name = r.getValue(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;name&quot;));        System.out.println(f1id + &quot; : &quot; + f2id + &quot; : &quot; + Bytes.toString(f1name) + &quot; : &quot; + Bytes.toString(f2name));    }}</code></pre><h1 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h1><pre><code>$hbase&gt;incr &apos;ns1:t8&apos;,&apos;row1&apos;,&apos;f1:click&apos;,1$hbase&gt;get_counter &apos;ns1:t8&apos;,&apos;row1&apos;,&apos;f1:click&apos;    //得到计数器的值[API编程]@Testpublic void testIncr() throws IOException {    Configuration conf = HBaseConfiguration.create();    Connection conn = ConnectionFactory.createConnection(conf);    TableName tname = TableName.valueOf(&quot;ns1:t8&quot;);    Table t = conn.getTable(tname);    Increment incr = new Increment(Bytes.toBytes(&quot;row1&quot;));    incr.addColumn(Bytes.toBytes(&quot;f1&quot;),Bytes.toBytes(&quot;daily&quot;),1);    incr.addColumn(Bytes.toBytes(&quot;f1&quot;),Bytes.toBytes(&quot;weekly&quot;),10);    incr.addColumn(Bytes.toBytes(&quot;f1&quot;),Bytes.toBytes(&quot;monthly&quot;),100);    t.increment(incr);}</code></pre><h1 id="coprocessor"><a href="#coprocessor" class="headerlink" title="coprocessor"></a>coprocessor</h1><p>协处理器工作过程：</p><p><img src="https://i.imgur.com/lZeb49u.png" alt=""></p><pre><code>批处理的，等价于存储过程或者触发器[Observer]    观察者,类似于触发器，基于事件。发生动作时，回调相应方法。    RegionObserver        //RegionServer区域观察者    MasterObserver        //Master节点。    WAlObserver            //[Endpoint]    终端,类似于存储过程。1.加载    [hbase-site.xml]    &lt;property&gt;        &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;        &lt;value&gt;coprocessor.RegionObserverExample, coprocessor.AnotherCoprocessor&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt;        &lt;value&gt;coprocessor.MasterObserverExample&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.coprocessor.wal.classes&lt;/name&gt;        &lt;value&gt;coprocessor.WALObserverExample, bar.foo.MyWALObserver&lt;/value&gt;    &lt;/property&gt;2.自定义观察者    [MyRegionObserver]    package com.it18zhang.hbasedemo.coprocessor;    import org.apache.hadoop.hbase.Cell;    import org.apache.hadoop.hbase.CoprocessorEnvironment;    import org.apache.hadoop.hbase.client.Delete;    import org.apache.hadoop.hbase.client.Durability;    import org.apache.hadoop.hbase.client.Get;    import org.apache.hadoop.hbase.client.Put;    import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;    import org.apache.hadoop.hbase.coprocessor.ObserverContext;    import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;    import org.apache.hadoop.hbase.regionserver.wal.WALEdit;    import org.apache.hadoop.hbase.util.Bytes;    import java.io.FileWriter;    import java.io.IOException;    import java.util.List;    /**     * 自定义区域观察者     */    public class MyRegionObserver extends BaseRegionObserver{        private void outInfo(String str){            try {                FileWriter fw = new FileWriter(&quot;/home/centos/coprocessor.txt&quot;,true);                fw.write(str + &quot;\r\n&quot;);                fw.close();            } catch (Exception e) {                e.printStackTrace();            }        }        public void start(CoprocessorEnvironment e) throws IOException {            super.start(e);            outInfo(&quot;MyRegionObserver.start()&quot;);        }        public void preOpen(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e) throws IOException {            super.preOpen(e);            outInfo(&quot;MyRegionObserver.preOpen()&quot;);        }        public void postOpen(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e) {            super.postOpen(e);            outInfo(&quot;MyRegionObserver.postOpen()&quot;);        }        @Override        public void preGetOp(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Get get, List&lt;Cell&gt; results) throws IOException {            super.preGetOp(e, get, results);            String rowkey = Bytes.toString(get.getRow());            outInfo(&quot;MyRegionObserver.preGetOp() : rowkey = &quot; + rowkey);        }        public void postGetOp(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Get get, List&lt;Cell&gt; results) throws IOException {            super.postGetOp(e, get, results);            String rowkey = Bytes.toString(get.getRow());            outInfo(&quot;MyRegionObserver.postGetOp() : rowkey = &quot; + rowkey);        }        public void prePut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {            super.prePut(e, put, edit, durability);            String rowkey = Bytes.toString(put.getRow());            outInfo(&quot;MyRegionObserver.prePut() : rowkey = &quot; + rowkey);        }        @Override        public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {            super.postPut(e, put, edit, durability);            String rowkey = Bytes.toString(put.getRow());            outInfo(&quot;MyRegionObserver.postPut() : rowkey = &quot; + rowkey);        }        @Override        public void preDelete(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Delete delete, WALEdit edit, Durability durability) throws IOException {            super.preDelete(e, delete, edit, durability);            String rowkey = Bytes.toString(delete.getRow());            outInfo(&quot;MyRegionObserver.preDelete() : rowkey = &quot; + rowkey);        }        @Override        public void postDelete(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Delete delete, WALEdit edit, Durability durability) throws IOException {            super.postDelete(e, delete, edit, durability);            String rowkey = Bytes.toString(delete.getRow());            outInfo(&quot;MyRegionObserver.postDelete() : rowkey = &quot; + rowkey);        }    }2.注册协处理器并分发    &lt;property&gt;        &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;        &lt;value&gt;com.it18zhang.hbasedemo.coprocessor.MyRegionObserver&lt;/value&gt;    &lt;/property&gt;3.导出jar包。4.复制jar到共享目录，分发到jar到hbase集群的hbase lib目录下.    [/soft/hbase/lib]</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;p&gt;title: Hbase第三天&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;null&lt;br&gt;categories:&lt;/li&gt;
&lt;li&gt;null&lt;br&gt;date: 2018-11-19 16:56:58&lt;br&gt;description:&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>SSM第二天</title>
    <link href="http://erichunn.github.io/2018/11/19/SSM%E7%AC%AC%E4%BA%8C%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2018/11/19/SSM第二天/</id>
    <published>2018-11-19T07:39:39.000Z</published>
    <updated>2018-11-28T13:23:45.304Z</updated>
    
    <content type="html"><![CDATA[<h2 id="mybatis"><a href="#mybatis" class="headerlink" title="mybatis"></a>mybatis</h2><pre><code>持久化技术。jdbcsql</code></pre><h2 id="Spring"><a href="#Spring" class="headerlink" title="Spring    "></a>Spring    </h2><pre><code>业务层框架。管理bean的。new Map&lt;String,Object&gt;</code></pre><h2 id="体验spring"><a href="#体验spring" class="headerlink" title="体验spring"></a>体验spring</h2><pre><code>1.创建模块 ,添加pom.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;springdemo&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;junit&lt;/groupId&gt;                &lt;artifactId&gt;junit&lt;/artifactId&gt;                &lt;version&gt;4.11&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-context&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;2.创建java类    public class WelcomeService {        private String message ;        public String getMessage() {            return message;        }        public void setMessage(String message) {            this.message = message;        }        public void sayHello(){            System.out.println(message);        }    }    3.创建配置文件    [resources/beans.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;        &lt;bean id=&quot;ws&quot; class=&quot;com.it18zhang.springdemo.service.WelcomeService&quot;&gt;            &lt;property name=&quot;message&quot; value=&quot;hello world&quot; /&gt;        &lt;/bean&gt;    &lt;/beans&gt;4.创建App    [App.java]    public static void main(String[] args) {        //创建容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);        WelcomeService ws = (WelcomeService)ac.getBean(&quot;ws&quot;);        ws.sayHello();    }</code></pre><h2 id="spring的注解方式使用"><a href="#spring的注解方式使用" class="headerlink" title="spring的注解方式使用"></a>spring的注解方式使用</h2><pre><code>0.增加pom.xml文件    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;        &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;    &lt;/dependency&gt;1.UserDao增加@Repository注解.    @Repository(&quot;userDao&quot;)    public class UserDao{        ...    }2.Service增加 @Service注解。    @Service(&quot;ws&quot;)    public class WelcomeService {        ...        //注入指定的dao对象        @Resource(name = &quot;userDao&quot;)        public void setDao(UserDao dao) {            this.dao = dao;        }    }3.修改beans.xml文件，引入context空间，使用组件扫描。    [resrouces/beans.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xmlns:context=&quot;http://www.springframework.org/schema/context&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd                            http://www.springframework.org/schema/context                            http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt;        &lt;context:component-scan base-package=&quot;com.it18zhang.springdemo.dao,com.it18zhang.springdemo.service&quot; /&gt;4.测试App.java    public class App {        public static void main(String[] args) {            //创建容器            ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);            WelcomeService ws = (WelcomeService)ac.getBean(&quot;ws&quot;);            ws.sayHello();        }    }</code></pre><h2 id="spring-整合mybatis"><a href="#spring-整合mybatis" class="headerlink" title="spring 整合mybatis"></a>spring 整合mybatis</h2><pre><code>1.创建模块 pom.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;springmybatisdemo&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;junit&lt;/groupId&gt;                &lt;artifactId&gt;junit&lt;/artifactId&gt;                &lt;version&gt;4.11&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.mybatis&lt;/groupId&gt;                &lt;artifactId&gt;mybatis&lt;/artifactId&gt;                &lt;version&gt;3.1.0&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;mysql&lt;/groupId&gt;                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;                &lt;version&gt;5.1.17&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;c3p0&lt;/groupId&gt;                &lt;artifactId&gt;c3p0&lt;/artifactId&gt;                &lt;version&gt;0.9.1.2&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.mybatis&lt;/groupId&gt;                &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;                &lt;version&gt;1.3.0&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.aspectj&lt;/groupId&gt;                &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;                &lt;version&gt;1.8.10&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;2.创建包    com.it18zhang.springmybatis.dao    com.it18zhang.springmybatis.service    com.it18zhang.springmybatis.util3.配置beans.xml    [resources/beans.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;        &lt;!-- 数据源 --&gt;        &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;            &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;            &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt;            &lt;property name=&quot;user&quot; value=&quot;root&quot;/&gt;            &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;property name=&quot;maxPoolSize&quot; value=&quot;10&quot;/&gt;            &lt;property name=&quot;minPoolSize&quot; value=&quot;2&quot;/&gt;            &lt;property name=&quot;initialPoolSize&quot; value=&quot;3&quot;/&gt;            &lt;property name=&quot;acquireIncrement&quot; value=&quot;2&quot;/&gt;        &lt;/bean&gt;    &lt;/beans&gt;4.编写单元测试    @Test    public void testConn() throws Exception {        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);        DataSource ds = (DataSource)ac.getBean(&quot;dataSource&quot;);        System.out.println(ds.getConnection());    }5.添加domain类    User    Order    Item    略6.添加Mapper.xml映射文件    //注意：修改类的别名    resources/UserMapper.xml    resources/OrderMapper.xml7.添加mybatis-config.xml    [resources/mybatis-config.xml]    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;    &lt;!DOCTYPE configuration            PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;            &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;    &lt;configuration&gt;        &lt;typeAliases&gt;            &lt;typeAlias type=&quot;com.it18zhang.springmybatis.domain.User&quot; alias=&quot;_User&quot;/&gt;            &lt;typeAlias type=&quot;com.it18zhang.springmybatis.domain.Order&quot; alias=&quot;_Order&quot;/&gt;            &lt;typeAlias type=&quot;com.it18zhang.springmybatis.domain.Item&quot; alias=&quot;_Item&quot;/&gt;        &lt;/typeAliases&gt;        &lt;!-- 引入映射文件 --&gt;        &lt;mappers&gt;            &lt;mapper resource=&quot;UserMapper.xml&quot;/&gt;            &lt;mapper resource=&quot;OrderMapper.xml&quot;/&gt;        &lt;/mappers&gt;    &lt;/configuration&gt;8.创建Dao接口和实现类.    [BaseDao.java]    package com.it18zhang.springmybatis.dao;    import java.util.List;    /**     *基本Dao接口     */    public interface BaseDao&lt;T&gt; {        public void insert(T t) ;        public void update(T t) ;        public void delete(Integer id) ;        public T selectOne(Integer id) ;        public List&lt;T&gt; selectAll() ;    }    [UserDao.java]    package com.it18zhang.springmybatis.dao;    import com.it18zhang.springmybatis.domain.User;    import org.mybatis.spring.support.SqlSessionDaoSupport;    import java.util.List;    /**     */    @Repository(&quot;userDao&quot;)    public class UserDao extends SqlSessionDaoSupport implements BaseDao&lt;User&gt; {        public void insert(User user) {            getSqlSession().insert(&quot;users.insert&quot;,user);        }        public void update(User user) {            getSqlSession().update(&quot;users.update&quot;, user);        }        public void delete(Integer id ) {            getSqlSession().delete(&quot;users.delete&quot;, id);        }        public User selectOne(Integer id) {            return getSqlSession().selectOne(&quot;users.selectOne&quot;,id) ;        }        public List&lt;User&gt; selectAll() {            return getSqlSession().selectList(&quot;users.selectAll&quot;);        }    }</code></pre><p>a<br>        [OrderDao.java]<br>        略</p><pre><code>9.创建BaseService&lt;T&gt;.java接口 + UserService.java + UserServcieImpl.java    [BaseService.java]    package com.it18zhang.springmybatis.service;    import java.util.List;    /**     * Created by Administrator on 2017/4/7.     */    public interface BaseService&lt;T&gt; {        public void insert(T t);        public void update(T t);        public void delete(Integer id);        public T selectOne(Integer id);        public List&lt;T&gt; selectAll();    }    [BaseServiceImpl.java]    public abstract class BaseServiceImpl&lt;T&gt; implements BaseService&lt;T&gt; {        private BaseDao&lt;T&gt; dao ;        public void setDao(BaseDao&lt;T&gt; dao) {            this.dao = dao;        }        public void insert(T t) {            dao.insert(t);        }        ...    }    [UserService.java]    public interface UserService extends BaseService&lt;User&gt; {    }    [UserServiceImpl.java]    @Service(&quot;userService&quot;)    public class UserServiceImpl extends BaseServiceImpl&lt;User&gt; implements  UserService{        /*** 重写该方法，注入指定的Dao对象 ***/        @Resource(name=&quot;userDao&quot;)        public void setDao(BaseDao&lt;User&gt; dao) {            super.setDao(dao);        }    }10.完善spring的配置文件.    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</code></pre><beans xmlns="http://www.springframework.org/schema/beans" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemalocation="http://www.springframework.org/schema/beans                                   http://www.springframework.org/schema/beans/spring-beans.xsd                                   http://www.springframework.org/schema/context                                   http://www.springframework.org/schema/context/spring-context-4.3.xsd                                   http://www.springframework.org/schema/tx                                   http://www.springframework.org/schema/tx/spring-tx-4.3.xsd                                   http://www.springframework.org/schema/aop                                   http://www.springframework.org/schema/aop/spring-aop-4.3.xsd" default-autowire="byType"><br>    <!-- 配置事务特征 --><br>    &lt;tx:advice id=”txAdvice” transaction-manager=”txManager”&gt;<br>        <a href="tx:attributes" target="_blank" rel="noopener">tx:attributes</a><br>            <!--，配置事务特征，            name代表所有都要加隔离事物。propagation代表传播行为，*是通配，隔离级别都用默认隔离级别            那么那些方法需要事务呢？所以我们又要加一个AOP的范畴--><br>            &lt;tx:method name=”<em>“ propagation=”REQUIRED” isolation=”DEFAULT”/&gt;<br>        &lt;/tx:attributes&gt;<br>    &lt;/tx:advice&gt;<br><br>    <!-- 配置事务切面 也叫aop。    意思是不用改源码，加入事务的管理功能其实都对应的是javabean。--><br>    <a href="aop:config" target="_blank" rel="noopener">aop:config</a><br>        &lt;!–advisor代表切入点通知，吧事务txAdvice加到一个地方去，这个地方叫做切入点，哪里执行execution呢，就是任何地方<br>        第一个</em>匹配的是函数的返回值  任何函数返回值都可以，然后<em>.代表包，任何包以及包的子包，然后.</em>service第一个点代表<br>        包和类的分割符，后面就是以Service结尾的任何接口或类，然后最后括号里面的..代表参数不限，随便什么参数都可以–&gt;<br>        &lt;aop:advisor advice-ref=”txAdvice” pointcut=”execution(<em> </em>..<em>Service.</em>(..))” /&gt;<br>    &lt;/aop:config&gt;<br><br>    <!-- 扫描包 --><br>    &lt;context:component-scan base-package=”com.it18zhang.springmybatis.dao,com.it18zhang.springmybatis.service” /&gt;<br><br>    <!-- 数据源 --><br>    <bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"><br>        <property name="driverClass" value="com.mysql.jdbc.Driver"><br>        <property name="jdbcUrl" value="jdbc:mysql://localhost:3306/mybatis"><br>        <property name="user" value="root"><br>        <property name="password" value="root"><br>        <property name="maxPoolSize" value="10"><br>        <property name="minPoolSize" value="2"><br>        <property name="initialPoolSize" value="3"><br>        <property name="acquireIncrement" value="2"><br>    </property></property></property></property></property></property></property></property></bean><br><br>    <!-- mybatis整合spring的核心类。配置会话工厂 --><br>    <bean id="sf" class="org.mybatis.spring.SqlSessionFactoryBean"><br>        <!-- 指定数据源 --><br>        <property name="dataSource" ref="dataSource"><br>        <!-- 指定mybatis配置文件 --><br>        <property name="configLocation" value="mybatis-config.xml"><br>    </property></property></bean><br><br>    <!-- 数据源事务管理器 --><br>    <bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"><br>        <property name="dataSource" ref="dataSource"><br>    </property></bean><br></beans><pre><code>11.测试UserService    @Test    public void testUserService() throws Exception {        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);        UserService us = (UserService)ac.getBean(&quot;userService&quot;);        User u = new User();        u.setName(&quot;jerry&quot;);        u.setAge(12);        us.insert(u);    }</code></pre><hr><p>select i.id iid,i.itemname iitemname,o.id oid,o.orderno oorderno , u.id uid ,u.name uname ,u.age uage<br>from items i<br>    left outer join orders o on i.oid = o.id<br>    left outer join users u on o.uid = u.id<br>where i.id = 2</p><p>我们一般吧最基础的增删改查里面放到baseservice这个接口里面，这里面是公共的功能，所以在下面还需要有分开的叉开的，需要有userservice继承自baseservice,他也是一个接口，然后在userservice里面有什么需要加的功能加到这个里面，也就是说在服务层需要有什么功能的都加到这个接口里面，避免都要实现。这个地方是要继承的。</p><p><img src="https://i.imgur.com/f3jj2Pc.png" alt=""></p><p><img src="https://i.imgur.com/WIINiCh.png" alt=""></p><p>一个spring整合mybatis的rose图：</p><p><img src="https://i.imgur.com/JOlAVsY.png" alt=""></p><p>整个结构：<br>这个里面如果直接接受dao可以在调试中get到他的具体的内容，<br>如果接受service就不行因为事务管理封装起了sevice。所以接收到的是一个事务</p><p><img src="https://i.imgur.com/4Kts8mg.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;mybatis&quot;&gt;&lt;a href=&quot;#mybatis&quot; class=&quot;headerlink&quot; title=&quot;mybatis&quot;&gt;&lt;/a&gt;mybatis&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;持久化技术。jdbc
sql
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Spring
      
    
    </summary>
    
    
      <category term="SSM" scheme="http://erichunn.github.io/tags/SSM/"/>
    
  </entry>
  
</feed>
