<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>无心是一首歌</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://erichunn.github.io/"/>
  <updated>2019-09-29T09:04:55.693Z</updated>
  <id>http://erichunn.github.io/</id>
  
  <author>
    <name>Eric Hunn</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>test</title>
    <link href="http://erichunn.github.io/2019/09/29/test/"/>
    <id>http://erichunn.github.io/2019/09/29/test/</id>
    <published>2019-09-29T09:04:55.000Z</published>
    <updated>2019-09-29T09:04:55.693Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/25/Spring%E7%AC%94%E8%AE%B0/Spring%E4%B8%ADbean%E7%BB%86%E8%8A%82%E4%B8%89%E7%A7%8D%E5%88%9B%E5%BB%BA%E6%96%B9%E5%BC%8F/"/>
    <id>http://erichunn.github.io/2019/09/25/Spring笔记/Spring中bean细节三种创建方式/</id>
    <published>2019-09-25T03:19:25.329Z</published>
    <updated>2019-09-26T14:13:38.556Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spring-bean的三种创建细节和生命周期"><a href="#Spring-bean的三种创建细节和生命周期" class="headerlink" title="Spring bean的三种创建细节和生命周期"></a>Spring bean的三种创建细节和生命周期</h2><p>首先如果一个类的默认构造函数是空值构造函数，然后在写一个带参构造函数，那么这个默认构造函数就被覆盖了。如下：<br>    public class AccountServiceImpl implements IAccountService {</p><pre><code>    public AccountServiceImpl(String name) {        System.out.println(&quot;对象创建了&quot;);    }}</code></pre><p>这种就是被覆盖了的构造函数</p><p> 第一种方式：使用默认构造函数创建。这种情况是使用自己写好的类</p><p> 在spring的配置文件中使用bean标签，配以id和class属性之后，且没有其他属性和标签时。<br> 采用的就是默认构造函数创建bean对象，此时如果类中没有默认构造函数，则对象无法创建。</p><pre><code>&lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot;&gt;&lt;/bean&gt;&gt;</code></pre><p>在实际开发中有可能使用别人定义好的类，那么如何调用在Jar包里面的类呢？<br>第二种方式： 使用普通工厂中的方法创建对象（使用某个类中的方法创建对象，并存入spring容器</p><pre><code>//bean.xml文件里面的配置&lt;bean id=&quot;instanceFactory&quot; class=&quot;com.itheima.factory.InstanceFactory&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;accountService&quot; factory-bean=&quot;instanceFactory&quot; factory method=&quot;getAccountService&quot;&gt;&lt;/bean&gt;</code></pre><hr><pre><code>/** * jar包中的类，模拟一个工厂类（该类可能是存在于jar包中的，我们无法通过修改源码的方式来提供默认构造函数） */public class InstanceFactory {    public IAccountService getAccountService(){        return new AccountServiceImpl();    }}</code></pre><p>第二种方式的要求工厂类instanceFactory，类名配好，然后下面那一行，有一个getAccountService方法和一个instanceFactory类。</p> <!-- 第三种方式：使用工厂中的静态方法创建对象（使用某个类中的静态方法创建对象，并存入spring容器)    <bean id="accountService" class="com.itheima.factory.StaticFactory" factory-method="getAccountService"></bean>***    /**     * jar包中的类，模拟一个工厂类（该类可能是存在于jar包中的，我们无法通过修改源码的方式来提供默认构造函数）     */    public class StaticFactory {        public static IAccountService getAccountService(){            return new AccountServiceImpl();        }    }Bean的作用范围调整        bean的作用范围调整            bean标签的scope属性：                作用：用于指定bean的作用范围                取值： 常用的就是单例的和多例的                    singleton：单例的（默认值）                    prototype：多例的                    request：作用于web应用的请求范围                    session：作用于web应用的会话范围                    global-session：作用于集群环境的会话范围（全局会话范围），当不是集群环境时，它就是session        <bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl" scope="prototype"></bean>那么global-session是什么：![](https://i.imgur.com/Xj13Dza.png)就比如开始有一个用户，他通过网址访问，然后过负载均衡，开始的时候在01,输入帐号密码，01里面的session就变成了1234，但是第二次她在访问06是空闲的，所以访问了06，但是这时候session还是在01里面，那么怎么办呢，就弄一个全局的globalsession，每次访问都放在global-session这个域里面就好了。Bean的对象的生命周期：     /**       单例对象                出生：当容器创建时对象出生                活着：只要容器还在，对象一直活着                死亡：容器销毁，对象消亡                总结：单例对象的生命周期和容器相同            多例对象                出生：当我们使用对象时spring框架为我们创建                活着：对象只要是在使用过程中就一直活着。                死亡：当对象长时间不用，且没有别的对象引用时，由Java的垃圾回收器回收     */需要借用一个属性：    <bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl"          scope="prototype" init-method="init" destroy-method="destroy"></bean>    </beans>***    /**     * 账户的业务层实现类     */    public class AccountServiceImpl implements IAccountService {    public AccountServiceImpl() {        System.out.println("对象创建了");    }    public void  saveAccount(){        System.out.println("service中的saveAccount方法执行了。。。");    }    public void  init(){        System.out.println("对象初始化了。。。");    }    public void  destroy(){        System.out.println("对象销毁了。。。");    }}再说一下如果代码写成这样子：    ApplicationContext ac = new ClassPathXmlApplicationContext("bean.xml");的话，会发现不能调用子类的方法，智能调用父类的方法，所以只能调用ApplicationContext的方法。在使用单例对象和多例对象的情况下，单例是刚执行这行方法就创建对象，多例是执行这个方法时候并不会创建，只有使用的时候才会创建。单例对象的死亡，就是容器destroy了，就关闭了，但是多例对象的死亡，如果对象长时间不用，并且没有别的对象引用的时候，由java的垃圾回收机制回收。下面是整个所有的代码：    package com.itheima.factory;    import com.itheima.service.IAccountService;    import com.itheima.service.impl.AccountServiceImpl;    /**     * 模拟一个工厂类（该类可能是存在于jar包中的，我们无法通过修改源码的方式来提供默认构造函数）     */    public class InstanceFactory {        public IAccountService getAccountService(){            return new AccountServiceImpl();        }    }***    package com.itheima.factory;    import com.itheima.service.IAccountService;    import com.itheima.service.impl.AccountServiceImpl;    /**     * 模拟一个工厂类（该类可能是存在于jar包中的，我们无法通过修改源码的方式来提供默认构造函数）     */    public class StaticFactory {        public static IAccountService getAccountService(){            return new AccountServiceImpl();        }    }***    package com.itheima.service;    /**     * 账户业务层的接口     */    public interface IAccountService {        /**         * 模拟保存账户         */        void saveAccount();    }***    package com.itheima.service.impl;    import com.itheima.service.IAccountService;    /**     * 账户的业务层实现类     */    public class AccountServiceImpl implements IAccountService {        public AccountServiceImpl() {            System.out.println("对象创建了");        }        public void  saveAccount(){            System.out.println("service中的saveAccount方法执行了。。。");        }        public void  init(){            System.out.println("对象初始化了。。。");        }        public void  destroy(){            System.out.println("对象销毁了。。。");        }    }***    package com.itheima.ui;    import com.itheima.service.IAccountService;    import org.springframework.context.support.ClassPathXmlApplicationContext;    /**     * 模拟一个表现层，用于调用业务层     */    public class Client {        /**         *         * @param args         */        public static void main(String[] args) {            //1.获取核心容器对象    //            ClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext("bean.xml");            //2.根据id获取Bean对象            IAccountService as  = (IAccountService)ac.getBean("accountService");            as.saveAccount();            //手动关闭容器            ac.close();        }    }***    <?xml version="1.0" encoding="UTF-8"?>    <beans xmlns="http://www.springframework.org/schema/beans"           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"           xsi:schemaLocation="http://www.springframework.org/schema/beans            http://www.springframework.org/schema/beans/spring-beans.xsd">        <!--把对象的创建交给spring来管理--><pre><code>    &lt;!--spring对bean的管理细节        1.创建bean的三种方式        2.bean对象的作用范围        3.bean对象的生命周期    --&gt;    &lt;!--创建Bean的三种方式 --&gt;    &lt;!-- 第一种方式：使用默认构造函数创建。            在spring的配置文件中使用bean标签，配以id和class属性之后，且没有其他属性和标签时。            采用的就是默认构造函数创建bean对象，此时如果类中没有默认构造函数，则对象无法创建。    &lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot;&gt;&lt;/bean&gt;    --&gt;    &lt;!-- 第二种方式： 使用普通工厂中的方法创建对象（使用某个类中的方法创建对象，并存入spring容器）    &lt;bean id=&quot;instanceFactory&quot; class=&quot;com.itheima.factory.InstanceFactory&quot;&gt;&lt;/bean&gt;    &lt;bean id=&quot;accountService&quot; factory-bean=&quot;instanceFactory&quot; factory-method=&quot;getAccountService&quot;&gt;&lt;/bean&gt;    --&gt;    &lt;!-- 第三种方式：使用工厂中的静态方法创建对象（使用某个类中的静态方法创建对象，并存入spring容器)    &lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.factory.StaticFactory&quot; factory-method=&quot;getAccountService&quot;&gt;&lt;/bean&gt;    --&gt;    &lt;!-- bean的作用范围调整        bean标签的scope属性：            作用：用于指定bean的作用范围            取值： 常用的就是单例的和多例的                singleton：单例的（默认值）                prototype：多例的                request：作用于web应用的请求范围                session：作用于web应用的会话范围                global-session：作用于集群环境的会话范围（全局会话范围），当不是集群环境时，它就是session    &lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot; scope=&quot;prototype&quot;&gt;&lt;/bean&gt;    --&gt;    &lt;!-- bean对象的生命周期              单例对象                  出生：当容器创建时对象出生                  活着：只要容器还在，对象一直活着                  死亡：容器销毁，对象消亡                  总结：单例对象的生命周期和容器相同              多例对象                  出生：当我们使用对象时spring框架为我们创建                  活着：对象只要是在使用过程中就一直活着。                  死亡：当对象长时间不用，且没有别的对象引用时，由Java的垃圾回收器回收       --&gt;    &lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot;          scope=&quot;prototype&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt;&lt;/beans&gt;</code></pre><h1 id="Spring的依赖注入"><a href="#Spring的依赖注入" class="headerlink" title="Spring的依赖注入"></a>Spring的依赖注入</h1><h2 id="1、使用构造函数注入"><a href="#1、使用构造函数注入" class="headerlink" title="1、使用构造函数注入"></a>1、使用构造函数注入</h2><pre><code>&lt;!--spring中的依赖注入--&gt;&lt;!--    依赖注入：--&gt;&lt;!--        Dependency Injection--&gt;&lt;!--     IOC的作用：降低程序之间的依赖关系，但是没有消除。--&gt;&lt;!--    依赖关系的管理：--&gt;&lt;!--    以后都交给了spring来维护，--&gt;&lt;!--    在当前类中需要用到其他的对象，由spring为我们提供，我们只需要在配置文件中说明--&gt;&lt;!--    依赖关系的维护：就称之为依赖注入，--&gt;&lt;!--        能注入的数据有三种：--&gt;&lt;!--        基本类型和String、其他的bean类型（在配置文件中或者注解配置过的bean)、复杂类型|集合类型--&gt;&lt;!--        注入的方式有三种：--&gt;&lt;!--            第一种：使用构造函数提供--&gt;&lt;!--            第二种：使用set方法提供--&gt;&lt;!--            第三种：使用注解提供（明天内容）--&gt;</code></pre><hr><p>第一种方式：</p><pre><code>package com.itheima.service.impl;import com.itheima.service.IAccountService;import java.util.Date;/** * 账户的业务层实现类 */public class AccountServiceImpl implements IAccountService {//如果是经常变化的数据，并不适合注入的方式，这里演示的3种类型，不考虑他们代表的意义，假设他们不经常变化适合注入    private String name;    private Integer age;    private Date birthday;    public AccountServiceImpl(String name, Integer age ,Date birthday){        this.name=name;        this.age=age;        this.birthday=birthday;    }    public void  saveAccount(){        System.out.println(&quot;service中的saveAccount方法执行了。。。&quot;);    }}</code></pre><hr><pre><code>// 但是像下面这样子注入的情况下，将test注入到上面实现类的构造函数里面，使用的是tpye方式，但是一旦构造函数中有2个以上的同类型，就难以判断是哪一个，这个是因为每个只有一种类型，所以可以解决。&lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot;&gt;&lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;test&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;</code></pre><hr><pre><code>  &lt;!--构造函数注入：    使用的标签:constructor-arg    标签出现的位置：bean标签的内部    标签中的属性        type：用于指定要注入的数据的数据类型，该数据类型也是构造函数中某个或某些参数的类型        index：用于指定要注入的数据给构造函数中指定索引位置的参数赋值。索引的位置是从0开始        name：用于指定给构造函数中指定名称的参数赋值                                        常用的        =============以上三个用于指定给构造函数中哪个参数赋值===============================        value：用于提供基本类型和String类型的数据        ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象    优势：        在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功。    弊端：        改变了bean对象的实例化方式，使我们在创建对象时，如果用不到这些数据，也必须提供。--&gt;  &lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot;&gt;    &lt;constructor-arg name=&quot;name&quot; value=&quot;泰斯特&quot;&gt;&lt;/constructor-arg&gt;    &lt;constructor-arg name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/constructor-arg&gt;    &lt;constructor-arg name=&quot;birthday&quot; ref=&quot;now&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;  &lt;!-- 配置一个日期对象 --&gt;&lt;bean id=&quot;now&quot; class=&quot;java.util.Date&quot;&gt;&lt;/bean&gt;</code></pre><h2 id="2、使用set方法注入"><a href="#2、使用set方法注入" class="headerlink" title="2、使用set方法注入"></a>2、使用set方法注入</h2><pre><code>&lt;!-- set方法注入                更常用的方式涉及的标签：property出现的位置：bean标签的内部标签的属性    name：用于指定注入时所调用的set方法名称    value：用于提供基本类型和String类型的数据    ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象优势：    创建对象时没有明确的限制，可以直接使用默认构造函数弊端： 对象是有可能set方法没有执行。（解释；有可能在调用AccountServiceImpl2这个类的时候已经用完了，所以set不了，每太明白。）--&gt;</code></pre><hr><pre><code>package com.itheima.service.impl;import com.itheima.service.IAccountService;import java.util.Date;/** * 账户的业务层实现类 */public class AccountServiceImpl2 implements IAccountService {    //如果是经常变化的数据，并不适合注入的方式，这里演示的3种类型，不考虑他们代表的意义，假设他们不经常变化适合注入    private String name;    private Integer age;    private Date birthday;    public void setName(String name) {        this.name = name;    }    public void setAge(Integer age) {        this.age = age;    }    public void setBirthday(Date birthday) {        this.birthday = birthday;    }    public void saveAccount() {        System.out.println(&quot;service中的saveAccount方法执行了。。。&quot;);    }}</code></pre><hr><pre><code> &lt;bean id=&quot;accountService2&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl2&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;TEST&quot; &gt;&lt;/property&gt;    &lt;property name=&quot;age&quot; value=&quot;21&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;birthday&quot; ref=&quot;now&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置一个日期对象 --&gt;&lt;bean id=&quot;now&quot; class=&quot;java.util.Date&quot;&gt;&lt;/bean&gt;</code></pre><h2 id="复杂类型的注入"><a href="#复杂类型的注入" class="headerlink" title="复杂类型的注入"></a>复杂类型的注入</h2><pre><code>package com.itheima.service.impl;import com.itheima.service.IAccountService;import java.util.Arrays;import java.util.List;import java.util.Properties;import java.util.Set;import java.util.Map;/** * 账户的业务层实现类 */public class AccountServiceImpl3 implements IAccountService {//    数组、List集合、Set集合、Map集合、     private String[] myStrs;    private List&lt;String&gt; myList;    private Set&lt;String&gt; mySet;    private Map&lt;String,String&gt; myMap;    private Properties myProps;    public void setMyStrs(String[] myStrs) {        this.myStrs = myStrs;    }    public void setMyList(List&lt;String&gt; myList) {        this.myList = myList;    }    public void setMySet(Set&lt;String&gt; mySet) {        this.mySet = mySet;    }    public void setMyMap(Map&lt;String, String&gt; myMap) {        this.myMap = myMap;    }    public void setMyProps(Properties myProps) {        this.myProps = myProps;    }    public void  saveAccount(){        System.out.println(Arrays.toString(myStrs));        System.out.println(myList);        System.out.println(mySet);        System.out.println(myMap);        System.out.println(myProps);    }}</code></pre><hr><pre><code>&lt;!-- 复杂类型的注入/集合类型的注入       用于给List结构集合注入的标签：           list array set       用于个Map结构集合注入的标签:           map  props       结构相同，标签可以互换   --&gt;   &lt;bean id=&quot;accountService3&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl3&quot;&gt;       &lt;property name=&quot;myStrs&quot;&gt;           &lt;set&gt;               &lt;value&gt;AAA&lt;/value&gt;               &lt;value&gt;BBB&lt;/value&gt;               &lt;value&gt;CCC&lt;/value&gt;           &lt;/set&gt;       &lt;/property&gt;       &lt;property name=&quot;myList&quot;&gt;           &lt;array&gt;               &lt;value&gt;AAA&lt;/value&gt;               &lt;value&gt;BBB&lt;/value&gt;               &lt;value&gt;CCC&lt;/value&gt;           &lt;/array&gt;       &lt;/property&gt;       &lt;property name=&quot;mySet&quot;&gt;           &lt;list&gt;               &lt;value&gt;AAA&lt;/value&gt;               &lt;value&gt;BBB&lt;/value&gt;               &lt;value&gt;CCC&lt;/value&gt;           &lt;/list&gt;       &lt;/property&gt;       &lt;property name=&quot;myMap&quot;&gt;           &lt;props&gt;               &lt;prop key=&quot;testC&quot;&gt;ccc&lt;/prop&gt;               &lt;prop key=&quot;testD&quot;&gt;ddd&lt;/prop&gt;           &lt;/props&gt;       &lt;/property&gt;       &lt;property name=&quot;myProps&quot;&gt;           &lt;map&gt;               &lt;entry key=&quot;testA&quot; value=&quot;aaa&quot;&gt;&lt;/entry&gt;               &lt;entry key=&quot;testB&quot;&gt;                   &lt;value&gt;BBB&lt;/value&gt;               &lt;/entry&gt;           &lt;/map&gt;       &lt;/property&gt;   &lt;/bean&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Spring-bean的三种创建细节和生命周期&quot;&gt;&lt;a href=&quot;#Spring-bean的三种创建细节和生命周期&quot; class=&quot;headerlink&quot; title=&quot;Spring bean的三种创建细节和生命周期&quot;&gt;&lt;/a&gt;Spring bean的三种创建细
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/21/VUE%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/09/21/VUE第一天/</id>
    <published>2019-09-21T12:52:25.900Z</published>
    <updated>2019-09-21T15:01:38.921Z</updated>
    
    <content type="html"><![CDATA[<p>1.Vue概述<br>2.Vue快速入门<br>3.Vue语法：<br>插值表达式<br>事件绑定<br>数据显示<br>逻辑判断和循环输出<br>4.Vue生命周期<br> 8个声明周期的执行点<br>        4个基本<br>        4个特殊<br>5.axios的ajax异步请求<br>        他和jquery的ajax比较相似<br>6.综合案例<br>        实现用户的查询列表和更新操作</p><p><img src="https://i.imgur.com/IyiqAsl.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.Vue概述&lt;br&gt;2.Vue快速入门&lt;br&gt;3.Vue语法：&lt;br&gt;插值表达式&lt;br&gt;事件绑定&lt;br&gt;数据显示&lt;br&gt;逻辑判断和循环输出&lt;br&gt;4.Vue生命周期&lt;br&gt; 8个声明周期的执行点&lt;br&gt;        4个基本&lt;br&gt;        4个特殊&lt;br&gt;5.a
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/18/Spring%E7%AC%94%E8%AE%B0/Spring%E7%AC%AC%E4%B8%8003.Spring%E7%9A%84%20IOC%20%E5%92%8C%20DI/"/>
    <id>http://erichunn.github.io/2019/09/18/Spring笔记/Spring第一03.Spring的 IOC 和 DI/</id>
    <published>2019-09-18T12:09:30.792Z</published>
    <updated>2019-09-18T12:37:05.120Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/wHM9KVT.png" alt=""></p><p>应用APP直接跟资源联系他们之间是必然联系，笑出不掉，很难应用独立，或者资源独立</p><p><img src="https://i.imgur.com/lGvrhOe.png" alt=""></p><p>这种通过APP联系工厂获得资源也就是所说的IOC控制反转。</p><p><img src="https://i.imgur.com/WcKZNOX.png" alt=""></p><p><img src="https://i.imgur.com/ng3fx2M.png" alt=""></p><p>在</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/wHM9KVT.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;应用APP直接跟资源联系他们之间是必然联系，笑出不掉，很难应用独立，或者资源独立&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/l
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/17/Spring%E7%AC%94%E8%AE%B0/Spring%E7%AC%AC%E4%B8%80%E5%A4%A9%E7%A8%8B%E5%BA%8F%E9%97%B4%E8%80%A6%E5%90%88/"/>
    <id>http://erichunn.github.io/2019/09/17/Spring笔记/Spring第一天程序间耦合/</id>
    <published>2019-09-17T14:32:26.724Z</published>
    <updated>2019-09-17T14:32:18.355Z</updated>
    
    <content type="html"><![CDATA[<p>一般不定义service层和dao层的类属性成员，因为一旦是单例对象的话就很容易每次调用的时候都修改掉他。对象创建多次，执行效率没有单例对象高。<br>工厂模式的解耦的升级版，我的理解是，在service层和controller层每次都需要一个下一层的对象，那么这个时候怎么办呢，就需要实例化一个对象，但是由于一直实例化对象不好，所以要通过写xml文件或者properties文件来写上service层的位置和dao层的位置，每次使用的时候就读取这个文件，然后通过getclassloader的getResourceAsStream来读取里面的文件，把这个存入到InputStream里面，在通过props.load(in)来加载这个放到props里面，在映射这个对象的时候，就是在工厂类里面来做这个事情的，然后通过while循环拿到props里面的每一个Key，然后在通过getProperty方法获取到Key对应的Propertiy，这个就是类全限定名路径，然后在通过Class.forName(beanPath).newInstance()来通过反射创建一个类。下面是一个工厂类。</p><pre><code>import java.io.InputStream;import java.util.Enumeration;import java.util.HashMap;import java.util.Map;import java.util.Properties;/** * @Description 一个创建bean对象的工厂 * Bean在英语中是：有可重用组件的意思。 * java bena不等于实体类。javabean的范围大于实体类。 * JavaBean:用Java语言编写的可重用组件 * &lt;p&gt; * 他就是创建我们的service和dao对象的 * 1、需要一个配置文件来配置我们的service和dao * 配置内容：唯一标志=全限定类名，(keyvalue) * 2、通过读取配置文件中配置的内容，反射创建对象 * &lt;p&gt; * 配置文件可以是xml也可以是Properties； * @Author TT Hun * @Data 2019/9/16 22:19 */public class BeanFactory {    //    读取properties文件。//    定义一个properties对象    private static Properties props;    //定义一个map，用于存放我们要创建的对象，我们把它称之为容器，是因为如果一个对象长时间不用的话垃圾回收机制就会把他回收    private static Map&lt;String, Object&gt; beans;//    使用静态代码块为Properties 对象赋值    static {        try {//    实例化对象            props = new Properties();//    不要采用如下的方式来New这一个对象，因为里面一旦写了src地址在编译期就没了，然后如果是写的绝对地址C盘，D盘的话也没了所以//    不用以下的方式//        InputStream in = new InputStream();//    获取Proerties文件的流对象//    所以这个地方我们使用类加载器来获取，里面的resource的路径会成为根路径下的一个文件。            InputStream in = BeanFactory.class.getClassLoader().getResourceAsStream(&quot;bean.properties&quot;);            props.load(in);//            实例化容器            beans = new HashMap&lt;String, Object&gt;();//            取出来配置文件中所有的Key，keys返回的是一个枚举类型            Enumeration keys = props.keys();//            遍历枚举            while (keys.hasMoreElements()) {//      取出来每个key                String key = keys.nextElement().toString();//                根据Key获取value                String beanPath = props.getProperty(key);//                反射创建对象                Object value = Class.forName(beanPath).newInstance();//                把Key和value存入容器之中                beans.put(key, value);            }        } catch (Exception e) {//     这个地方一旦读取Properties失败后面的也就都失败了，所以这里面就可以抛出一个初始化异常，这个异常本质上也是一个error            throw new ExceptionInInitializerError(&quot;初始化properties失败程序不能执行&quot;);        }    }    /*根据benad的名称获取对象，此时已经是单例模式了*/        public static Object getBean(String beanName) {        return beans.get(beanName);    }////    /*根据bena的名称获取bean的对象*///    public static Object getBean(String beanName) {//        Object bean = null;//        try {//            String beanPath = props.getProperty(beanName);//            bean = Class.forName(beanPath).newInstance();//        } catch (Exception e) {//            e.printStackTrace();//        }//        return bean;//    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一般不定义service层和dao层的类属性成员，因为一旦是单例对象的话就很容易每次调用的时候都修改掉他。对象创建多次，执行效率没有单例对象高。&lt;br&gt;工厂模式的解耦的升级版，我的理解是，在service层和controller层每次都需要一个下一层的对象，那么这个时候怎么
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/17/Spring%E7%AC%94%E8%AE%B0/Spring%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/09/17/Spring笔记/Spring第一天/</id>
    <published>2019-09-17T13:15:45.189Z</published>
    <updated>2019-09-25T14:36:22.044Z</updated>
    
    <content type="html"><![CDATA[<p>一般不定义service层和dao层的类属性成员，因为一旦是单例对象的话就很容易每次调用的时候都修改掉他。对象创建多次，执行效率没有单例对象高。</p><p>工厂模式的解耦的升级版，我的理解是，在service层和controller层每次都需要一个下一层的对象，那么这个时候怎么办呢，就需要实例化一个对象，但是由于一直实例化对象不好，所以要通过写xml文件或者properties文件来写上service层的位置和dao层的位置，每次使用的时候就读取这个文件，然后通过getclassloader的getResourceAsStream来读取里面的文件，把这个存入到InputStream里面，在通过props.load(in)来加载这个放到props里面，在映射这个对象的时候，就是在工厂类里面来做这个事情的，然后通过while循环拿到props里面的每一个Key，然后在通过getProperty方法获取到Key对应的Propertiy，这个就是类全限定名路径，然后在通过Class.forName(beanPath).newInstance()来通过反射创建一个类。下面是一个工厂类。</p><pre><code>import java.io.InputStream;import java.util.Enumeration;import java.util.HashMap;import java.util.Map;import java.util.Properties;/** * @Description 一个创建bean对象的工厂 * Bean在英语中是：有可重用组件的意思。 * java bena不等于实体类。javabean的范围大于实体类。 * JavaBean:用Java语言编写的可重用组件 * &lt;p&gt; * 他就是创建我们的service和dao对象的 * 1、需要一个配置文件来配置我们的service和dao * 配置内容：唯一标志=全限定类名，(keyvalue) * 2、通过读取配置文件中配置的内容，反射创建对象 * &lt;p&gt; * 配置文件可以是xml也可以是Properties； * @Author TT Hun * @Data 2019/9/16 22:19 */public class BeanFactory {    //    读取properties文件。//    定义一个properties对象    private static Properties props;    //定义一个map，用于存放我们要创建的对象，我们把它称之为容器，是因为如果一个对象长时间不用的话垃圾回收机制就会把他回收    private static Map&lt;String, Object&gt; beans;//    使用静态代码块为Properties 对象赋值    static {        try {//    实例化对象            props = new Properties();//    不要采用如下的方式来New这一个对象，因为里面一旦写了src地址在编译期就没了，然后如果是写的绝对地址C盘，D盘的话也没了所以//    不用以下的方式//        InputStream in = new InputStream();//    获取Proerties文件的流对象//    所以这个地方我们使用类加载器来获取，里面的resource的路径会成为根路径下的一个文件。            InputStream in = BeanFactory.class.getClassLoader().getResourceAsStream(&quot;bean.properties&quot;);            props.load(in);//            实例化容器            beans = new HashMap&lt;String, Object&gt;();//            取出来配置文件中所有的Key，keys返回的是一个枚举类型            Enumeration keys = props.keys();//            遍历枚举            while (keys.hasMoreElements()) {//      取出来每个key                String key = keys.nextElement().toString();//                根据Key获取value                String beanPath = props.getProperty(key);//                反射创建对象                Object value = Class.forName(beanPath).newInstance();//                把Key和value存入容器之中                beans.put(key, value);            }        } catch (Exception e) {//     这个地方一旦读取Properties失败后面的也就都失败了，所以这里面就可以抛出一个初始化异常，这个异常本质上也是一个error            throw new ExceptionInInitializerError(&quot;初始化properties失败程序不能执行&quot;);        }    }    /*根据benad的名称获取对象，此时已经是单例模式了*/        public static Object getBean(String beanName) {        return beans.get(beanName);    }////    /*根据bena的名称获取bean的对象*///    public static Object getBean(String beanName) {//        Object bean = null;//        try {//            String beanPath = props.getProperty(beanName);//            bean = Class.forName(beanPath).newInstance();//        } catch (Exception e) {//            e.printStackTrace();//        }//        return bean;//    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一般不定义service层和dao层的类属性成员，因为一旦是单例对象的话就很容易每次调用的时候都修改掉他。对象创建多次，执行效率没有单例对象高。&lt;/p&gt;
&lt;p&gt;工厂模式的解耦的升级版，我的理解是，在service层和controller层每次都需要一个下一层的对象，那么这个
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/12/Spark%E7%AC%AC%E4%BA%8C%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/09/12/Spark第二天/</id>
    <published>2019-09-12T12:37:10.115Z</published>
    <updated>2019-09-13T15:31:35.970Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><pre><code>通用性。</code></pre><h2 id="Spark模块"><a href="#Spark模块" class="headerlink" title="Spark模块"></a>Spark模块</h2><pre><code>Spark Core            //核心库Spark SQL            //SQLSpark Streaming        //准实时计算。Spark MLlib            //机器学习库Spark graph            //图计算</code></pre><h2 id="Spark集群运行"><a href="#Spark集群运行" class="headerlink" title="Spark集群运行"></a>Spark集群运行</h2><pre><code>1.local            //本地模式2.standalone    //独立模式3.yarn            //yarn模式4.mesos            //mesos</code></pre><h2 id="start-all-sh"><a href="#start-all-sh" class="headerlink" title="start-all.sh"></a>start-all.sh</h2><pre><code>start-master.sh    //RPC端口 7077start-slave.sh    spark://s201:7077</code></pre><h2 id="webui"><a href="#webui" class="headerlink" title="webui"></a>webui</h2><pre><code>http://s201:8080</code></pre><h2 id="添加针对scala文件的编译插件"><a href="#添加针对scala文件的编译插件" class="headerlink" title="添加针对scala文件的编译插件"></a>添加针对scala文件的编译插件</h2><p>在IDEA的settings里面没有设置自动编译的情况下，需要记入scala编译插件，所以打包不含scala的类。</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;    &lt;artifactId&gt;SparkDemo1&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;build&gt;        &lt;sourceDirectory&gt;src/main/java&lt;/sourceDirectory&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;source&gt;1.8&lt;/source&gt;                    &lt;target&gt;1.8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;                &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;                &lt;version&gt;3.2.2&lt;/version&gt;                &lt;configuration&gt;                    &lt;recompileMode&gt;incremental&lt;/recompileMode&gt;                &lt;/configuration&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;goals&gt;                            &lt;goal&gt;compile&lt;/goal&gt;                            &lt;goal&gt;testCompile&lt;/goal&gt;                        &lt;/goals&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;            &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;            &lt;version&gt;2.1.0&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><p>C:\Users\Administrator.m2\repository\net<br>C:\Users\Administrator.m2\repository\net\alchim31\maven...</p><h2 id="SparkContext"><a href="#SparkContext" class="headerlink" title="SparkContext:"></a>SparkContext:</h2><pre><code>Spark集群的连接。主要入口点。SparkConf = new ();conf.setApp(&quot;&quot;)conf.setMaster(&quot;local&quot;) ;sc = new SparkContext(conf);//RDD : Resilient distributed dataset,弹性分布式数据集。val rdd1 = sc.textFile(&quot;d:/scala/test.txt&quot;);val rdd2 = rdd1.flatMap(line=&gt;line.split(&quot; &quot;));val rdd3 = rdd2.map(word=&gt;(word,1));val rdd4 = rdd3.reduceByKey(_ + _) ;val list = rdd4.collect()list.foreach(e=&gt;println(e));//sc.textFile(&quot;d:/scala&quot;).flatMap(_.split(&quot; &quot;)).map((_1)).reduceByKey(_ + _).collect().foreach(println)</code></pre><h2 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h2><pre><code>基于hadoop的mr，扩展MR模型高效使用MR模型，内存型集群计算，提高app处理速度。</code></pre><h2 id="spark特点"><a href="#spark特点" class="headerlink" title="spark特点"></a>spark特点</h2><pre><code>速度:在内存中存储中间结果。支持多种语言.内置了80+的算子.高级分析:MR，SQL/ Streamming /mllib / graph</code></pre><p>spark模块<br>    core        //通用执行引擎，提供内存计算和对外部数据集的引用。<br>    SQL            //构建在core之上，引入新的抽象SchemaRDD，提供了结构化和半结构化支持。</p><pre><code>Streaming    //小批量计算，用的是RDD.MLlib        //机器学习库。core在。Graphx        //图计算。</code></pre><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD:"></a>RDD:</h2><pre><code>是spark的基本数据结构，是不可变数据集。RDD中的数据集进行逻辑分区，每个分区可以单独在集群节点进行计算。可以包含任何java,scala，python和自定义类型。RDD是只读的记录分区集合。RDD具有容错机制。创建RDD方式，一、并行化一个现有集合。hadoop 花费90%时间用户rw。、但是也不一定，如果是一次ｍｒ可能就不进入到磁盘里面，如果多次ｍｒ肯定进入到磁盘里面了。要等到数据都写入才可以，收到磁盘Ｉｏ影响严重内存处理计算。在job间进行数据共享。内存的IO速率高于网络和disk的10 ~ 100之间。内部包含5个主要属性-----------------------1.分区列表2.针对每个split的计算函数。3.对其他rdd的依赖列表4.可选，如果是KeyValueRDD的话，可以带分区类。5.可选，首选块位置列表(hdfs block location);//默认并发度下面从下往上面看是sc.textFile的源码过程这边确定一下，这个textFile里面的defaultMinPartitions指的是分区个数。然后在代码里面conf.setMaster(&quot;local[2]&quot;)这个里面的2指的才是线程个数才是并发度。这个线程就类似于我们完全分布下的节点local.backend.defaultParallelism() = scheduler.conf.getInt(&quot;spark.default.parallelism&quot;, totalCores)taskScheduler.defaultParallelism = backend.defaultParallelism()sc.defaultParallelism =...; taskScheduler.defaultParallelismdefaultMinPartitions = math.min(defaultParallelism, 2)sc.textFile(path,defaultMinPartitions)            //1,2</code></pre><p>先说一下mapreduce里面的Map和reduce可以和spark里面的Map和reduce相结合看一下：</p><p>Map过程：并行读取文本，对读取的单词进行map操作，每个词都以&lt;key,value&gt;形式生成。</p><pre><code>　　一个有三行文本的文件进行MapReduce操作。　　读取第一行Hello World Bye World ，分割单词形成Map。　　&lt;Hello,1&gt; &lt;World,1&gt; &lt;Bye,1&gt; &lt;World,1&gt;　　读取第二行Hello Hadoop Bye Hadoop ，分割单词形成Map。　　&lt;Hello,1&gt; &lt;Hadoop,1&gt; &lt;Bye,1&gt; &lt;Hadoop,1&gt;　　读取第三行Bye Hadoop Hello Hadoop，分割单词形成Map。　　&lt;Bye,1&gt; &lt;Hadoop,1&gt; &lt;Hello,1&gt; &lt;Hadoop,1&gt;</code></pre><p>Reduce操作是对map的结果进行排序，合并，最后得出词频。<br>我的理解：</p><pre><code>　　经过进一步处理(combiner),将形成的Map根据相同的key组合成value数组。　　&lt;Bye,1,1,1&gt; &lt;Hadoop,1,1,1,1&gt; &lt;Hello,1,1,1&gt; &lt;World,1,1&gt;　　循环执行Reduce(K,V[])，分别统计每个单词出现的次数。　　&lt;Bye,3&gt; &lt;Hadoop,4&gt; &lt;Hello,3&gt; &lt;World,2&gt;</code></pre><h2 id="RDD变换"><a href="#RDD变换" class="headerlink" title="RDD变换"></a>RDD变换</h2><pre><code>返回指向新rdd的指针，在rdd之间创建依赖关系。每个rdd都有计算函数和指向父RDD的指针。map()                                    //对每个元素进行变换，应用变换函数                                        //(T)=&gt;Vfilter()                                //过滤器,(T)=&gt;BooleanflatMap()                                //压扁,T =&gt; TraversableOnce[U]mapPartitions()                            //对每个分区进行应用变换，输入的Iterator,返回新的迭代器，可以对分区进行函数处理。                                        //Iterator&lt;T&gt; =&gt; Iterator&lt;U&gt;mapPartitionsWithIndex(func)            //同上，(Int, Iterator&lt;T&gt;) =&gt; Iterator&lt;U&gt;sample(withReplacement, fraction, seed)    //采样返回采样的RDD子集。                                        //withReplacement 元素是否可以多次采样.                                        //fraction : 期望采样数量.[0,1]union()                                    //类似于mysql union操作。                                        //select * from persons where id &lt; 10                                         //union select * from id persons where id &gt; 29 ;intersection                            //交集,提取两个rdd中都含有的元素。distinct([numTasks]))                    //去重,去除重复的元素。groupByKey()                            //(K,V) =&gt; (K,Iterable&lt;V&gt;)reduceByKey(*)                            //按key聚合。 aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])                                        //按照key进行聚合key:String U:Int = 0sortByKey                                //排序join(otherDataset, [numTasks])            //连接,(K,V).join(K,W) =&gt;(K,(V,W)) cogroup                                    //协分组                                        //(K,V).cogroup(K,W) =&gt;(K,(Iterable&lt;V&gt;,Iterable&lt;!-- &lt;W&gt; --&gt;)) cartesian(otherDataset)                    //笛卡尔积,RR[T] RDD[U] =&gt; RDD[(T,U)]pipe                                    //将rdd的元素传递给脚本或者命令，执行结果返回形成新的RDDcoalesce(numPartitions)                    //减少分区repartition                                //可增可减repartitionAndSortWithinPartitions(partitioner)                                        //再分区并在分区内进行排序</code></pre><h2 id="RDD-Action"><a href="#RDD-Action" class="headerlink" title="RDD Action"></a>RDD Action</h2><pre><code>collect()                                //收集rdd元素形成数组.count()                                    //统计rdd元素的个数reduce()                                //聚合,返回一个值。first                                    //取出第一个元素take(1)take                                    //takeSample (withReplacement,num, [seed])takeOrdered(n, [ordering])saveAsTextFile(path)                    //保存到文件saveAsSequenceFile(path)                //保存成序列文件saveAsObjectFile(path) (Java and Scala)countByKey()                            //按照key,统计每个key下value的个数.</code></pre><h2 id="spark集成hadoop-ha"><a href="#spark集成hadoop-ha" class="headerlink" title="spark集成hadoop ha"></a>spark集成hadoop ha</h2><pre><code>1.复制core-site.xml + hdfs-site.xml到spark/conf目录下2.分发文件到spark所有work节点3.启动spark集群4.启动spark-shell,连接spark集群上    $&gt;spark-shell --master spark://s201:7077    $scala&gt;sc.textFile(&quot;hdfs://mycluster/user/centos/test.txt&quot;).collect();    </code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Spark&quot;&gt;&lt;a href=&quot;#Spark&quot; class=&quot;headerlink&quot; title=&quot;Spark&quot;&gt;&lt;/a&gt;Spark&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;通用性。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Spark模块&quot;&gt;&lt;a href=&quot;#Spark
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/11/Mybatis%E7%AC%AC%E4%BA%8C%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/09/11/Mybatis第二天/</id>
    <published>2019-09-11T13:32:10.533Z</published>
    <updated>2019-09-11T13:34:19.365Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/CduGMIo.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/CduGMIo.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/10/Mybatis%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/09/10/Mybatis第一天/</id>
    <published>2019-09-10T07:05:48.373Z</published>
    <updated>2019-09-10T15:17:50.540Z</updated>
    
    <content type="html"><![CDATA[<p>mybatis框架<br>共四天<br>第一天：mybatis入门<br>    mybatis的概述<br>    mybatis的环境搭建<br>    mybatis入门案例<br>    自定义mybatis框架（主要的目的是为了让大家了解mybatis中执行细节）<br>第二天：mybatis基本使用<br>    mybatis的单表crud操作<br>    mybatis的参数和返回值<br>    mybatis的dao编写<br>    mybatis配置的细节<br>        几个标签的使用<br>第三天：mybatis的深入和多表<br>    mybatis的连接池<br>    mybatis的事务控制及设计的方法<br>    mybatis的多表查询<br>        一对多（多对一）<br>        多对多<br>第四天：mybatis的缓存和注解开发<br>    mybatis中的加载时机（查询的时机）<br>    mybatis中的一级缓存和二级缓存<br>    mybatis的注解开发<br>        单表CRUD</p><pre><code>多表查询</code></pre><hr><p>1、什么是框架？<br>    它是我们软件开发中的一套解决方案，不同的框架解决的是不同的问题。<br>    使用框架的好处：<br>        框架封装了很多的细节，使开发者可以使用极简的方式实现功能。大大提高开发效率。<br>2、三层架构<br>    表现层：<br>        是用于展示数据的<br>    业务层：<br>        是处理业务需求<br>    持久层：<br>        是和数据库交互的<br>3、持久层技术解决方案<br>    JDBC技术：<br>        Connection<br>        PreparedStatement<br>        ResultSet<br>    Spring的JdbcTemplate：<br>        Spring中对jdbc的简单封装<br>    Apache的DBUtils：<br>        它和Spring的JdbcTemplate很像，也是对Jdbc的简单封装</p><pre><code>以上这些都不是框架    JDBC是规范    Spring的JdbcTemplate和Apache的DBUtils都只是工具类</code></pre><p>4、mybatis的概述<br>    mybatis是一个持久层框架，用java编写的。<br>    它封装了jdbc操作的很多细节，使开发者只需要关注sql语句本身，而无需关注注册驱动，创建连接等繁杂过程<br>    它使用了ORM思想实现了结果集的封装。</p><pre><code>ORM：    Object Relational Mappging 对象关系映射    简单的说：        就是把数据库表和实体类及实体类的属性对应起来        让我们可以操作实体类就实现操作数据库表。        user            User        id            userId        user_name        userName今天我们需要做到    实体类中的属性和数据库表的字段名称保持一致。        user            User        id            id        user_name        user_name</code></pre><p>5、mybatis的入门<br>    mybatis的环境搭建<br>        第一步：创建maven工程并导入坐标<br>        第二步：创建实体类和dao的接口<br>        第三步：创建Mybatis的主配置文件<br>                SqlMapConifg.xml<br>        第四步：创建映射配置文件<br>                IUserDao.xml<br>    环境搭建的注意事项：<br>        第一个：创建IUserDao.xml 和 IUserDao.java时名称是为了和我们之前的知识保持一致。<br>            在Mybatis中它把持久层的操作接口名称和映射文件也叫做：Mapper<br>            所以：IUserDao 和 IUserMapper是一样的<br>        第二个：在idea中创建目录的时候，它和包是不一样的<br>            包在创建时：com.itheima.dao它是三级结构<br>            目录在创建时：com.itheima.dao是一级目录<br>        第三个：mybatis的映射配置文件位置必须和dao接口的包结构相同<br>        第四个：映射配置文件的mapper标签namespace属性的取值必须是dao接口的全限定类名<br>        第五个：映射配置文件的操作配置（select），id属性的取值必须是dao接口的方法名</p><pre><code>    当我们遵从了第三，四，五点之后，我们在开发中就无须再写dao的实现类。mybatis的入门案例    第一步：读取配置文件    第二步：创建SqlSessionFactory工厂    第三步：创建SqlSession    第四步：创建Dao接口的代理对象    第五步：执行dao中的方法    第六步：释放资源    注意事项：        不要忘记在映射配置中告知mybatis要封装到哪个实体类中        配置的方式：指定实体类的全限定类名    mybatis基于注解的入门案例：        把IUserDao.xml移除，在dao接口的方法上使用@Select注解，并且指定SQL语句        同时需要在SqlMapConfig.xml中的mapper配置时，使用class属性指定dao接口的全限定类名。明确：    我们在实际开发中，都是越简便越好，所以都是采用不写dao实现类的方式。    不管使用XML还是注解配置。    但是Mybatis它是支持写dao实现类的。</code></pre><p>6、自定义Mybatis的分析：<br>    mybatis在使用代理dao的方式实现增删改查时做什么事呢？<br>        只有两件事：<br>            第一：创建代理对象<br>            第二：在代理对象中调用selectList</p><pre><code>自定义mybatis能通过入门案例看到类    class Resources    class SqlSessionFactoryBuilder    interface SqlSessionFactory    interface SqlSession</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;mybatis框架&lt;br&gt;共四天&lt;br&gt;第一天：mybatis入门&lt;br&gt;    mybatis的概述&lt;br&gt;    mybatis的环境搭建&lt;br&gt;    mybatis入门案例&lt;br&gt;    自定义mybatis框架（主要的目的是为了让大家了解mybatis中执行细节）
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://erichunn.github.io/2019/09/07/Spark%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/09/07/Spark第一天/</id>
    <published>2019-09-07T08:22:05.593Z</published>
    <updated>2019-09-09T14:59:34.528Z</updated>
    
    <content type="html"><![CDATA[<h2 id="并行"><a href="#并行" class="headerlink" title="并行"></a>并行</h2><pre><code>集群计算。并行计算。</code></pre><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><pre><code>并发执行。</code></pre><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><pre><code>Lightning-fast cluster computing。快如闪电的集群计算。大规模快速通用的计算引擎。速度:    比hadoop 100x,磁盘计算快10x使用:    java / Scala /R /python        提供80+算子(操作符)，容易构建并行应用。通用:    组合SQL ，流计算 + 复杂分析。运行：    Hadoop, Mesos, standalone, or in the cloud,local.</code></pre><h2 id="Spark模块"><a href="#Spark模块" class="headerlink" title="Spark模块"></a>Spark模块</h2><pre><code>Spark core        //核心模块Spark SQL        //SQLSpark Streaming    //流计算Spark MLlib        //机器学习Spark graph        //图计算DAG        //direct acycle graph,有向无环图。</code></pre><h2 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h2><pre><code>1.下载spark-2.1.0-bin-hadoop2.7.tgz    ..2.解压    ..3.环境变量    [/etc/profile]    SPARK_HOME=/soft/spark    PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin    [source]    $&gt;source /etc/profile4.验证spark    $&gt;cd /soft/spark    $&gt;./spark-shell5.webui    http://s201:4040/</code></pre><h2 id="体验spark"><a href="#体验spark" class="headerlink" title="体验spark"></a>体验spark</h2><pre><code>0.sc    SparkContext，Spark程序的入口点，封装了整个spark运行环境的信息。1.进入spark-shell    $&gt;spark-shell    $scala&gt;sc</code></pre><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><pre><code>[SparkContext]    Spark程序的入口点，封装了整个spark运行环境的信息。[RDD]    resilient distributed dataset,弹性分布式数据集。等价于集合。</code></pre><h2 id="spark实现word-count"><a href="#spark实现word-count" class="headerlink" title="spark实现word count"></a>spark实现word count</h2><pre><code>//加载文本文件,以换行符方式切割文本.Array(hello  world2,hello world2 ,...)val rdd1 = sc.textFile(&quot;/home/centos/test.txt&quot;);//单词统计1$scala&gt;val rdd1 = sc.textFile(&quot;/home/centos/test.txt&quot;)$scala&gt;val rdd2 = rdd1.flatMap(line=&gt;line.split(&quot; &quot;))$scala&gt;val rdd3 = rdd2.map(word = &gt; (word,1))$scala&gt;val rdd4 = rdd3.reduceByKey(_ + _)$scala&gt;rdd4.collect//单词统计2sc.textFile(&quot;/home/centos/test.txt&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_ + _).collect//统计所有含有wor字样到单词个数。filter//过滤单词sc.textFile(&quot;/home/centos/test.txt&quot;).flatMap(_.split(&quot; &quot;)).filter(_.contains(&quot;wor&quot;)).map((_,1)).reduceByKey(_ + _).collect</code></pre><p>[API]<br>    SparkContext:<br>        Spark功能的主要入口点。代表到Spark集群的连接，可以创建RDD、累加器和广播变量.<br>        每个JVM只能激活一个SparkContext对象，在创建sc之前需要stop掉active的sc。</p><pre><code>SparkConf:    spark配置对象，设置Spark应用各种参数，kv形式。</code></pre><h2 id="编写scala程序，引入spark类库，完成wordcount"><a href="#编写scala程序，引入spark类库，完成wordcount" class="headerlink" title="编写scala程序，引入spark类库，完成wordcount"></a>编写scala程序，引入spark类库，完成wordcount</h2><pre><code>1.创建Scala模块,并添加pom.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;SparkDemo1&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;                &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;                &lt;version&gt;2.1.0&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;2.编写scala文件    import org.apache.spark.{SparkConf, SparkContext}    /**      * Created by Administrator on 2017/4/20.      */    object WordCountDemo {        def main(args: Array[String]): Unit = {            //创建Spark配置对象            val conf = new SparkConf();            conf.setAppName(&quot;WordCountSpark&quot;)            //设置master属性            conf.setMaster(&quot;local&quot;) ;            //通过conf创建sc            val sc = new SparkContext(conf);            //加载文本文件            val rdd1 = sc.textFile(&quot;d:/scala/test.txt&quot;);            //压扁            val rdd2 = rdd1.flatMap(line =&gt; line.split(&quot; &quot;)) ;            //映射w =&gt; (w,1)            val rdd3 = rdd2.map((_,1))            val rdd4 = rdd3.reduceByKey(_ + _)            val r = rdd4.collect()            r.foreach(println)        }    }</code></pre><h2 id="java版单词统计"><a href="#java版单词统计" class="headerlink" title="java版单词统计"></a>java版单词统计</h2><pre><code>import org.apache.spark.SparkConf;import org.apache.spark.SparkContext;import org.apache.spark.api.java.JavaPairRDD;import org.apache.spark.api.java.JavaRDD;import org.apache.spark.api.java.JavaSparkContext;import org.apache.spark.api.java.function.FlatMapFunction;import org.apache.spark.api.java.function.Function2;import org.apache.spark.api.java.function.PairFunction;import scala.Tuple2;import java.util.ArrayList;import java.util.Iterator;import java.util.List;/** * java版 */public class WordCountJava2 {    public static void main(String[] args) {        //创建SparkConf对象        SparkConf conf = new SparkConf();        conf.setAppName(&quot;WordCountJava2&quot;);        conf.setMaster(&quot;local&quot;);        //创建java sc        JavaSparkContext sc = new JavaSparkContext(conf);        //加载文本文件        JavaRDD&lt;String&gt; rdd1 = sc.textFile(&quot;d:/scala//test.txt&quot;);        //压扁        JavaRDD&lt;String&gt; rdd2 = rdd1.flatMap(new FlatMapFunction&lt;String, String&gt;() {            public Iterator&lt;String&gt; call(String s) throws Exception {                List&lt;String&gt; list = new ArrayList&lt;String&gt;();                String[] arr = s.split(&quot; &quot;);                for(String ss :arr){                    list.add(ss);                }                return list.iterator();            }        });        //映射,word -&gt; (word,1)        JavaPairRDD&lt;String,Integer&gt; rdd3 = rdd2.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {            public Tuple2&lt;String, Integer&gt; call(String s) throws Exception {                return new Tuple2&lt;String, Integer&gt;(s,1);            }        });        //reduce化简        JavaPairRDD&lt;String,Integer&gt; rdd4 = rdd3.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() {            public Integer call(Integer v1, Integer v2) throws Exception {                return v1 + v2;            }        });        //        List&lt;Tuple2&lt;String,Integer&gt;&gt; list = rdd4.collect();        for(Tuple2&lt;String, Integer&gt; t : list){            System.out.println(t._1() + &quot; : &quot; + t._2());        }    }}</code></pre><p>Spark2.1.0最新版是基于Scala2.11.8版本，因此安装scala2.11.8版本，</p><h2 id="否则如果基于2-12-0版本编译会出现找不到包的问题。"><a href="#否则如果基于2-12-0版本编译会出现找不到包的问题。" class="headerlink" title="否则如果基于2.12.0版本编译会出现找不到包的问题。"></a>否则如果基于2.12.0版本编译会出现找不到包的问题。</h2><pre><code>1.卸载原来的scala.2.重新安装scala2.11.8版本3.配置idea的全局库    project settings -&gt; global library -&gt; 删除原来的scala sdk    project settings -&gt; global library -&gt; 添加sdk -&gt; browser -&gt; 定位scala安装目录 -&gt;选中scala-compiler.jar +                                                                                         scala-library.jar +                                                                                         scala-reflect.jar4.在模块中添加scala sdk 2.11.8版本5.重新编译项目 -&gt; 导入jar -&gt;丢到集群运行。</code></pre><h2 id="提交作业到spark集群运行"><a href="#提交作业到spark集群运行" class="headerlink" title="提交作业到spark集群运行"></a>提交作业到spark集群运行</h2><pre><code>1.导出jar包2.spark-submit提交命令运行job    //Scala版本    $&gt;spark-submit --master local --name MyWordCount --class com.it18zhang.spark.scala.WordCountScala SparkDemo1-1.0-SNAPSHOT.jar /home/centos/test.txt    //java版    $&gt;spark-submit --master local --name MyWordCount --class com.it18zhang.spark.java.WordCountJava SparkDemo1-1.0-SNAPSHOT.jar /home/centos/test.txt</code></pre><h2 id="Spark集群模式"><a href="#Spark集群模式" class="headerlink" title="Spark集群模式"></a>Spark集群模式</h2><pre><code>1.local    nothing!    spark-shell --master local;        //默认2.standalone    独立模式。    a)复制spark安装目录到其他几个主机    b)配置其他主机的所有环境变量        [/etc/profile]        SPARK_HOME        PATH    c)配置master节点的slaves        [/soft/spark/conf/slaves]文件中添加下面的        s202        s203        s204    d)启动spark集群，和hadoop一样，但是要指定目录下即可。这个是独立模式和没有关系        /soft/spark/sbin/start-all.sh    e)查看进程        $&gt;xcall.jps jps            master        //s201            worker        //s202            worker        //s203            worker        //s204    e)webui，然后验证webui，8080端口。本地模式是4040端口        http://s201:8080/</code></pre><h2 id="提交作业jar到完全分布式spark集群"><a href="#提交作业jar到完全分布式spark集群" class="headerlink" title="提交作业jar到完全分布式spark集群"></a>提交作业jar到完全分布式spark集群</h2><pre><code>1.需要启动hadoop集群(只需要hdfs，是standalone模式，不需要yarn调度)    $&gt;start-dfs.sh2.put文件到hdfs.3.运行spark-submit    $&gt;spark-submit                 --master spark://s201:7077                 --name MyWordCount                 --class com.it18zhang.spark.scala.WordCountScala                 SparkDemo1-1.0-SNAPSHOT.jar                 hdfs://s201:8020/user/centos/test.txt</code></pre><h2 id="脚本分析"><a href="#脚本分析" class="headerlink" title="脚本分析"></a>脚本分析</h2><pre><code>[start-all.sh]    sbin/spark-config.sh    sbin/spark-master.sh        //启动master进程    sbin/spark-slaves.sh        //启动worker进程[start-master.sh]    sbin/spark-config.sh    org.apache.spark.deploy.master.Master    spark-daemon.sh start org.apache.spark.deploy.master.Master --host --port --webui-port ...[spark-slaves.sh]    sbin/spark-config.sh    slaves.sh                //主要循环这个文件conf/slaves[slaves.sh]    for conf/slaves{        ssh host start-slave.sh ...    }[start-slave.sh]</code></pre><p>先找到这个work类<br>        CLASS=”org.apache.spark.deploy.worker.Worker”<br>        sbin/spark-config.sh 走这个配置<br>        for ((  .. )) ; do<br>            start_instance $(( 1 + $i )) “$@”<br>        done </p><pre><code>$&gt;cd /soft/spark/sbin$&gt;./stop-all.sh                //停掉整个spark集群.$&gt;./start-master.sh            //停掉整个spark集群.$&gt;./start-master.sh            //启动master节点$&gt;./start-slaves.sh            //启动所有worker节点从s204里面启动某一个slave ./start-slave.sh spark://s201:7077对上面几个命令了解可以通过 start-master.sh --help来查询，其他类似</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;并行&quot;&gt;&lt;a href=&quot;#并行&quot; class=&quot;headerlink&quot; title=&quot;并行&quot;&gt;&lt;/a&gt;并行&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;集群计算。
并行计算。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;并发&quot;&gt;&lt;a href=&quot;#并发&quot; class=&quot;head
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>编程题</title>
    <link href="http://erichunn.github.io/2019/03/04/%E7%BC%96%E7%A8%8B%E9%A2%98/"/>
    <id>http://erichunn.github.io/2019/03/04/编程题/</id>
    <published>2019-03-04T06:40:20.000Z</published>
    <updated>2019-03-04T06:48:40.118Z</updated>
    
    <content type="html"><![CDATA[<p>public class Problem3 {<br>    public static void main1(String[] args) {<br>        int[] arr = new int[]{2, 3, 1, 0, 2, 5, 3};<br>        int[] ints = new int[10];<br>        boolean duplicate = duplicate(arr, 6, ints);<br>        System.out.println(ints[0]);</p><pre><code>    System.out.println();}public static boolean duplicate(int numbers[], int length, int[] duplication) {    if (numbers == null || length &lt;= 0)        return false;    for (int a : numbers) {        if (a &lt; 0 || a &gt;= length)            return false;    }    int temp;    for (int i = 0; i &lt; length; i++) {        while (numbers[i] != i) {            if (numbers[numbers[i]] == numbers[i]) {                duplication[0] = numbers[i];                return true;            }            temp = numbers[i];            numbers[i] = numbers[temp];            numbers[temp] = temp;        }    }    return false;}</code></pre><p>//另一种方法<br>    /**</p><pre><code> * 避免使用辅助空间 */public int getDuplication(int[] arr){    for(int i = 0;i &lt; arr.length;i++)    {        if(arr[i] &lt; 0 || arr[i] &gt;= arr.length)            throw new IllegalArgumentException(&quot;输入参数不合法&quot;);    }    int start = 0;    int end = arr.length-1;    int flag = 0;    int middle = 0;    while(end &gt;= start)    {        if(flag == 0)            middle = (end + start)/2;        int count = countRange(arr,start,middle);        if(end == start)        {            if(count &gt; 1)                return start;            else                break;        }        if(count &gt; (middle-start+1))//说明(start,middle)这个区间有重复的数        {            end = middle;            flag = 0;        }else if(count == (middle-start+1))//不能判断(start,middle)这个区间有重复的数        {            middle = middle - 1;            if(middle &lt; start)//说明(start,middle)这个区间没有重复的数            {                start = (start+end)/2 + 1;                flag = 0;            }else                flag = 1;        }else //说明(middle+1,end)这个区间有重复的数        {            start = middle + 1;            flag = 0;        }    }    return -1;}private int countRange(int[] arr, int start, int end){    int count = 0;    for(int i = 0;i &lt; arr.length;i++)    {        if(arr[i] &gt;= start &amp;&amp; arr[i] &lt;= end)            ++count;    }    return count;}public  static void main(String[] args) {    Problem3 test = new Problem3();    int[] arr = {0,3,5,4,1,2,6,7};    int value = test.getDuplication(arr);}</code></pre><p>}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;public class Problem3 {&lt;br&gt;    public static void main1(String[] args) {&lt;br&gt;        int[] arr = new int[]{2, 3, 1, 0, 2, 5, 3};&lt;br&gt;      
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>剑指offer第45题</title>
    <link href="http://erichunn.github.io/2019/01/28/%E5%89%91%E6%8C%87offer%E7%AC%AC45%E9%A2%98/"/>
    <id>http://erichunn.github.io/2019/01/28/剑指offer第45题/</id>
    <published>2019-01-28T13:12:17.000Z</published>
    <updated>2019-01-28T13:13:24.689Z</updated>
    
    <content type="html"><![CDATA[<p>关于compare排序的讲解：<br><a href="https://blog.csdn.net/lx_nhs/article/details/78871295" target="_blank" rel="noopener">https://blog.csdn.net/lx_nhs/article/details/78871295</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;关于compare排序的讲解：&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/lx_nhs/article/details/78871295&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/l
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目面试总结</title>
    <link href="http://erichunn.github.io/2019/01/15/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/"/>
    <id>http://erichunn.github.io/2019/01/15/实战大数据电信项目面试总结/</id>
    <published>2019-01-15T14:27:10.000Z</published>
    <updated>2019-01-16T08:10:04.084Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/GR90bE7.png" alt=""></p><p>4.Hadoop以及HBase的HA集群配置与实战。<br>  hadoop的使用QJM的高可用架构配置讲解，ResourceManager的高可用架构配置讲解。<br>  zookeeper的工作原理以及配置、实操演练，hbase与Hadoop HA集成注意事项以及客户端<br>  API编程细节处理。</p><h2 id="hadoop-HDFS-HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾"><a href="#hadoop-HDFS-HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾" class="headerlink" title="hadoop HDFS HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾"></a>hadoop HDFS HA高可用配置也就是实现2个namenode一个active一个standby，利用zk实现自动容灾</h2><p>配置hdfs-site和core-site.xml指定zk地址。</p><pre><code>自动容灾引入两个组件，zk quarum + zk容灾控制器(ZKFC)。运行NN的主机还要运行ZKFC进程，主要负责:a.健康监控b.session管理c.选举</code></pre><h2 id="resourcemanager自动容灾配置"><a href="#resourcemanager自动容灾配置" class="headerlink" title="resourcemanager自动容灾配置"></a>resourcemanager自动容灾配置</h2><p>对yarn-site.xml进行配置配置自动容灾并且将zk地址配制进去。</p><h2 id="部署zk集群"><a href="#部署zk集群" class="headerlink" title="部署zk集群"></a>部署zk集群</h2><p>1、配置zk配置文件</p><p> [/soft/zk/conf/zoo.cfg]<br>    …<br>    dataDir=/home/centos/zookeeper</p><pre><code>server.1=s201:2888:3888server.2=s202:2888:3888 server.3=s203:2888:3888</code></pre><p>2、在每台主机的/home/centos/zookeeper中添加myid,内容分别是1,2,3</p><h2 id="配置HBase和Hbase高可用"><a href="#配置HBase和Hbase高可用" class="headerlink" title="配置HBase和Hbase高可用"></a>配置HBase和Hbase高可用</h2><h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><p>1、安装后配置环境后在修改配置文件[hbase/conf/hbase-env.sh]，添加hbase在hdfs存放路径、zk地址、zk本地目录、使用完全分布式true。</p><p>2、配置regionservers</p><pre><code>[hbase/conf/regionservers]s202s203s204</code></pre><h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>直接在2台机器上执行命令：</p><p>hbase-daemon.sh start master</p><h2 id="配置Kafka集群"><a href="#配置Kafka集群" class="headerlink" title="配置Kafka集群"></a>配置Kafka集群</h2><p>1、配置kafka<br>    [kafka/config/server.properties]<br>    …<br>    broker.id=202<br>    …<br>    listeners=PLAINTEXT://:9092<br>    …<br>    log.dirs=/home/centos/kafka/logs<br>    …<br>    zookeeper.connect=s201:2181,s202:2181,s203:2181</p><p>2、分发server.properties，同时修改每个文件的broker.id</p><h2 id="配置Flume"><a href="#配置Flume" class="headerlink" title="配置Flume"></a>配置Flume</h2><p>配置flume将其配置文件修改为source为某个文件夹，然后sink为kafka集群</p><hr><h2 id="创建hbase名字空间-表"><a href="#创建hbase名字空间-表" class="headerlink" title="创建hbase名字空间+表"></a>创建hbase名字空间+表</h2><pre><code>1.创建名字空间和表。表是：名字空间+列族。    $&gt;hbase shell                        //进入hbase shell    $hbase&gt;create_namespace &apos;ns1&apos;        //创建空间    $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;    //创建表    $hbase&gt;truncate &apos;ns1:calllogs&apos;        //重建表</code></pre><h2 id="创建kafka消费者，订阅calllog主题"><a href="#创建kafka消费者，订阅calllog主题" class="headerlink" title="创建kafka消费者，订阅calllog主题"></a>创建kafka消费者，订阅calllog主题</h2><pre><code>1.设计rowkey    业务数据: caller , callee , date , duration    分区号    号码     时间,标记  (对方号码),时长    regionNo, caller,date , flag,callee,duration    caller(11) + 通话时间(201701) =     (后四位) + 201701 = % 100</code></pre><p>对日志信息进行整理，删除多余的部分如/:之类的<br>解析日志数据将日志数据截取串，实例化put对象，插入Hbase中去。</p><p>打成jar包放到classpath之中，将kafka消费者打成Jar包，并且，用maven在windows将其的依赖都下载下来放到classpath当中。</p><p>将这个文件夹都放置到Linux下，然后写一个执行这个jar包的脚本：</p><pre><code>java -cp CallLogConsumerModule.jar;./lib/activation-1.1.jar;./lib/apacheds-i18n-2.0.0-M15.jar;./lib/apacheds-kerberos-codec-2.0.0-M15.jar;./lib/api-asn1-api-1.0.0-M20.jar;./lib/api-util-1.0.0-M20.jar;./lib/avro-1.7.4.jar;./lib/commons-beanutils-1.7.0.jar;./lib/commons-beanutils-core-1.8.0.jar;./lib/commons-cli-1.2.jar;./lib/commons-codec-1.9.jar;./lib/commons-collections-3.2.2.jar;./lib/commons-compress-1.4.1.jar;./lib/commons-configuration-1.6.jar;./lib/commons-digester-1.8.jar;./lib/commons-el-1.0.jar;./lib/commons-httpclient-3.1.jar;./lib/commons-io-2.4.jar;./lib/commons-lang-2.6.jar;./lib/commons-logging-1.2.jar;./lib/commons-math3-3.1.1.jar;./lib/commons-net-3.1.jar;./lib/findbugs-annotations-1.3.9-1.jar;./lib/guava-12.0.1.jar;./lib/hadoop-annotations-2.5.1.jar;./lib/hadoop-auth-2.5.1.jar;./lib/hadoop-common-2.5.1.jar;./lib/hadoop-mapreduce-client-core-2.5.1.jar;./lib/hadoop-yarn-api-2.5.1.jar;./lib/hadoop-yarn-common-2.5.1.jar;./lib/hamcrest-core-1.3.jar;./lib/hbase-annotations-1.2.4.jar;./lib/hbase-client-1.2.4.jar;./lib/hbase-common-1.2.4.jar;./lib/hbase-protocol-1.2.4.jar;./lib/htrace-core-3.1.0-incubating.jar;./lib/httpclient-4.2.5.jar;./lib/httpcore-4.2.4.jar;./lib/jackson-core-asl-1.9.13.jar;./lib/jackson-mapper-asl-1.9.13.jar;./lib/jaxb-api-2.2.2.jar;./lib/jcodings-1.0.8.jar;./lib/jdk.tools-1.6.jar;./lib/jetty-util-6.1.26.jar;./lib/jline-0.9.94.jar;./lib/joni-2.1.2.jar;./lib/jopt-simple-4.9.jar;./lib/jsch-0.1.42.jar;./lib/jsr305-1.3.9.jar;./lib/junit-4.12.jar;./lib/kafka-clients-0.10.0.1.jar;./lib/kafka_2.11-0.10.0.1.jar;./lib/log4j-1.2.15.jar;./lib/lz4-1.3.0.jar;./lib/mail-1.4.jar;./lib/metrics-core-2.2.0.jar;./lib/netty-3.7.0.Final.jar;./lib/netty-all-4.0.23.Final.jar;./lib/paranamer-2.3.jar;./lib/protobuf-java-2.5.0.jar;./lib/scala-library-2.11.8.jar;./lib/scala-parser-combinators_2.11-1.0.4.jar;./lib/slf4j-api-1.6.1.jar;./lib/slf4j-log4j12-1.7.21.jar;./lib/snappy-java-1.1.2.6.jar;./lib/stax-api-1.0-2.jar;./lib/xmlenc-0.52.jar;./lib/xz-1.0.jar;./lib/zkclient-0.8.jar;./lib/zookeeper-3.4.6.jar com.it18zhang.calllog.consumer.HbaseConsumer</code></pre><p>执行kafak消费者</p><h2 id="业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）"><a href="#业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）" class="headerlink" title="业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）"></a>业务场景一：输入电话号码查询所有该用户所有通话记录（利用Hbase查询）</h2><p>通过在service中建立和hbase的连接，通过使用scan对象，将查询的内容填充到实体类中，将实体类添加到list当中去，然后返回list，在controller层调用service层的findall方法。返回给前段，前段通过jsp界面，将返回的数据填充到表格中去。</p><h2 id="业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫-利用hbase查询"><a href="#业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫-利用hbase查询" class="headerlink" title="业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫(利用hbase查询)"></a>业务场景二：根据主叫和开始时间年月，结束时间年月来查询该用户的通话记录包括主叫和被叫(利用hbase查询)</h2><p>这块就有点内容了，首先hbase的rowkey的实际根据实际的业务需要把rowkey设置成reginonumber,callerid calltime(精确到分) flag calleeid duration.为什么设置成这样根据rowkey的设计原则，吧尽可能多的内容设计到rowkey里面，可以直接查询的到。最常用的放到前面，可以通过callerid和time直接查询的到。设计成不同的regionnumber将不同的号码进行类似于分桶可以切割放到不同的服务器里面。</p><p>在查询rowkey的时候考虑到根据时间段查询的时候，由于rowkey的设计是哈希号，主叫，时间，被叫，所以哈希号是个根据主叫+时间（年月）来设计的，这块根据主叫+年月的设计是因为要是淡出根据手机号来哈希的话大多数都是138值类的会造成热点问题。所以根据时间+手机号来设计，然后搜易在根据时间来查找的时候，要考虑起止时间是否是同年月，不同年月，如果是同年月的话就是说在同一个哈希号之间，开始时间就是开始时间，结束时间是day+1，前包后不包，如果是不同年月的话就在不同的区号之间，比如是2017.3.11-2017.5.9就要搜索2017.3.11-2017.4,2017.4-2017.5,2017.5-2017,5,9</p><p>要取到callerid+年月作为hash的值而不能取到时，分作为哈希的值，因为取到时，分的话就每个都是不一样的哈希的值，查询的时候就要根据时分来查询而不能根据年月来查询。因为每次查询的时候要指定callerid和年月。如果是根据callerid+时分来计算的话，每次存储的时候即便是同一天同一个月也不会分散的同一个哈希区域，而是分散到不同的区域，难以查询到，如果是这样只能通过每一分钟每一分钟的查询，没法查询了。</p><p>由于在输入数据的时候只是插入主叫的数据，在查询通话详单的时候要查询该号码即是主叫，又是被叫的情况下，在rowkey是rno,callerid,calltime,calleeid,calleeid,duration的情况下要查询位置在后面的calleeid的情况下，几乎要全表扫描。所以这块我们在每次put进来数据的时候我们使用协处理器，每次添加主叫的时候，在添加一个被叫。这个被叫的Rowkey是哈希+被叫+时间+1+主叫+时长。然后在put这个被叫的时候区域号也就是rno还是根据主叫+时间片来哈希的。就可以让被叫信息和主叫信息在同一个哈希区域内，然后插入flag=1的rowkey，然后他的value值就是原来主叫表的rowkey的各个值。这样的话避免了将之前主叫表的冗余的value在重复插入一遍。也就是一个二级索引的思想，在协处理器里面重写Postput方法和postScannerNext()方法，postput方法的作用就是在插入一条主叫记录的同时，在插入一条被叫记录，而postgetOp()方法的作用是查询被叫返回主叫信息。在查询的时候用的是scan的API然后查询value值，所以在查询被叫的时候让他返回主叫信息，（这边视频中这边考虑的是如果得到rowkey还需要解析，就算了这样说的），</p><h2 id="业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）"><a href="#业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）" class="headerlink" title="业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）"></a>业务场景三：输入手机号和开始年月，结束年月，查询用户通话记录的主叫被叫实名（利用hiveSQL）</h2><p>业务场景是吧人员信息放到一个简单的关系型数据库中，也就是人员信息在公安部的信息中，然后实现一个和关系型数据库的交互查询    。</p><h2 id="查询电话号码最近通话记录"><a href="#查询电话号码最近通话记录" class="headerlink" title="查询电话号码最近通话记录"></a>查询电话号码最近通话记录</h2><p>通过完成hive到hbase表的映射，实现对最近通话信息的查询，<br>从现有手段hbase查询，首先rowkey没法确定。rowkey是手机号+年份+月份。因为每个月份的哈希code都不一样，所以只能一个月一个月查。很麻烦。但是我们可以通过hive里面的max()聚集函数查询，借助于mr，也就是用Hive查询。通过hive操纵hbase里面的表，创建一个外部表映射到hbase上去通过Hive的聚集函数通过max min count等聚集函数来查询。</p><p><img src="https://i.imgur.com/FFumqvN.png" alt=""></p><p>由于hive操作是通过hive和beeline来操作。hive客户端只能本地使用并且不能并发，所以使用hiveserver2服务通过beeline.sh这个脚本，㑨10000，走的是thrift服务器。而ssm是通过ssm里面的service通过jdbc和hiveserver2交互，hiveserver2找到hive外部表并且操作这个是走的jdbc可以实现远程访问。</p><p>那么怎样在hive里面查询最近通话详单呢：（最近一条记录）<br>$hive&gt;select * from ext_calllogs_in_hbase where id like ‘%xxxx%’ order by callTime desc limit 1 ;</p><p><img src="https://i.imgur.com/7N6lXVy.png" alt=""></p><h2 id="业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）"><a href="#业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）" class="headerlink" title="业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）"></a>业务场景四：查询用户各个月份的通话次数并且以echart柱状图展示（利用HiveSQL）</h2><p>hive中查询某个人一年的通话记录按月份进行分组：</p><p>select count(*) , substr(calltime,1,6) from ext_calllogs_in_hbase where caller = ‘15032293356’ and substr(calltime,1,4) == ‘2017’ group by substr(calltime,1,6) ;</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/GR90bE7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.Hadoop以及HBase的HA集群配置与实战。&lt;br&gt;  hadoop的使用QJM的高可用架构配置讲解，ResourceManager的高可用架构配置讲
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（四）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E5%9B%9B%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（四）/</id>
    <published>2019-01-11T07:56:51.000Z</published>
    <updated>2019-01-15T12:30:08.565Z</updated>
    
    <content type="html"><![CDATA[<p>hive统计某个人的通话次数：<br>数据在kafka最多是7天时间。<br>hive中查询某个人一年的通话记录按月份进行分组：<br>select count(*) , substr(calltime,1,6) from ext_calllogs_in_hbase where caller = ‘15032293356’ and substr(calltime,1,4) == ‘2017’ group by substr(calltime,1,6) ;</p><p>要写hiveservice，在里面添加</p><pre><code>1.HiveCallLogService.java        /**         * 查询指定人员指定年份中各个月份的通话次数         */        public List&lt;CallLogStat&gt; statCallLogsCount(String caller, String year){            List&lt;CallLogStat&gt; list = new ArrayList&lt;CallLogStat&gt;() ;            try {                Connection conn = DriverManager.getConnection(url);                Statement st = conn.createStatement();                String sql = &quot;select count(*) ,substr(calltime,1,6) from ext_calllogs_in_hbase &quot; +                        &quot;where caller = &apos;&quot; + caller+&quot;&apos; and substr(calltime,1,4) == &apos;&quot; + year                        + &quot;&apos; group by substr(calltime,1,6);&quot;;                ResultSet rs = st.executeQuery(sql);                CallLog log = null;                while (rs.next()) {                    CallLogStat logSt = new CallLogStat();                    logSt.setCount(rs.getInt(1));                    logSt.setYearMonth(rs.getString(2));                    list.add(logSt);                }                rs.close();                return list;            } catch (Exception e) {                e.printStackTrace();            }            return null;        }</code></pre><p>2.CallLogController.java</p><pre><code>    /**     * 统计指定人员，指定月份的通话次数     */    @RequestMapping(&quot;/callLog/toStatCallLog&quot;)    public String toStatCallLog(){        return &quot;callLog/statCallLog&quot; ;    }    /**     * 统计指定人员，指定月份的通话次数     */    @RequestMapping(&quot;/callLog/statCallLog&quot;)    public String statCallLog(Model m ,@RequestParam(&quot;caller&quot;) String caller ,@RequestParam(&quot;year&quot;) String year){        List&lt;CallLogStat&gt; list = hcs.statCallLogsCount(caller, year);        m.addAttribute(&quot;stat&quot; , list) ;        return &quot;callLog/statCallLog&quot; ;    }3.statCallLog.jsp    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;通话记录统计结果&lt;/title&gt;        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;        &lt;script type=&quot;text/javascript&quot; src=&quot;../js/jquery-3.2.0.min.js&quot;&gt;&lt;/script&gt;        &lt;script type=&quot;text/javascript&quot;&gt;            //定义函数            function refreshTable(){                $(&quot;#t1 tbody&quot;).empty();                $.getJSON(&quot;/callLog/json/findAll&quot;, function (data) {                    $.each(data, function (i, obj) {                        var str = &quot;&lt;tr&gt;&lt;td&gt;&quot; + obj.caller + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callerName + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callee + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.calleeName + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callTime + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;td&gt; &quot; + obj.callDuration + &quot;&lt;/td&gt;&quot;;                        str = str + &quot;&lt;/tr&gt;&quot;;                        $(&quot;#t1 tbody&quot;).append(str);                    });                });            }            $(function(){                setInterval(refreshTable, 2000);            })        &lt;/script&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;form action=&apos;&lt;c:url value=&quot;/callLog/statCallLog&quot; /&gt;&apos; method=&quot;post&quot;&gt;            电话号码 : &lt;input type=&quot;text&quot; name=&quot;caller&quot;&gt;&lt;br&gt;            年 份:  &lt;input type=&quot;text&quot; name=&quot;year&quot;&gt;&lt;br&gt;            &lt;input type=&quot;submit&quot; name=&quot;查询&quot;&gt;        &lt;/form&gt;        &lt;br&gt;        &lt;table id=&quot;t1&quot; border=&quot;1px&quot; class=&quot;t-1&quot; style=&quot;width: 800px&quot;&gt;            &lt;thead&gt;                &lt;tr&gt;                    &lt;td&gt;月份&lt;/td&gt;                    &lt;td&gt;次数&lt;/td&gt;                &lt;/tr&gt;            &lt;/thead&gt;            &lt;tbody&gt;                &lt;c:forEach items=&quot;${stat}&quot; var=&quot;s&quot;&gt;                    &lt;tr&gt;                        &lt;td&gt;&lt;c:out value=&quot;${s.yearMonth}&quot;/&gt;&lt;/td&gt;                        &lt;td&gt;&lt;c:out value=&quot;${s.count}&quot;/&gt;&lt;/td&gt;                    &lt;/tr&gt;                &lt;/c:forEach&gt;            &lt;/tbody&gt;        &lt;/table&gt;    &lt;/body&gt;    &lt;/html&gt;</code></pre><h2 id="做了一个xcall-sh和xkill脚本"><a href="#做了一个xcall-sh和xkill脚本" class="headerlink" title="做了一个xcall.sh和xkill脚本"></a>做了一个xcall.sh和xkill脚本</h2><p>[xkill.sh]</p><pre><code>#!/bin/bashpids=`jps | grep $1 | awk &apos;{print $1}&apos;`for pid in $pids ; do    kill -9 $piddone</code></pre><p>[xcall.sh]</p><pre><code>#!/bin/bashparams=$@i=201for (( i=201 ; i &lt;= 206 ; i = $i + 1 )) ; do    tput setaf 2    echo ============= s$i =============    tput setaf 7    ssh -4 s$i &quot;source /etc/profile ; $params&quot;done</code></pre><p>//开启kafka集群<br>[/usr/local/bin/xkafka-cluster-start.sh]</p><pre><code>#!/bin/bashservsers=&quot;s202 s203 s204&quot;for s in $servers ; do    ssh $s &quot;source /etc/profile ; kafka-server-start.sh -daemon /soft/kakfa/config/server.properties&quot;done</code></pre><p>//启动zk集群<br>[/usr/local/bin/xzk-cluster-start.sh]</p><pre><code>#!/bin/bashservers=&quot;s201 s202 s203&quot;for s in $servers ; do    ssh $s &quot;source /etc/profile ; zkServer.sh start&quot;done</code></pre><p>//xconsumer-start.sh<br>[/usr/local/bin/xconsumer-start.sh]</p><pre><code>#!/bin/bashcd /home/centos/KafkaHbaseConsumerrun.sh &amp;</code></pre><p>//s201:xflume-calllog-start.sh<br>[/usr/local/bin/xconsumer-start.sh]</p><pre><code>#!/bin/bashcd /soft/flume/confflume-ng agent -f calllog.conf -n a1 &amp;</code></pre><hr><p>查询所有用户的各个月份的通话次数     </p><p>使用echart实现数据可视化</p><p>业务场景：根据电话号码，年份实现每个月的电话次数以echar可视化的图标展示<br>通过在service连接hive服务器，执行Hivesql查询查询到的内容，通过controller层调用返回的内容传到前台。前台jsp界面继承echart和c标签库展示后台查询的内容</p><p>在集群中安装ganglia监控集群CPU内存进程监控fulme kafka gendata数据生成进程    </p><h2 id="ganglia"><a href="#ganglia" class="headerlink" title="ganglia"></a>ganglia</h2><pre><code>集群监控.不仅能够监控单个主机的资源情况，还可以对集群整个资源进行统计。gmond            //在每个节点收集资源数据的。gmetad            //接受每个节点发送资源数据gweb            //webui,展示数据web程序，和gmetad通信。</code></pre><h2 id="安装ganglia"><a href="#安装ganglia" class="headerlink" title="安装ganglia"></a>安装ganglia</h2><pre><code>1.ganglia-gmond    所有节点。    $&gt;sudo yum install -y ganglia-gmond2.ganglia-gmetad    s201    $&gt;sudo yum install -y ganglia-gmetad3.ganglia-gweb    [s201]    a)安装依赖        $&gt;sudo yum install -y httpd php    b)下载ganglia-web-3.5.12.tar.gz程序        wget http://ncu.dl.sourceforge.net/project/ganglia/ganglia-web/3.5.12/ganglia-web-3.5.12.tar.gz    c)tar开文件    d)修改Makefile文件，执行编译命令sudo make install        ...    e)启动服务        [s201]        $&gt;sudo service httpd start         $&gt;sudo service gmetad start         $&gt;sudo service gmond start         [s202]        $&gt;sudo service gmond start </code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;hive统计某个人的通话次数：&lt;br&gt;数据在kafka最多是7天时间。&lt;br&gt;hive中查询某个人一年的通话记录按月份进行分组：&lt;br&gt;select count(*) , substr(calltime,1,6) from ext_calllogs_in_hbase whe
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（三）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%89%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（三）/</id>
    <published>2019-01-11T07:56:40.000Z</published>
    <updated>2019-01-16T07:53:04.472Z</updated>
    
    <content type="html"><![CDATA[<p>前段请求和hive交互，在hive之中创建外部表，映射到Hbase当中<br>一般hive在远端通过jdbc方式来交互，要想走jdbc协议hive还需要打开hiveserver2，其实就是启动thrift服务器，端口是10000.而ssm是在controller里面，交互service在SSM里面得有一个service。service通过jdbc协议和hive server2交互，转换hive语句，在通过hbase交互。</p><p>为什么要用到Hive映射到hbase表：</p><h2 id="要想查询用户最近通话信息-，"><a href="#要想查询用户最近通话信息-，" class="headerlink" title="要想查询用户最近通话信息 ##，"></a>要想查询用户最近通话信息 ##，</h2><p>从现有手段hbase查询，首先rowkey没法确定。rowkey是手机号+年份+月份。因为每个月份的哈希code都不一样，所以只能一个月一个月查。很麻烦。但是我们可以通过hive里面的max()聚集函数查询，借助于mr，也就是用Hive查询。通过hive操纵hbase里面的表，创建一个外部表映射到hbase上去通过Hive的聚集函数通过max min count等聚集函数来查询。</p><p><img src="https://i.imgur.com/FFumqvN.png" alt=""></p><p>由于hive操作是通过hive和beeline来操作。hive客户端只能本地使用并且不能并发，所以使用hiveserver2服务通过beeline.sh这个脚本，㑨10000，走的是thrift服务器。而ssm是通过ssm里面的service通过jdbc和hiveserver2交互，hiveserver2找到hive外部表并且操作这个是走的jdbc可以实现远程访问。</p><p>那么怎样在hive里面查询最近通话详单呢：（最近一条记录）<br>$hive&gt;select * from ext_calllogs_in_hbase where id like ‘%xxxx%’ order by callTime desc limit 1 ;</p><p><img src="https://i.imgur.com/7N6lXVy.png" alt=""></p><p>1.SSm中创建service做一个hive的聚集表的查询，查询最近的通话记录进行Mr查询。加一个pom的hive驱动<br>    @Service(“hiveCallLogService”)<br>    public class HiveCallLogService {</p><pre><code>    //hiveserver2连接串    private static String url = &quot;jdbc:hive2://s201:10000/&quot; ;    //驱动程序类    private static String driverClass = &quot;org.apache.hive.jdbc.HiveDriver&quot; ;    static{        try {            Class.forName(driverClass);        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 查询最近的通话记录,使用hive进行mr查询.     */    public CallLog findLatestCallLog(String phoneNum){        try {            Connection conn = DriverManager.getConnection(url);            Statement st = conn.createStatement();            String sql = &quot;select * from ext_calllogs_in_hbase where id like &apos;%&quot;+ phoneNum+&quot;%&apos; order by callTime desc limit 1&quot; ;            ResultSet rs = st.executeQuery(sql);            CallLog log = null ;            if(rs.next()){                log = new CallLog();                log.setCaller(rs.getString(&quot;caller&quot;));                log.setCallee(rs.getString(&quot;caller&quot;));                log.setCallTime(rs.getString(&quot;callTime&quot;));                log.setCallDuration(rs.getString(&quot;callDuration&quot;));            }            rs.close();            return log ;        } catch (Exception e) {             e.printStackTrace();        }        return null ;    }}</code></pre><p>在controller层添加内容：</p><pre><code>/**     * 查询最近通话记录     */    @RequestMapping(value = &quot;/callLog/findLatestCallLog&quot;,method = RequestMethod.POST)    public String findLatestCallLog(Model m , @RequestParam(&quot;caller&quot;) String caller){        CallLog log = hcs.findLatestCallLog(caller);        if(log != null){            m.addAttribute(&quot;log&quot;, log);        }        return &quot;callLog/latestCallLog&quot; ;    }    /**     * 查询最近通话记录     */    @RequestMapping(value = &quot;/callLog/toFindLatestCallLog&quot;)    public String toFindLatestCallLog(){        return &quot;callLog/findLatestCallLog&quot; ;    }}</code></pre><p>jsp界面编写：</p><pre><code>&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;通话记录&lt;/title&gt;    &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;&lt;/head&gt;&lt;body&gt;    &lt;c:if test=&quot;${log == null}&quot;&gt;        无记录！    &lt;/c:if&gt;    &lt;c:if test=&quot;${log != null}&quot;&gt;        &lt;table id=&quot;t1&quot; border=&quot;1px&quot; class=&quot;t-1&quot; style=&quot;width: 800px&quot;&gt;            &lt;tr&gt;                &lt;td&gt;电话1&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.caller}&quot; /&gt;&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;电话2&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.callee}&quot;/&gt;&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;时间&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.callTime}&quot;/&gt;&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;时长&lt;/td&gt;                &lt;td&gt;&lt;c:out value=&quot;${log.callDuration}&quot;/&gt;&lt;/td&gt;            &lt;/tr&gt;        &lt;/table&gt;    &lt;/c:if&gt;&lt;/body&gt;&lt;/html&gt;    </code></pre><p>在中间有一个报错问题：<br><img src="https://i.imgur.com/qyHtkg0.png" alt=""><br><img src="https://i.imgur.com/V9gqUmv.png" alt=""><br><img src="https://i.imgur.com/QCKt99s.png" alt=""><br>解决办法是更新继承的tomcat倒9。0版本。然后hive的依赖百年城1.2.1</p><h2 id="然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容"><a href="#然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容" class="headerlink" title="然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容"></a>然后做一个增加人员信息的内容：然后完成一个人员信息查询在界面显示的内容</h2><p>业务场景是吧人员信息放到一个简单的关系型数据库中，也就是人员信息在公安部的信息中，然后实现一个和关系型数据库的交互查询    </p><pre><code>1.建表create table persons(id ...) ;2.domainpublic class Person {    private Integer id ;    private String name ;    private String phone  ;    ...}3.dao4.service5.</code></pre><p>//在查询之中集成MYSQL的查询到的内容，整理一下下就是写mapper的SQL语句，在DAO层getSqlSession().selectOne(“persons.selectNameByPhone”,phone)通过这句话来返回，然后service层调用这个方法，然后在到personserviceimpl中调用这个方法，然后在calllogseriviceimpl中调用这个方法返回内容填充到实体类里面，controller层调用这些方法然后在jsp文件里面进行一个内容的填充。<br>——————</p><h2 id="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制"><a href="#MR运行参数配置，关闭物理内存和虚拟内存对容器的限制" class="headerlink" title="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制"></a>MR运行参数配置，关闭物理内存和虚拟内存对容器的限制</h2><pre><code>默认限制是开启的，最多分配给容器8G的物理内存，虚拟内存是物理内存的2.1倍。[yarn-site.xml]&lt;property&gt;    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;    &lt;value&gt;8192&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;    &lt;value&gt;2.1&lt;/value&gt;&lt;/property&gt;</code></pre><hr><p>0310然后实现一个生成带名字的数据源的代码。然后要做一个局部刷新的fastjson。<br>0311实现一个通过服务器返回给客户端json格式的内容，通过集成jQuery实现ajax访问，动态刷新通话记录。</p><p>启动顺序，先启动kafka，启动kafka消费者，启动flume，启动ssm，启动日志生成程序。.<br>flume-ng agent -f calllog.conf -n a1在s201中<br>kafka-server-start.sh -daemon /soft/kafka/config/server.properties启动3个<br>启动kafka消费者：kafka-console-consumer.sh –zookeeper s202:2181 –topic calllog<br>开启hadoop集群和hbase集群</p><p>真机使用：<br>10个kafka3台zk我们是1，2，3是zk。3台zk里面分配好myid。配置好zoo.cfg里面配置好3台主机的Ip地址<br>kafka配置配置kafka/config/server.properties 。kafka依赖于zk在kafka的配置文件里面配置zk的ip<br>单独安装flume配置配置文件。配置source channel sink<br>一边生成日志一边搜集。</p><hr><h2 id="协处理器-批处理。"><a href="#协处理器-批处理。" class="headerlink" title="协处理器:批处理。"></a>协处理器:批处理。</h2><pre><code>1.类似于触发器。    完成被叫日志的写入过程。2.重写postPut()/postGetOp()/postScannNext();    put / get / scann    直接返回主叫。</code></pre><h2 id="按时间段查询通话记录"><a href="#按时间段查询通话记录" class="headerlink" title="按时间段查询通话记录"></a>按时间段查询通话记录</h2><pre><code>hashcode            //确定分区。100</code></pre><h2 id="用户最近的通话信息"><a href="#用户最近的通话信息" class="headerlink" title="用户最近的通话信息"></a>用户最近的通话信息</h2><pre><code>hbase:rowkeymax()聚集函数。</code></pre><h2 id="mr-hive"><a href="#mr-hive" class="headerlink" title="mr:hive"></a>mr:hive</h2><pre><code>MapReduce.</code></pre><h2 id="用户最近的通话信息-1"><a href="#用户最近的通话信息-1" class="headerlink" title="用户最近的通话信息"></a>用户最近的通话信息</h2><pre><code>1.启动hadoop的yarn集群    [s201]    $&gt;start-yarn.sh    [s206]    $&gt;yarn-daemon.sh start resourcemanager    [验证]    http://s201:8088/2.初始化hive    $&gt;cd /soft/hive/bin    $&gt;./schemaTool -dbType mysql -initSchema    $&gt;hive            //进入hive的shell    $hive&gt;create database mydb ;    $hive&gt;use mydb ;    $hive&gt;create external table ext_calllogs_in_hbase(id string, caller string,callTime string,callee string,callDuration string) STORED BY &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,f1:caller,f1:callTime,f1:callee,f1:callDuration&quot;) TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;ns1:calllogs&quot;);    $hive&gt;select * from ext_calllogs_in_hbase where id like &apos;%xxxx%&apos; order by callTime desc limit 1 ;    $hive&gt;select * from ext_calllogs_in_hbase where callTime = (select max(tt.callTime) from ext_calllogs_in_hbase tt where tt.id like &apos;%xxx%&apos;);3.ssm中创建service，查询hive表中数据。    a.增加依赖        [pom.xml]        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;            &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;            &lt;version&gt;1.2.1&lt;/version&gt;        &lt;/dependency&gt;    b.编写类        package com.it18zhang.ssm.hive;        import com.it18zhang.ssm.domain.CallLog;        import java.sql.Connection;        import java.sql.DriverManager;        /**         * Created by Administrator on 2017/4/14.         */        public class HiveCallLogService {            //hiveserver2连接串            private static String url = &quot;jdbc:hive2://s201:10000/mydb&quot; ;            //驱动程序类            private static String driverClass = &quot;org.apache.hive.jdbc.HiveDriver&quot; ;            static{                try {                    Class.forName(driverClass);                } catch (Exception e) {                    e.printStackTrace();                }            }            /**             * 查询最近的通话记录,使用hive进行mr查询.             */            public CallLog findLatestCallLog(){                try {                    Connection conn = DriverManager.getConnection(url);                    System.out.println(conn);                } catch (Exception e) {                    e.printStackTrace();                }                return null ;            }        }    c.启动hiveserver2服务器        $&gt;hive/bin/hiveserver2 &amp;    d.验证hiveserver2端口        $&gt;netstat -anop | grep 100004.测试类    package com.it18zhang.ssm.hive;    import com.it18zhang.ssm.domain.CallLog;    import org.apache.hadoop.hbase.client.Result;    import java.sql.Connection;    import java.sql.DriverManager;    import java.sql.ResultSet;    import java.sql.Statement;    /**     *     */    public class HiveCallLogService {        //hiveserver2连接串        private static String url = &quot;jdbc:hive2://s201:10000/&quot; ;        //驱动程序类        private static String driverClass = &quot;org.apache.hive.jdbc.HiveDriver&quot; ;        static{            try {                Class.forName(driverClass);            } catch (Exception e) {                e.printStackTrace();            }        }        /**         * 查询最近的通话记录,使用hive进行mr查询.         */        public CallLog findLatestCallLog(){            try {                Connection conn = DriverManager.getConnection(url);                Statement st = conn.createStatement();                ResultSet rs = st.executeQuery(&quot;select * from ext_calllogs_in_hbase&quot;);                while(rs.next()){                    String id = rs.getString(&quot;id&quot;);                    String caller = rs.getString(&quot;caller&quot;);                    String callee = rs.getString(&quot;callee&quot;);                    String callTime = rs.getString(&quot;callTime&quot;);                    String callDuration = rs.getString(&quot;callDuration&quot;);                    System.out.println(id + &quot; :  &quot; + caller);                }                rs.close();                System.out.println(conn);            } catch (Exception e) {                e.printStackTrace();            }            return null ;        }    }5.注意事项    SSM集成hive-jdbc访问hive的hiveserver2时，需要如下处理:    5.1)使用hive-jdbc-1.2.1的依赖版本        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;            &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;            &lt;version&gt;1.2.1&lt;/version&gt;        &lt;/dependency&gt;    5.5)需要集成apache-tomcat-9.0.0.M19版本，否则报编译器错误。</code></pre><h2 id="添加人员信息"><a href="#添加人员信息" class="headerlink" title="添加人员信息"></a>添加人员信息</h2><pre><code>1.建表create table persons(id ...) ;2.domainpublic class Person {    private Integer id ;    private String name ;    private String phone  ;    ...}3.dao4.service5.</code></pre><h2 id="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制-1"><a href="#MR运行参数配置，关闭物理内存和虚拟内存对容器的限制-1" class="headerlink" title="MR运行参数配置，关闭物理内存和虚拟内存对容器的限制"></a>MR运行参数配置，关闭物理内存和虚拟内存对容器的限制</h2><pre><code>默认限制是开启的，最多分配给容器8G的物理内存，虚拟内存是物理内存的2.1倍。[yarn-site.xml]&lt;property&gt;    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;    &lt;value&gt;8192&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;    &lt;value&gt;2.1&lt;/value&gt;&lt;/property&gt;</code></pre><h2 id="实现局部实时刷新通话记录的功能"><a href="#实现局部实时刷新通话记录的功能" class="headerlink" title="实现局部实时刷新通话记录的功能"></a>实现局部实时刷新通话记录的功能</h2><pre><code>1.引入pom.xml    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;        &lt;version&gt;1.2.24&lt;/version&gt;    &lt;/dependency&gt;2.编写Controller，增加方法    @RequestMapping(&quot;/callLog/json/findAll&quot;)    public String findAllJson(HttpServletResponse response) {        List&lt;CallLog&gt; list = cs.findAll();        String json = JSON.toJSONString(list);        //内容类型        response.setContentType(&quot;application/json&quot;);        try {            OutputStream out = response.getOutputStream();            out.write(json.getBytes());            out.flush();            out.close();        } catch (IOException e) {            e.printStackTrace();        }        return  null;    }</code></pre><p>1.启动顺序<br>    a)1.zookeeper<br>    b)2.hadoop<br>    c)3.hbase<br>    d)4.kakfa<br>    e)5.HbaseConsumer<br>    f)6.flume<br>    g)7.web程序<br>    h)8.数据生成程序.<br>2.<br>3.<br>4.<br>5.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前段请求和hive交互，在hive之中创建外部表，映射到Hbase当中&lt;br&gt;一般hive在远端通过jdbc方式来交互，要想走jdbc协议hive还需要打开hiveserver2，其实就是启动thrift服务器，端口是10000.而ssm是在controller里面，交互s
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（二）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（二）/</id>
    <published>2019-01-11T07:56:27.000Z</published>
    <updated>2019-01-14T03:07:13.834Z</updated>
    
    <content type="html"><![CDATA[<p>按照时间段查询通话记录：</p><p>1.按照时间段查询通话记录，设置startRow+endRow。<br>2.web部分设置一个电话号码输入起始时间输入结束时间输入，然后在SSMweb层controller设置一个查询使用hbaseapi。重点在月份值取出来哈希构造rowkey。</p><p>设置一个表单的查询的jsp界面，action是动态嵌套打印的用url标识库，提交给/callLog/finCallLog通过Post方式，返回输入值起始时间和结束时间到controller层接受参数，</p><p>传值到controller层之后，controller层拿到了参数，拿到starttime callerid endtie。</p><p>对起始日期和结束日期进行一个calendar.getinstance()，日历这个可以计算天数月份数，有多少东西都可以算出来。</p><p>编程：在得到的起始时间和结束时间对2个时间点做操作：得到一个结束的endpoint=开始的前6个数字是年和月+最后2个数字是天+1。</p><p>如果是同年月，起始点就是起始串，结束点是天+1的endpoint。<br>    public static List<calllogrange> getCallLogRanges(String startStr ,String endStr){<br>            try{<br>                SimpleDateFormat sdfYMD = new SimpleDateFormat(“yyyyMMdd”);<br>                SimpleDateFormat sdfYM = new SimpleDateFormat(“yyyyMM”);<br>                DecimalFormat df00 = new DecimalFormat(“00”);</calllogrange></p><pre><code>            //            List&lt;CallLogRange&gt; list = new ArrayList&lt;CallLogRange&gt;();            //字符串时间            String startPrefix = startStr.substring(0, 6);            String endPrefix = endStr.substring(0, 6);            int endDay = Integer.parseInt(endStr.substring(6, 8));            //结束点            String endPoint = endPrefix + df00.format(endDay + 1);            //日历对象            Calendar c = Calendar.getInstance();            //同年月            if (startPrefix.equals(endPrefix)) {                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);          //设置起始点                range.setEndPoint(endPoint);            //设置结束点                list.add(range);            } else {                //1.起始月                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);                //设置日历的时间对象                c.setTime(sdfYMD.parse(startStr));                c.add(Calendar.MONTH, 1);                range.setEndPoint(sdfYM.format(c.getTime()));                list.add(range);                //是否是最后一月                while (true) {                    //到了结束月份                    if (endStr.startsWith(sdfYM.format(c.getTime()))) {                        range = new CallLogRange();                        range.setStartPoint(sdfYM.format(c.getTime()));                        range.setEndPoint(endPoint);                        list.add(range);                        break;                    } else {                        range = new CallLogRange();                        //起始时间                        range.setStartPoint(sdfYM.format(c.getTime()));                        //增加月份                        c.add(Calendar.MONTH, 1);                        range.setEndPoint(sdfYM.format(c.getTime()));                        list.add(range);                    }                }            }            return list ;        }        catch(Exception e){            e.printStackTrace();        }        return null ;    }    /**     * 对时间进行格式化     */    public static String formatDate(String timeStr){        try {            return sdfFriend.format(sdf.parse(timeStr));        } catch (Exception e) {            e.printStackTrace();        }        return null ;    }}</code></pre><p>上图是工具类时间的代码。</p><p>下面代码是service层的具体实现内容：<br>    /**</p><pre><code>     * 按照范围查询通话记录     */    public List&lt;CallLog&gt; findCallogs(String call , List&lt;CallLogRange&gt; ranges){        List&lt;CallLog&gt; logs = new ArrayList&lt;CallLog&gt;();        try {            for(CallLogRange range : ranges){                Scan scan = new Scan();                //设置扫描起始行                scan.setStartRow(Bytes.toBytes(CallLogUtil.getStartRowkey(call, range.getStartPoint(),100)));                //设置扫描结束行                scan.setStopRow(Bytes.toBytes(CallLogUtil.getStopRowkey(call, range.getStartPoint(), range.getEndPoint(),100)));                ResultScanner rs = table.getScanner(scan);                Iterator&lt;Result&gt; it = rs.iterator();                byte[] f = Bytes.toBytes(&quot;f1&quot;);                byte[] caller = Bytes.toBytes(&quot;caller&quot;);                byte[] callee = Bytes.toBytes(&quot;callee&quot;);                byte[] callTime = Bytes.toBytes(&quot;callTime&quot;);                byte[] callDuration = Bytes.toBytes(&quot;callDuration&quot;);                CallLog log = null;                while (it.hasNext()) {                    log = new CallLog();                    Result r = it.next();                    //rowkey                    String rowkey = Bytes.toString(r.getRow());                    String flag = rowkey.split(&quot;,&quot;)[3] ;                    log.setFlag(flag.equals(&quot;0&quot;)?true:false);                    //caller                    log.setCaller(Bytes.toString(r.getValue(f, caller)));                    //callee                    log.setCallee(Bytes.toString(r.getValue(f, callee)));                    //callTime                    log.setCallTime(Bytes.toString(r.getValue(f, callTime)));                    //callDuration                    log.setCallDuration(Bytes.toString(r.getValue(f, callDuration)));                    logs.add(log);                }            }            return logs;        } catch (Exception e) {            e.printStackTrace();        }        return null;    }}</code></pre><p>在查询的controller层里面写调用工具类里面对时间进行格式化。格式化之后的List集合作为参数传入到service层的findCallogs（）里面查询到hbase内容集合logs，将logs传入Model.addAttribute里面（向模型中传入数据也就是让前台可以调用）。下面是controller层的内容：</p><pre><code>    /**     * 进入查询通话记录的页面,form     */    @RequestMapping(&quot;/callLog/toFindCallLogPage&quot;)    public String toFindCallLogPage(){        return &quot;callLog/findCallLog&quot; ;    }    @RequestMapping(value = &quot;/callLog/findCallLog&quot;,method = RequestMethod.POST)    public String findCallLog(Model m , @RequestParam(&quot;caller&quot;) String caller, @RequestParam(&quot;startTime&quot;) String startTime, @RequestParam(&quot;endTime&quot;) String endTime){        List&lt;CallLogRange&gt; list = CallLogUtil.getCallLogRanges(startTime, endTime);        List&lt;CallLog&gt; logs = cs.findCallogs(caller,list);        m.addAttribute(&quot;callLogs&quot;, logs);        return &quot;callLog/callLogList&quot; ;    }}</code></pre><p>上述就完成了主叫查询功能。但是查询的只有主叫功能，没有被叫功能，我们在编写一个协处理器处理被叫查询功能：<br>      /**</p><pre><code> * Put后处理 */public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {    super.postPut(e, put, edit, durability);    //    String tableName0 = TableName.valueOf(CALL_LOG_TABLE_NAME).getNameAsString();    //得到当前的TableName对象    String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();    //判断是否是ns1:calllogs表    if (!tableName0.equals(tableName1)) {        return;    }    //得到主叫的rowkey,    String rowkey = Bytes.toString(put.getRow());    //如果被叫就放行    String[] arr = rowkey.split(&quot;,&quot;);    if (arr[3].equals(&quot;1&quot;)) {        return;    }    //hashcode,caller,time,flag,callee,duration    String caller = arr[1] ;        //主叫    String callTime = arr[2] ;      //通话时间    String callee = arr[4] ;        //被叫    String callDuration = arr[5] ;  //通话时长    //被叫hashcode    String hashcode = CallLogUtil.getHashcode(callee,callTime,100);    //被叫rowkey    String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;    Put newPut = new Put(Bytes.toBytes(calleeRowKey));    newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(REF_ROW_ID), Bytes.toBytes(rowkey));    TableName tn = TableName.valueOf(CALL_LOG_TABLE_NAME);    Table t = e.getEnvironment().getTable(tn);    t.put(newPut);}</code></pre><p>也就是创建协处理器，在postput的方法下（这个方法本来是用于在添加一条主叫信息后在添加一条被叫信息）重写之后，在添加主叫信息后，在添加一条被叫信息，该被叫信息的value值插入到f2列族，refrowid列。然后value值就是 原来主叫的rowkey,这个也就是二级索引的思想，避免了原来的主叫的value重复存储，减少了冗余。所以是重写postput方法。</p><p>在没有重写postgetOp()方法的时候返回的是这种情况：</p><p><img src="https://i.imgur.com/gB8tQaU.png" alt=""></p><p>发现里面是被叫的时候没有电话1和电话2为什么呢？<br>因为在检索时候的是这样子写的：检索填充的值是通过getvalue方法，而通过协处理器填进去的是一个被叫信息是控制，所以get不到value信息。</p><p><img src="https://i.imgur.com/0EPdPzM.png" alt=""></p><p>但是查询的时候，还是不能查询到主叫，所以重写检索方法,在协处理器中重写    postscannerNext（）方法。完成被叫查询返回主叫的rowkey值。</p><pre><code>/**     *     */    public boolean postScannerNext(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, InternalScanner s, List&lt;Result&gt; results, int limit, boolean hasMore) throws IOException {        boolean b = super.postScannerNext(e, s, results, limit, hasMore);        //新集合        List&lt;Result&gt; newList = new ArrayList&lt;Result&gt;();        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if (tableName.equals(CALL_LOG_TABLE_NAME)) {            Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));            for(Result r : results){                //rowkey                String rowkey = Bytes.toString(r.getRow());                String flag = rowkey.split(&quot;,&quot;)[3] ;                //主叫                if(flag.equals(&quot;0&quot;)){                    newList.add(r) ;                }                //被叫                else{                    //取出主叫号码                    byte[] refrowkey = r.getValue(Bytes.toBytes(&quot;f2&quot;),Bytes.toBytes(REF_ROW_ID)) ;                    Get newGet = new Get(refrowkey);                    newList.add(tt.get(newGet));                }            }            results.clear();            results.addAll(newList);        }        return b ;    }}</code></pre><p><img src="https://i.imgur.com/cJBPeDB.png" alt=""></p><pre><code>1.hbase交互    Scan : 设置startRow + endRow    rowkey : hashcode , + callerid , + callTime, 0 , callee , duration.</code></pre><p>2.<br>3.</p><h2 id="编写CallLogController-java"><a href="#编写CallLogController-java" class="headerlink" title="编写CallLogController.java"></a>编写CallLogController.java</h2><pre><code>/** * 进入查询通话记录的页面,form */@RequestMapping(&quot;/callLog/toFindCallLogPage&quot;)public String toFindCallLogPage(){    return &quot;callLog/findCallLog&quot; ;}@RequestMapping(value = &quot;/callLog/findCallLog&quot;,method = RequestMethod.POST)public String findCallLog(@RequestParam(&quot;caller&quot;) String caller, @RequestParam(&quot;startTime&quot;) String startTime, @RequestParam(&quot;endTime&quot;) String endTime){    Calendar startCalendar = Calendar.getInstance();    Calendar endCalendar = Calendar.getInstance();    return &quot;callLog/callLogList&quot; ;}</code></pre><h2 id="编写jsp"><a href="#编写jsp" class="headerlink" title="编写jsp"></a>编写jsp</h2><pre><code>&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;查询通话记录&lt;/title&gt;    &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&apos;&lt;c:url value=&quot;/callLog/findCallLog&quot; /&gt;&apos; method=&quot;post&quot;&gt;    &lt;table&gt;        &lt;tr&gt;            &lt;td&gt;电话号码 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;caller&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;起始时间 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;startTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;结束时间:&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;endTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td colspan=&quot;2&quot;&gt;                &lt;input type=&quot;submit&quot; value=&quot;查询&quot;/&gt;            &lt;/td&gt;        &lt;/tr&gt;    &lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="实现时间段查询"><a href="#实现时间段查询" class="headerlink" title="实现时间段查询"></a>实现时间段查询</h2><pre><code>1.提取时间范围    [CallLogUtil.java]    /**     * 起始时间     */    public static String getStartRowkey(String caller, String startTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + startTime ;    }    /**     * 结束时间     */    public static String getStopRowkey(String caller, String startTime,String endTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + endTime ;    }    /**     * 计算查询时间范围     */    public static List&lt;CallLogRange&gt; getCallLogRanges(String startStr ,String endStr){        try{            SimpleDateFormat sdfYMD = new SimpleDateFormat(&quot;yyyyMMdd&quot;);            SimpleDateFormat sdfYM = new SimpleDateFormat(&quot;yyyyMM&quot;);            DecimalFormat df00 = new DecimalFormat(&quot;00&quot;);            //            List&lt;CallLogRange&gt; list = new ArrayList&lt;CallLogRange&gt;();            //字符串时间            String startPrefix = startStr.substring(0, 6);            String endPrefix = endStr.substring(0, 6);            int endDay = Integer.parseInt(endStr.substring(6, 8));            //结束点            String endPoint = endPrefix + df00.format(endDay + 1);            //日历对象            Calendar c = Calendar.getInstance();            //同年月            if (startPrefix.equals(endPrefix)) {                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);          //设置起始点                range.setEndPoint(endPoint);            //设置结束点                list.add(range);            } else {                //1.起始月                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);                //设置日历的时间对象                c.setTime(sdfYMD.parse(startStr));                c.add(Calendar.MONTH, 1);                range.setEndPoint(sdfYM.format(c.getTime()));                list.add(range);                //是否是最后一月                while (true) {                    //到了结束月份                    if (endStr.startsWith(sdfYM.format(c.getTime()))) {                        range = new CallLogRange();                        range.setStartPoint(sdfYM.format(c.getTime()));                        range.setEndPoint(endPoint);                        list.add(range);                        break;                    } else {                        range = new CallLogRange();                        //起始时间                        range.setStartPoint(sdfYM.format(c.getTime()));                        //增加月份                        c.add(Calendar.MONTH, 1);                        range.setEndPoint(sdfYM.format(c.getTime()));                        list.add(range);                    }                }            }            return list ;        }        catch(Exception e){            e.printStackTrace();        }        return null ;    }2.编写service.3.4.</code></pre><h2 id="实现hbase的协处理器"><a href="#实现hbase的协处理器" class="headerlink" title="实现hbase的协处理器"></a>实现hbase的协处理器</h2><pre><code>0.说明    HBaseConsumer put的数据都是主叫，被叫数据在Coprossor中完成。1.创建协处理器    package com.it18zhang.calllog.coprossor;    import org.apache.hadoop.hbase.TableName;    import org.apache.hadoop.hbase.client.Durability;    import org.apache.hadoop.hbase.client.Put;    import org.apache.hadoop.hbase.client.Table;    import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;    import org.apache.hadoop.hbase.coprocessor.ObserverContext;    import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;    import org.apache.hadoop.hbase.regionserver.wal.WALEdit;    import org.apache.hadoop.hbase.util.Bytes;    import java.io.IOException;    /**     * 协处理器,     */    public class CallLogRegionObserver extends BaseRegionObserver {        /**         * Put后处理         */        public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {            super.postPut(e, put, edit, durability);            //            String tableName0 = TableName.valueOf(&quot;ns1:calllogs&quot;).getNameAsString();            //得到当前的TableName对象            String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();            //判断是否是ns1:calllogs表            if (!tableName0.equals(tableName1)) {                return;            }            //得到主叫的rowkey,            String rowkey = Bytes.toString(put.getRow());            //如果被叫就放行            String[] arr = rowkey.split(&quot;,&quot;);            if (arr[3].equals(&quot;1&quot;)) {                return;            }            //hashcode,caller,time,flag,callee,duration            String caller = arr[1] ;        //主叫            String callTime = arr[2] ;      //通话时间            String callee = arr[4] ;        //被叫            String callDuration = arr[5] ;  //通话时长            //被叫hashcode            String hashcode = CallLogUtil.getHashcode(callee,callTime,100);            //被叫rowkey            String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;            Put newPut = new Put(Bytes.toBytes(calleeRowKey));            newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;refrowid&quot;), Bytes.toBytes(rowkey));            TableName tn = TableName.valueOf(&quot;ns1:calllogs&quot;);            Table t = e.getEnvironment().getTable(tn);            t.put(newPut);        }    }2.注册协处理器    a)导出jar包,分到集群.        ...    b)修改hbase配置文件并分发.        [hbase-site.xml]        &lt;property&gt;                &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;                &lt;value&gt;com.it18zhang.calllog.coprossor.CallLogRegionObserver&lt;/value&gt;        &lt;/property&gt;    c)停止hbase集群    d)重新启动        ...    e)进入hbase shell,重建ns1:calllogs        $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;,&apos;f2&apos;</code></pre><h2 id="主叫"><a href="#主叫" class="headerlink" title="主叫"></a>主叫</h2><pre><code>rowkey:12,1234,xxx,0,5678,60,.,.,.,.,</code></pre><h2 id="被叫"><a href="#被叫" class="headerlink" title="被叫"></a>被叫</h2><pre><code>rowkey:                        f2:refrowkey98,5678,xxxx,1,1234,60   --&gt; 12,1234,xxx,0,5678,60,.</code></pre><h2 id="重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录"><a href="#重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录" class="headerlink" title="重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录"></a>重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录</h2><pre><code>1.重写[CallLogRegionObserver.java]package com.it18zhang.calllog.coprossor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;import org.apache.hadoop.hbase.coprocessor.ObserverContext;import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;import org.apache.hadoop.hbase.regionserver.InternalScanner;import org.apache.hadoop.hbase.regionserver.wal.WALEdit;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * 协处理器, */public class CallLogRegionObserver extends BaseRegionObserver {    //被叫引用id    private static final String REF_ROW_ID = &quot;refrowid&quot; ;    //通话记录表名    private static final String CALL_LOG_TABLE_NAME = &quot;ns1:calllogs&quot; ;    /**     * Put后处理     */    public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {        super.postPut(e, put, edit, durability);        //        String tableName0 = TableName.valueOf(CALL_LOG_TABLE_NAME).getNameAsString();        //得到当前的TableName对象        String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断是否是ns1:calllogs表        if (!tableName0.equals(tableName1)) {            return;        }        //得到主叫的rowkey,        String rowkey = Bytes.toString(put.getRow());        //如果被叫就放行        String[] arr = rowkey.split(&quot;,&quot;);        if (arr[3].equals(&quot;1&quot;)) {            return;        }        //hashcode,caller,time,flag,callee,duration        String caller = arr[1] ;        //主叫        String callTime = arr[2] ;      //通话时间        String callee = arr[4] ;        //被叫        String callDuration = arr[5] ;  //通话时长        //被叫hashcode        String hashcode = CallLogUtil.getHashcode(callee,callTime,100);        //被叫rowkey        String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;        Put newPut = new Put(Bytes.toBytes(calleeRowKey));        newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(REF_ROW_ID), Bytes.toBytes(rowkey));        TableName tn = TableName.valueOf(CALL_LOG_TABLE_NAME);        Table t = e.getEnvironment().getTable(tn);        t.put(newPut);    }    /**     * 重写方法，完成被叫查询，返回主叫结果。     */    public void postGetOp(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Get get, List&lt;Cell&gt; results) throws IOException {        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if(!tableName.equals(CALL_LOG_TABLE_NAME)){            super.preGetOp(e, get, results);        }        else{            //得到rowkey            String rowkey = Bytes.toString(get.getRow());            //            String[] arr = rowkey.split(&quot;,&quot;);            //主叫            if(arr[3].equals(&quot;0&quot;)){                super.postGetOp(e, get, results);            }            //被叫            else{                //得到主叫方的rowkey                String refrowid = Bytes.toString(CellUtil.cloneValue(results.get(0)));                //                Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));                Get g = new Get(Bytes.toBytes(refrowid));                Result r = tt.get(g);                List&lt;Cell&gt; newList = r.listCells();                results.clear();                results.addAll(newList);            }        }    }    /**     *     */    public boolean postScannerNext(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, InternalScanner s, List&lt;Result&gt; results, int limit, boolean hasMore) throws IOException {        boolean b = super.postScannerNext(e, s, results, limit, hasMore);        //新集合        List&lt;Result&gt; newList = new ArrayList&lt;Result&gt;();        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if (tableName.equals(CALL_LOG_TABLE_NAME)) {            Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));            for(Result r : results){                //rowkey                String rowkey = Bytes.toString(r.getRow());                String flag = rowkey.split(&quot;,&quot;)[3] ;                //主叫                if(flag.equals(&quot;0&quot;)){                    newList.add(r) ;                }                //被叫                else{                    //取出主叫号码                    byte[] refrowkey = r.getValue(Bytes.toBytes(&quot;f2&quot;),Bytes.toBytes(REF_ROW_ID)) ;                    Get newGet = new Get(refrowkey);                    newList.add(tt.get(newGet));                }            }            results.clear();            results.addAll(newList);        }        return b ;    }}1&apos;.修改jsp页面    [callLogList.jsp]    &lt;c:if test=&quot;${log.caller == param.caller}&quot;&gt;主叫&lt;/c:if&gt;    &lt;c:if test=&quot;${log.caller != param.caller}&quot;&gt;被叫&lt;/c:if&gt;2.部署jar包3.测试    ...4.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;按照时间段查询通话记录：&lt;/p&gt;
&lt;p&gt;1.按照时间段查询通话记录，设置startRow+endRow。&lt;br&gt;2.web部分设置一个电话号码输入起始时间输入结束时间输入，然后在SSMweb层controller设置一个查询使用hbaseapi。重点在月份值取出来哈希构造r
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Spring第二天_01Spring常用注解</title>
    <link href="http://erichunn.github.io/2019/01/11/Spring%E7%AC%94%E8%AE%B0/Spring%E7%AC%AC%E4%BA%8C%E5%A4%A9_01Spring%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/"/>
    <id>http://erichunn.github.io/2019/01/11/Spring笔记/Spring第二天_01Spring常用注解/</id>
    <published>2019-01-11T07:56:21.000Z</published>
    <updated>2019-09-27T06:49:25.098Z</updated>
    
    <content type="html"><![CDATA[<p>前言：上一章节讲解的是就是通过工厂类获取bean实例，通过获取xml文件里面的配置，value是serviceimpl对应一个Id，然后获取一个serviceimpl的实例，或者获取一个daoimpl的实例，就不用通过new来创建了，本章讲解的是通过Spring容器，注解的方式达到上面的目的，直接注入实例或者注入某一成员类型的值。</p><h1 id="Spring基于注解的IOC以及IOC的案例"><a href="#Spring基于注解的IOC以及IOC的案例" class="headerlink" title="Spring基于注解的IOC以及IOC的案例"></a>Spring基于注解的IOC以及IOC的案例</h1><h2 id="1、spring中ioc的常用注解"><a href="#1、spring中ioc的常用注解" class="headerlink" title="1、spring中ioc的常用注解"></a>1、spring中ioc的常用注解</h2><h2 id="2、案例使用xml方式和注解方式实现单表的CRUD操作"><a href="#2、案例使用xml方式和注解方式实现单表的CRUD操作" class="headerlink" title="2、案例使用xml方式和注解方式实现单表的CRUD操作"></a>2、案例使用xml方式和注解方式实现单表的CRUD操作</h2><pre><code>持久层技术选择：dbutils</code></pre><h2 id="3、改造基于注解的ioc案例，使用纯注解的方式实现"><a href="#3、改造基于注解的ioc案例，使用纯注解的方式实现" class="headerlink" title="3、改造基于注解的ioc案例，使用纯注解的方式实现"></a>3、改造基于注解的ioc案例，使用纯注解的方式实现</h2><pre><code>spring的一些新注解使用</code></pre><h2 id="4、spring和Junit整合"><a href="#4、spring和Junit整合" class="headerlink" title="4、spring和Junit整合"></a>4、spring和Junit整合</h2><p>曾经XML的配置，</p><pre><code>&lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot;&lt;scope =&quot;&quot;   init-method=&quot;&quot;  destory-method=&quot;&quot;&gt;&lt;propertiy name = &quot;&quot; value=&quot;&quot; | ref=&quot;&quot;&gt;&lt;/propertiy&gt;&lt;/bean&gt;</code></pre><p> 1、用于创建对象的注解：</p><pre><code>@Component</code></pre><p>他们的作用就和在XML配置文件中编写一个<bean></bean>标签实现的功能一样的</p><p> 2、用于注入数据的注解：</p><p>他们的作用就和在XML配置文件中写一个prepertiy标签的作用是一样的</p><p> 3、用于改变范围的注解</p><p>他们的作用就和在bean标签中使用scope属性实现的功能是一样的</p><p> 4、和生命周期相关的</p><p>他们的作用就和在bean标签中使用Init-method和destory标签是一样的</p><hr><pre><code>package com.itheima.service.impl;import com.itheima.dao.IAccountDao;import com.itheima.dao.impl.AccountDaoImpl;import com.itheima.service.IAccountService;import org.springframework.stereotype.Component;/** * @Description 账户的业务层实现类 * @Author TT Hun * @Data 2019/9/16 22:09 * *  1、用于创建对象的注解 *      他们的作用就和在XML配置文件中编写一个&lt;bean&gt;&lt;/bean&gt;标签实现的功能一样的 */@Component(value=&quot;accountService&quot;)public class AccountServiceImpl implements IAccountService {        public AccountServiceImpl(){        System.out.println(&quot;对象被创建了&quot;);    }    public void saveAccount() {        accountDao.saveAccount();    }}</code></pre><hr><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;!--    告知Spring在创建容器的时候需要扫描的包，配置所需要的标签不是在beans这个约束中，而是一个名称为context名称空间和约束中--&gt;    &lt;context:component-scan base-package=&quot;com.itheima&quot;&gt;&lt;/context:component-scan&gt;    &lt;/beans&gt;</code></pre><hr><pre><code>package com.itheima.ui;import com.itheima.dao.IAccountDao;import com.itheima.service.IAccountService;import com.itheima.service.impl.AccountServiceImpl;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.context.support.FileSystemXmlApplicationContext;import org.springframework.core.io.ClassPathResource;import org.springframework.core.io.Resource;import sun.security.tools.keytool.Resources;/** * @Description 用这个模拟一个表现层用于调用业务层，实际上应该是一个servlet * @Author TT Hun * @Data 2019/9/16 22:15 */public class Client {    public static void main(String[] args) {        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);//        2、根据ID获取bean对象        IAccountService as = (IAccountService) ac.getBean(&quot;accountService&quot;);        System.out.println(as);    }}</code></pre><hr><h2 id="由Component衍生出来的三个注解："><a href="#由Component衍生出来的三个注解：" class="headerlink" title="由Component衍生出来的三个注解："></a>由Component衍生出来的三个注解：</h2><pre><code>/**  1、用于创建对象的注解*      他们的作用就和在XML配置文件中编写一个&lt;bean&gt;&lt;/bean&gt;标签实现的功能一样的*      Component;作用，用于把当前对象注入Srping容器中*      属性：value:用于指定的bean的id。当我们不写的时候，它默认值是当前类名，而且首字母小写*      Controller:用在表现层*      Service:业务层*      Respository：用于持久层*      以上是和Component一样的作用，他们是Spring框架提供的为了明确三层使用的注解，是我们对三层更加清晰**  2、用于注入数据的注解*      他们的作用就和在XML配置文件中写一个prepertiy标签的作用是一样的*  3、用于改变范围的注解*      他们的作用就和在bean标签中使用scope属性实现的功能是一样的*  4、和生命周期相关的*      他们的作用就和在bean标签中使用Init-method和destory标签是一样的**/</code></pre><hr><blockquote><p>下面这段例子会报错因为没有注入数据，导致空指针异常。</p></blockquote><pre><code>package com.itheima.service.impl;import com.itheima.dao.IAccountDao;import com.itheima.dao.impl.AccountDaoImpl;import com.itheima.service.IAccountService;import org.springframework.stereotype.Component;/** * @Description 账户的业务层实现类 * @Author TT Hun * @Data 2019/9/16 22:09 * 曾经XML的配置， *  &lt;bean id=&quot;accountService&quot; class=&quot;com.itheima.service.impl.AccountServiceImpl&quot; *  &lt;scope =&quot;&quot;   init-method=&quot;&quot;  destory-method=&quot;&quot;&gt; *  &lt;propertiy name = &quot;&quot; value=&quot;&quot; | ref=&quot;&quot;&gt;&lt;/propertiy&gt; *  &lt;/bean&gt; * * * *  1、用于创建对象的注解 *      他们的作用就和在XML配置文件中编写一个&lt;bean&gt;&lt;/bean&gt;标签实现的功能一样的 *      Component;作用，用于把当前对象注入Srping容器中 *      属性：value:用于指定的bean的id。当我们不写的时候，它默认值是当前类名，而且首字母小写 *      Controller:用在表现层 *      Service:业务层 *      Respository：用于持久层 *      以上是和Component一样的作用，他们是Spring框架提供的为了明确三层使用的注解，是我们对三层更加清晰 * *  2、用于注入数据的注解 *      他们的作用就和在XML配置文件中写一个prepertiy标签的作用是一样的 *  3、用于改变范围的注解 *      他们的作用就和在bean标签中使用scope属性实现的功能是一样的 *  4、和生命周期相关的 *      他们的作用就和在bean标签中使用Init-method和destory标签是一样的 */@Component(value=&quot;accountService&quot;)public class AccountServiceImpl implements IAccountService {        private IAccountDao accountDao ;    public void saveAccount() {        accountDao.saveAccount();    }}</code></pre><hr><pre><code>package com.itheima.dao.impl;import com.itheima.dao.IAccountDao;import org.springframework.stereotype.Repository;/** * @Description 账户的持久层实现类 * @Author TT Hun * @Data 2019/9/16 22:13 */@Repository(&quot;accountDao&quot;)public class AccountDaoImpl implements IAccountDao {    public void saveAccount() {        System.out.println(&quot;保存了账户&quot;);    }}</code></pre><hr><pre><code>package com.itheima.ui;import com.itheima.dao.IAccountDao;import com.itheima.service.IAccountService;import com.itheima.service.impl.AccountServiceImpl;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.context.support.FileSystemXmlApplicationContext;import org.springframework.core.io.ClassPathResource;import org.springframework.core.io.Resource;import sun.security.tools.keytool.Resources;/** * @Description 用这个模拟一个表现层用于调用业务层，实际上应该是一个servlet * @Author TT Hun * @Data 2019/9/16 22:15 */public class Client {    public static void main(String[] args) {        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);//        2、根据ID获取Service的实例        IAccountService as = (IAccountService) ac.getBean(&quot;accountService&quot;);//      下面是获取dao对象的实例，        IAccountDao adao = ac.getBean(&quot;accountDao&quot;,IAccountDao.class);//        这里只显示调用了对象，没有使用其中的方法，因为其中的Serviceimpl里面隐入了Dao类型的变量，因为还没有实例化，所以他是null，会出现空指针异常，        as.saveAccount();        }}</code></pre><blockquote><p>所以要在上面这一段代码的数据类型serviceimpl里面的成员变量上面写上@Autowired</p></blockquote><hr><blockquote><p>下面这一段讲解当出现相同的类的时候，Autowired注解怎么解决：</p></blockquote><p><img src="https://i.imgur.com/vgQ4cGY.png" alt=""></p><p>Spring容器本质上是Map，key-value格式的</p><p>如果在注入数据的时候有2个DAO类型的，那么首先，他会先匹配数据类型一致的，他会发现2个。</p><p>然后在根据变量名称找对应的Spring容器里面的key写的，哪一个是相同的名字。</p><hr><blockquote><p>Qualifier:<br>作用：在按照类中注入的基础之上再按照名称注入。他在给类成员注入时不能单独使用。但是在方法范数注入的时候可以。在给类成员注入的时候，需要和antuwired联合使用，在给方法注入时候可以单独使用<br>属性：value用于指定注入bean的id。</p></blockquote><blockquote><p>Resource：<br>作用：直接按照bean的id注入。可以独立使用<br>属性：<br>name:用于指定bean的Id</p></blockquote><blockquote><p>Autowired注解、Qualifier注解、Resource注解只能注入其他类型的bean数据类型，而基本类型和String类型无法实现上述实现。<br>另外，集合类型的注入智能通过XML来实现。</p></blockquote><blockquote><p>基本类型和String类型的注入用Value注解<br>作用：用于注入基本类型和String类型的数据 </p></blockquote><blockquote><p>属性：<br>value用于指定数据的值，他可以使用Spring中的SPEl（也就是Srpring的el表达式）<br>Spel的写法：${表达式}</p></blockquote><blockquote><p>用于改变作用范围的：</p></blockquote><blockquote><p>他们的作用就和在bean标签中使用scope属性实现的功能是一样的。</p></blockquote><blockquote><p>scope:</p></blockquote><blockquote><p>作用：用于指定bean的作用范围，</p></blockquote><blockquote><p>属性：value:用于指定范围的取值。常用取值：singleton 和 prototype</p></blockquote><p>和生命周期相关：</p><pre><code>他们的作用和在bean标签中使用init-method和destroy-method的作用是一样的。PreDestory    用于指定销毁方法PostConstruct    作用用于指定初始化方法</code></pre><p>小结：<br>    1、多例模式，关闭Spring不会销毁对象，<br>    2、想要实现销毁方法的实现，如果在serviceimpl注入初始化和销毁注解，然后写方法，然后再在main方法里面先初始化Spring容器，但是只有写了spring的close方法， 才会执行对象的销毁方法，这个地方的初始化和销毁，销毁的是spring容器创建的，比如下图；创建的是IAccountService类型的bean对象，最后要使用ac.close()方法关闭spring容器。</p><p><img src="https://i.imgur.com/QmLkCqe.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：上一章节讲解的是就是通过工厂类获取bean实例，通过获取xml文件里面的配置，value是serviceimpl对应一个Id，然后获取一个serviceimpl的实例，或者获取一个daoimpl的实例，就不用通过new来创建了，本章讲解的是通过Spring容器，注解的
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实战大数据电信项目（一）</title>
    <link href="http://erichunn.github.io/2019/01/11/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://erichunn.github.io/2019/01/11/实战大数据电信项目（一）/</id>
    <published>2019-01-11T07:56:21.000Z</published>
    <updated>2019-01-13T07:38:32.377Z</updated>
    
    <content type="html"><![CDATA[<p>0.rowkey的设计<br>因为通过rowkey查询，吧尽可能多的数据放到rowkey里面去。</p><p>考虑的问题：</p><p>从通话记录整个来考虑，记录量比较大。让记录分散，吧主叫被叫编写进去时间编进去，就是一个rowkey的构成，如果用主叫被叫时间做rowkey的话。 </p><p>每个服务器承载的数据量。hbase没经过10G就切割成2个区域，分成2个区域服务器，一条记录是1k10G是多少行可以算出来，可以设计出来区间。要知道rowkey的范围 。</p><p>如果数据都在一台服务器吧请求都发送给一台服务器，压力很大。</p><p>对于服务器来说，每个服务器应该多少数据量的问题。怎么衡量？</p><p>对于单张表是10G就切割。切割出来的区域分成2个区域服务器上去了是10G的数据量。可以算一下一条记录是1K那么10G的数据量是多少行，根据这个法则设定空间，要知道rowkey的范围。加入1个区域存放10G要是有10个区域存放10G是100G。存放就是10G、1k=1亿数据量。</p><p>rowkey是排序的，所以排序最好是等长度的，因为如果从1-10000情况下8是大于10000的。</p><p> 可以通过预切割避免切割风暴。<br> 139。。。。<br>137.。。。<br>切割成区域，如果定了10个区域，要把所有的数据分散到10个区域里面去就是00-09，所以在编写rowkey里面，139，137的都有很多，所以在前面加一个前缀，也就是说盐析。</p><p>rowkey设计的长度原则。一般是定长，越短越好，不超过1个字节：因为目前都是64位系统，内存是8字节对其，控制在16字节8字节的整数倍利用了操作系统的最佳特性。</p><p>建议用rowkey的高位进行散列处理，由程序随机生成，低位放时间字段，这样提高数据均衡分布在每个regionServer来实现负载均衡。</p><p>如果不进行散列，如果用时间片编写开头。起始的Rowkey的弊端就会集中在一个regionserver上，光是交换机写入就已经爆掉hbase了。因为数据量太大了。</p><p>以电话号码编写开头的话，所有数据都在</p><p>rowkey设计原则由于rowkey是字典排序的所以要将常用的放到一个region但是又不能量太大。</p><p>热点：<br><img src="https://i.imgur.com/fYWGFDr.png" alt=""></p><p>总结来说就是在整个数据rowkey前面加个2位数的随机数也就是通过盐析的方式避免热点问题。2位数的随机数是通过一个hash算法实现0-100散列。分布在0-100的不通的region里面。协处理器相当于一个区域观察期，类似于zookeeper的观察者。也就是插入了一条数据他就观察的到通过该preput 和postput重写这些方法来实现在插入前和插入后的动作，和插入的时候类似，通过哈希算法实现前面的随机数。完成新的rowkey的重组。这个地方根据业务场景的需要，每次查询的时候主叫和被叫都要查询出来，所以他的设计是将两个电话的主叫和被叫同时分布在一个区域里面。使得查询的效率更加高效分布更加合理。通过在协处理器哈希算法的时候通过被叫号码+时间片来哈希，主动插入的时候通过主叫号码+时间片来哈希。就可以实现主叫和被叫一个号码的都在同一个区域里面。</p><p>在查询几月到几月的通话详单的时候，通过设置scan.startKey和scan.stopRow查询到开始日期和结束日期。打印是通过resultscanner</p><p>如果查询某一个号码作为被叫的信息，我们可以在设计一张表calleelog被叫记录日志。rowkey设计：呼叫时间吧calltime和calleeid作为rowkey的设计什么时候被叫的但是他的value就是之前设计的callerlog表的rowkey的值，然后通过被叫表的value，这个value就是主叫表的rowkey通过这个也就是通过被叫表查询到了主叫表。这个场景还有2中可能，一种是设计2张表，然后查询，要是不设计2张表的话就是通过上文说过的通过设计一个被叫表指向主叫表的rowkey来完成这个业务场景。</p><p>主叫表查询的rowkey设计：因为主要查询的时候都是通过主叫电话号码和时间来查询通过清单的，所以rowkey设计为hash,callerid,time,0,calleeid，然后value里面放一些其他诸如基站，手机信息等等其他无关紧要的信息，吧主要要查询的内容放到rowkey里面可以增加效率，直接查询rowkey就可以查询到所需要的内容。</p><p>被叫表rowkey设计：设计一个另外一个表。calleeid,callertime里面的value放主叫表的rowkey即可。是为了避免第二张表大量冗余。</p><p>1.按照时间段查询通话记录</p><p><img src="https://i.imgur.com/2vxKcC0.png" alt=""><br>    1.hbase交互<br>        Scan : 设置startRow + endRow<br>        rowkey : hashcode , + callerid , + callTime, 0 , callee , duration.</p><p>2.<br>3.</p><h2 id="编写CallLogController-java"><a href="#编写CallLogController-java" class="headerlink" title="编写CallLogController.java"></a>编写CallLogController.java</h2><pre><code>/** * 进入查询通话记录的页面,form */@RequestMapping(&quot;/callLog/toFindCallLogPage&quot;)public String toFindCallLogPage(){    return &quot;callLog/findCallLog&quot; ;}@RequestMapping(value = &quot;/callLog/findCallLog&quot;,method = RequestMethod.POST)public String findCallLog(@RequestParam(&quot;caller&quot;) String caller, @RequestParam(&quot;startTime&quot;) String startTime, @RequestParam(&quot;endTime&quot;) String endTime){    Calendar startCalendar = Calendar.getInstance();    Calendar endCalendar = Calendar.getInstance();    return &quot;callLog/callLogList&quot; ;}</code></pre><h2 id="编写jsp界面"><a href="#编写jsp界面" class="headerlink" title="编写jsp界面"></a>编写jsp界面</h2><pre><code>&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;查询通话记录&lt;/title&gt;    &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../css/my.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&apos;&lt;c:url value=&quot;/callLog/findCallLog&quot; /&gt;&apos; method=&quot;post&quot;&gt;    &lt;table&gt;        &lt;tr&gt;            &lt;td&gt;电话号码 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;caller&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;起始时间 :&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;startTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;结束时间:&lt;/td&gt;            &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;endTime&quot;&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td colspan=&quot;2&quot;&gt;                &lt;input type=&quot;submit&quot; value=&quot;查询&quot;/&gt;            &lt;/td&gt;        &lt;/tr&gt;    &lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="实现时间段查询"><a href="#实现时间段查询" class="headerlink" title="实现时间段查询"></a>实现时间段查询</h2><pre><code>1.提取时间范围    [CallLogUtil.java]    /**     * 起始时间     */    public static String getStartRowkey(String caller, String startTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + startTime ;    }    /**     * 结束时间     */    public static String getStopRowkey(String caller, String startTime,String endTime, int partitions){        String hashcode = getHashcode(caller, startTime,partitions);        return hashcode + &quot;,&quot; + caller + &quot;,&quot; + endTime ;    }    /**     * 计算查询时间范围     */    public static List&lt;CallLogRange&gt; getCallLogRanges(String startStr ,String endStr){        try{            SimpleDateFormat sdfYMD = new SimpleDateFormat(&quot;yyyyMMdd&quot;);            SimpleDateFormat sdfYM = new SimpleDateFormat(&quot;yyyyMM&quot;);            DecimalFormat df00 = new DecimalFormat(&quot;00&quot;);            //            List&lt;CallLogRange&gt; list = new ArrayList&lt;CallLogRange&gt;();            //字符串时间            String startPrefix = startStr.substring(0, 6);            String endPrefix = endStr.substring(0, 6);            int endDay = Integer.parseInt(endStr.substring(6, 8));            //结束点            String endPoint = endPrefix + df00.format(endDay + 1);            //日历对象            Calendar c = Calendar.getInstance();            //同年月            if (startPrefix.equals(endPrefix)) {                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);          //设置起始点                range.setEndPoint(endPoint);            //设置结束点                list.add(range);            } else {                //1.起始月                CallLogRange range = new CallLogRange();                range.setStartPoint(startStr);                //设置日历的时间对象                c.setTime(sdfYMD.parse(startStr));                c.add(Calendar.MONTH, 1);                range.setEndPoint(sdfYM.format(c.getTime()));                list.add(range);                //是否是最后一月                while (true) {                    //到了结束月份                    if (endStr.startsWith(sdfYM.format(c.getTime()))) {                        range = new CallLogRange();                        range.setStartPoint(sdfYM.format(c.getTime()));                        range.setEndPoint(endPoint);                        list.add(range);                        break;                    } else {                        range = new CallLogRange();                        //起始时间                        range.setStartPoint(sdfYM.format(c.getTime()));                        //增加月份                        c.add(Calendar.MONTH, 1);                        range.setEndPoint(sdfYM.format(c.getTime()));                        list.add(range);                    }                }            }            return list ;        }        catch(Exception e){            e.printStackTrace();        }        return null ;    }2.编写service.3.4.</code></pre><h2 id="实现hbase的协处理器"><a href="#实现hbase的协处理器" class="headerlink" title="实现hbase的协处理器"></a>实现hbase的协处理器</h2><pre><code>0.说明    HBaseConsumer put的数据都是主叫，被叫数据在Coprossor中完成。1.创建协处理器    package com.it18zhang.calllog.coprossor;    import org.apache.hadoop.hbase.TableName;    import org.apache.hadoop.hbase.client.Durability;    import org.apache.hadoop.hbase.client.Put;    import org.apache.hadoop.hbase.client.Table;    import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;    import org.apache.hadoop.hbase.coprocessor.ObserverContext;    import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;    import org.apache.hadoop.hbase.regionserver.wal.WALEdit;    import org.apache.hadoop.hbase.util.Bytes;    import java.io.IOException;    /**     * 协处理器,     */    public class CallLogRegionObserver extends BaseRegionObserver {        /**         * Put后处理         */        public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {            super.postPut(e, put, edit, durability);            //            String tableName0 = TableName.valueOf(&quot;ns1:calllogs&quot;).getNameAsString();            //得到当前的TableName对象            String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();            //判断是否是ns1:calllogs表            if (!tableName0.equals(tableName1)) {                return;            }            //得到主叫的rowkey,            String rowkey = Bytes.toString(put.getRow());            //如果被叫就放行            String[] arr = rowkey.split(&quot;,&quot;);            if (arr[3].equals(&quot;1&quot;)) {                return;            }            //hashcode,caller,time,flag,callee,duration            String caller = arr[1] ;        //主叫            String callTime = arr[2] ;      //通话时间            String callee = arr[4] ;        //被叫            String callDuration = arr[5] ;  //通话时长            //被叫hashcode            String hashcode = CallLogUtil.getHashcode(callee,callTime,100);            //被叫rowkey            String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;            Put newPut = new Put(Bytes.toBytes(calleeRowKey));            newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(&quot;refrowid&quot;), Bytes.toBytes(rowkey));            TableName tn = TableName.valueOf(&quot;ns1:calllogs&quot;);            Table t = e.getEnvironment().getTable(tn);            t.put(newPut);        }    }2.注册协处理器    a)导出jar包,分到集群.        ...    b)修改hbase配置文件并分发.        [hbase-site.xml]        &lt;property&gt;                &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;                &lt;value&gt;com.it18zhang.calllog.coprossor.CallLogRegionObserver&lt;/value&gt;        &lt;/property&gt;    c)停止hbase集群    d)重新启动        ...    e)进入hbase shell,重建ns1:calllogs        $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;,&apos;f2&apos;</code></pre><h2 id="主叫"><a href="#主叫" class="headerlink" title="主叫"></a>主叫</h2><pre><code>rowkey:12,1234,xxx,0,5678,60,.,.,.,.,</code></pre><h2 id="被叫"><a href="#被叫" class="headerlink" title="被叫"></a>被叫</h2><pre><code>rowkey:                        f2:refrowkey98,5678,xxxx,1,1234,60   --&gt; 12,1234,xxx,0,5678,60,.</code></pre><h2 id="重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录"><a href="#重写RegionObserver的postGetOp方法-完成被叫查询时，直接返回主叫的记录" class="headerlink" title="重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录"></a>重写RegionObserver的postGetOp方法,完成被叫查询时，直接返回主叫的记录</h2><pre><code>1.重写[CallLogRegionObserver.java]package com.it18zhang.calllog.coprossor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;import org.apache.hadoop.hbase.coprocessor.ObserverContext;import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;import org.apache.hadoop.hbase.regionserver.InternalScanner;import org.apache.hadoop.hbase.regionserver.wal.WALEdit;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * 协处理器, */public class CallLogRegionObserver extends BaseRegionObserver {    //被叫引用id    private static final String REF_ROW_ID = &quot;refrowid&quot; ;    //通话记录表名    private static final String CALL_LOG_TABLE_NAME = &quot;ns1:calllogs&quot; ;    /**     * Put后处理     */    public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {        super.postPut(e, put, edit, durability);        //        String tableName0 = TableName.valueOf(CALL_LOG_TABLE_NAME).getNameAsString();        //得到当前的TableName对象        String tableName1 = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断是否是ns1:calllogs表        if (!tableName0.equals(tableName1)) {            return;        }        //得到主叫的rowkey,        String rowkey = Bytes.toString(put.getRow());        //如果被叫就放行        String[] arr = rowkey.split(&quot;,&quot;);        if (arr[3].equals(&quot;1&quot;)) {            return;        }        //hashcode,caller,time,flag,callee,duration        String caller = arr[1] ;        //主叫        String callTime = arr[2] ;      //通话时间        String callee = arr[4] ;        //被叫        String callDuration = arr[5] ;  //通话时长        //被叫hashcode        String hashcode = CallLogUtil.getHashcode(callee,callTime,100);        //被叫rowkey        String calleeRowKey = hashcode + &quot;,&quot; + callee + &quot;,&quot; + callTime + &quot;,1,&quot; + caller + &quot;,&quot; + callDuration;        Put newPut = new Put(Bytes.toBytes(calleeRowKey));        newPut.addColumn(Bytes.toBytes(&quot;f2&quot;), Bytes.toBytes(REF_ROW_ID), Bytes.toBytes(rowkey));        TableName tn = TableName.valueOf(CALL_LOG_TABLE_NAME);        Table t = e.getEnvironment().getTable(tn);        t.put(newPut);    }    /**     * 重写方法，完成被叫查询，返回主叫结果。     */    public void postGetOp(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Get get, List&lt;Cell&gt; results) throws IOException {        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if(!tableName.equals(CALL_LOG_TABLE_NAME)){            super.preGetOp(e, get, results);        }        else{            //得到rowkey            String rowkey = Bytes.toString(get.getRow());            //            String[] arr = rowkey.split(&quot;,&quot;);            //主叫            if(arr[3].equals(&quot;0&quot;)){                super.postGetOp(e, get, results);            }            //被叫            else{                //得到主叫方的rowkey                String refrowid = Bytes.toString(CellUtil.cloneValue(results.get(0)));                //                Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));                Get g = new Get(Bytes.toBytes(refrowid));                Result r = tt.get(g);                List&lt;Cell&gt; newList = r.listCells();                results.clear();                results.addAll(newList);            }        }    }    /**     *     */    public boolean postScannerNext(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, InternalScanner s, List&lt;Result&gt; results, int limit, boolean hasMore) throws IOException {        boolean b = super.postScannerNext(e, s, results, limit, hasMore);        //新集合        List&lt;Result&gt; newList = new ArrayList&lt;Result&gt;();        //获得表名        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();        //判断表名是否是ns1:calllogs        if (tableName.equals(CALL_LOG_TABLE_NAME)) {            Table tt = e.getEnvironment().getTable(TableName.valueOf(CALL_LOG_TABLE_NAME));            for(Result r : results){                //rowkey                String rowkey = Bytes.toString(r.getRow());                String flag = rowkey.split(&quot;,&quot;)[3] ;                //主叫                if(flag.equals(&quot;0&quot;)){                    newList.add(r) ;                }                //被叫                else{                    //取出主叫号码                    byte[] refrowkey = r.getValue(Bytes.toBytes(&quot;f2&quot;),Bytes.toBytes(REF_ROW_ID)) ;                    Get newGet = new Get(refrowkey);                    newList.add(tt.get(newGet));                }            }            results.clear();            results.addAll(newList);        }        return b ;    }}1&apos;.修改jsp页面    [callLogList.jsp]    &lt;c:if test=&quot;${log.caller == param.caller}&quot;&gt;主叫&lt;/c:if&gt;    &lt;c:if test=&quot;${log.caller != param.caller}&quot;&gt;被叫&lt;/c:if&gt;2.部署jar包3.测试    ...4.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;0.rowkey的设计&lt;br&gt;因为通过rowkey查询，吧尽可能多的数据放到rowkey里面去。&lt;/p&gt;
&lt;p&gt;考虑的问题：&lt;/p&gt;
&lt;p&gt;从通话记录整个来考虑，记录量比较大。让记录分散，吧主叫被叫编写进去时间编进去，就是一个rowkey的构成，如果用主叫被叫时间做rowk
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>SSM第四天</title>
    <link href="http://erichunn.github.io/2019/01/10/SSM%E7%AC%AC%E5%9B%9B%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/01/10/SSM第四天/</id>
    <published>2019-01-10T09:11:25.000Z</published>
    <updated>2019-01-10T09:22:13.251Z</updated>
    
    <content type="html"><![CDATA[<p>新建SSM模块，添加完之后再加入maven支持，刷新  </p><p><img src="https://i.imgur.com/p9PS1Gs.png" alt=""></p><h2 id="session数据访问"><a href="#session数据访问" class="headerlink" title="session数据访问"></a>session数据访问</h2><pre><code>1.java    @RequestMapping(&quot;/toLogin&quot;)    public String doLogin() {        return &quot;login&quot;;    }    @RequestMapping(&quot;/doLogin&quot;)    public String doLogin(User u ,HttpSession s){        //将数据存放到session范围。        s.setAttribute(&quot;user&quot;,u);        return &quot;index&quot; ;    }2.jsp    &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;    &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;    &lt;%@ page session=&quot;true&quot; %&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;login.jsp&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;    &lt;c:out value=&quot;${sessionScope.user.name}&quot;/&gt;    &lt;c:if test=&quot;${sessionScope.user != null}&quot;&gt;        欢迎 &lt;c:out value=&quot;${sessionScope.user.name}&quot;/&gt;    &lt;/c:if&gt;    &lt;c:if test=&quot;${sessionScope.user == null}&quot;&gt;       您尚未登录,请登录!!    &lt;/c:if&gt;    &lt;c:out value=&quot;${sessionScope.user.name}&quot;/&gt;    &lt;form action=&apos;&lt;c:url value=&quot;/doLogin&quot; /&gt;&apos; method=&quot;post&quot;&gt;        UserName : &lt;input type=&quot;text&quot; name=&quot;name&quot;&gt;&lt;br&gt;        Password : &lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br&gt;        &lt;input type=&quot;submit&quot;/&gt;    &lt;/form&gt;    &lt;/body&gt;    &lt;/html&gt;</code></pre><h2 id="整合SSM-springmvc-spring-mybatis"><a href="#整合SSM-springmvc-spring-mybatis" class="headerlink" title="整合SSM(springmvc + spring + mybatis)"></a>整合SSM(springmvc + spring + mybatis)</h2><pre><code>1.创建模块    ssm(javaee)2.添加maven支持3.添加依赖。    mysql驱动    c3p0数据源    mybatis    spring(tx | aop | context))包括事务AOP上下文。    mybatis-spring    spring mvc    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.it18zhang&lt;/groupId&gt;        &lt;artifactId&gt;ssm&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;mysql&lt;/groupId&gt;                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;                &lt;version&gt;5.1.17&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;c3p0&lt;/groupId&gt;                &lt;artifactId&gt;c3p0&lt;/artifactId&gt;                &lt;version&gt;0.9.1.2&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.mybatis&lt;/groupId&gt;                &lt;artifactId&gt;mybatis&lt;/artifactId&gt;                &lt;version&gt;3.2.1&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;junit&lt;/groupId&gt;                &lt;artifactId&gt;junit&lt;/artifactId&gt;                &lt;version&gt;4.11&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;                &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.mybatis&lt;/groupId&gt;                &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;                &lt;version&gt;1.3.0&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.aspectj&lt;/groupId&gt;                &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;                &lt;version&gt;1.8.10&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/project&gt;4.创建包    com.it18zhang.ssm.dao.impl    com.it18zhang.ssm.service.impl    com.it18zhang.ssm.domain    com.it18zhang.ssm.util    com.it18zhang.ssm.web.controller5.创建基本类库    com.it18zhang.ssm.domain.User    com.it18zhang.ssm.domain.Order    com.it18zhang.ssm.domain.Item    ...6.复制beans.xml + mybatis-cconfig.xml+UserMapper.xml + OrderMapper.xml + ItemMapper.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;           xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;           xmlns:context=&quot;http://www.springframework.org/schema/context&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                               http://www.springframework.org/schema/beans/spring-beans.xsd                               http://www.springframework.org/schema/context                               http://www.springframework.org/schema/context/spring-context-4.3.xsd                               http://www.springframework.org/schema/tx                               http://www.springframework.org/schema/tx/spring-tx-4.3.xsd                               http://www.springframework.org/schema/aop                               http://www.springframework.org/schema/aop/spring-aop-4.3.xsd&quot; default-autowire=&quot;byType&quot;&gt;        &lt;!-- 配置事务特征 --&gt;        &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;txManager&quot;&gt;            &lt;tx:attributes&gt;                &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot; isolation=&quot;DEFAULT&quot;/&gt;            &lt;/tx:attributes&gt;        &lt;/tx:advice&gt;        &lt;!-- 配置事务切面 --&gt;        &lt;aop:config&gt;            &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut=&quot;execution(* *..*Service.*(..))&quot; /&gt;        &lt;/aop:config&gt;        &lt;!-- 扫描包 --&gt;        &lt;context:component-scan base-package=&quot;com.it18zhang.ssm.dao,com.it18zhang.ssm.service&quot; /&gt;        &lt;!-- 数据源 --&gt;        &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;            &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;            &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?user=root&amp;amp;password=root&quot;/&gt;            &lt;property name=&quot;user&quot; value=&quot;root&quot;/&gt;            &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;property name=&quot;maxPoolSize&quot; value=&quot;10&quot;/&gt;            &lt;property name=&quot;minPoolSize&quot; value=&quot;2&quot;/&gt;            &lt;property name=&quot;initialPoolSize&quot; value=&quot;3&quot;/&gt;            &lt;property name=&quot;acquireIncrement&quot; value=&quot;2&quot;/&gt;        &lt;/bean&gt;        &lt;!-- mybatis整合spring的核心类。 --&gt;        &lt;bean id=&quot;sf&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;            &lt;!-- 指定数据源 --&gt;            &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;            &lt;!-- 指定mybatis配置文件 --&gt;            &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt;        &lt;/bean&gt;        &lt;!-- 数据源事务管理器 --&gt;        &lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;            &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;        &lt;/bean&gt;    &lt;/beans&gt;    ...7.创建UserController.java    package com.it18zhang.ssm.web.controller;    import com.it18zhang.ssm.domain.User;    import com.it18zhang.ssm.service.UserService;    import org.springframework.stereotype.Controller;    import org.springframework.ui.Model;    import org.springframework.web.bind.annotation.RequestMapping;    import javax.annotation.Resource;    import java.util.List;    /**     *     */    @Controller    public class UserController {        @Resource(name=&quot;userService&quot;)        private UserService us ;        /**         * 查看全部user         */        @RequestMapping(&quot;/user/findall&quot;)        public String findAll(Model m ){            List&lt;User&gt; list = us.selectAll();            m.addAttribute(&quot;allUsers&quot;,list);            return &quot;user/userList&quot; ;        }    }8.编写web.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot;             version=&quot;3.1&quot;&gt;        &lt;!-- 指定spring的配置文件beans.xml --&gt;        &lt;context-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath*:beans.xml&lt;/param-value&gt;        &lt;/context-param&gt;        &lt;!-- 确保web服务器启动时，完成spring的容器初始化 --&gt;        &lt;listener&gt;            &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;        &lt;/listener&gt;        &lt;!-- 配置分发器Servlet --&gt;        &lt;servlet&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;/servlet&gt;        &lt;servlet-mapping&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;url-pattern&gt;/&lt;/url-pattern&gt;        &lt;/servlet-mapping&gt;    &lt;/web-app&gt;9.编写WEB-INF/dispatcher-servlet.xml    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;           xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;           xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;           xmlns:context=&quot;http://www.springframework.org/schema/context&quot;           xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans                            http://www.springframework.org/schema/beans/spring-beans.xsd                            http://www.springframework.org/schema/mvc                            http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd                            http://www.springframework.org/schema/context                            http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt;        &lt;!-- 配置扫描路径 --&gt;        &lt;context:component-scan base-package=&quot;com.it18zhang.ssm.web.controller&quot; /&gt;        &lt;!-- 使用注解驱动 --&gt;        &lt;mvc:annotation-driven   /&gt;        &lt;!-- 内部资源视图解析器 --&gt;        &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;            &lt;property name=&quot;prefix&quot; value=&quot;/&quot; /&gt;            &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;        &lt;/bean&gt;    &lt;/beans&gt;</code></pre><h2 id="spring-mvc静态资源部分"><a href="#spring-mvc静态资源部分" class="headerlink" title="spring mvc静态资源部分"></a>spring mvc静态资源部分</h2><pre><code>1.描述    html    image    css    js2.在[dispatcher-servlet.xml]添加如下元素    &lt;mvc:resources mapping=&quot;/jsssss/**&quot; location=&quot;/js/&quot;/&gt;    &lt;mvc:resources mapping=&quot;/css/**&quot; location=&quot;/css/&quot;/&gt;    &lt;mvc:resources mapping=&quot;/images/**&quot; location=&quot;/images/&quot;/&gt;    &lt;mvc:resources mapping=&quot;/html/**&quot; location=&quot;/html/&quot;/&gt;3.常见相关目录    /web/js    /web/css    /web/images    /web/html4.放置相应文件    /web/html/hello.html    &lt;!DOCTYPE html&gt;    &lt;html lang=&quot;en&quot;&gt;    &lt;head&gt;        &lt;meta charset=&quot;UTF-8&quot;&gt;        &lt;title&gt;Hello.html&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div&gt;hello&lt;/div&gt;        &lt;table&gt;            &lt;tr&gt;                &lt;td&gt;ID&lt;/td&gt;                &lt;td&gt;name&lt;/td&gt;                &lt;td&gt;age&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;1&lt;/td&gt;                &lt;td&gt;tom&lt;/td&gt;                &lt;td&gt;12&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;2&lt;/td&gt;                &lt;td&gt;tomas&lt;/td&gt;                &lt;td&gt;13&lt;/td&gt;            &lt;/tr&gt;            &lt;tr&gt;                &lt;td&gt;3&lt;/td&gt;                &lt;td&gt;tomasLee&lt;/td&gt;                &lt;td&gt;4&lt;/td&gt;            &lt;/tr&gt;        &lt;/table&gt;    &lt;/body&gt;    &lt;/html&gt;5.启动程序访问    http://localhost:9090/html/hello.html</code></pre><h2 id="css选择器"><a href="#css选择器" class="headerlink" title="css选择器"></a>css选择器</h2><pre><code>table            //标签选择#id                //id选择.class-name        //类选择tabble td        //后台选择</code></pre><h2 id="中文乱码"><a href="#中文乱码" class="headerlink" title="中文乱码"></a>中文乱码</h2><pre><code>1.jsp页面使用&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; language=&quot;java&quot; %&gt;进行utf8码声明。2.在web.xml文件中，加入filter。    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;             xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;             xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot;             version=&quot;3.1&quot;&gt;        &lt;!-- 指定spring的配置文件beans.xml --&gt;        &lt;context-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath*:beans.xml&lt;/param-value&gt;        &lt;/context-param&gt;        &lt;!-- 确保web服务器启动时，完成spring的容器初始化 --&gt;        &lt;listener&gt;            &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;        &lt;/listener&gt;        &lt;filter&gt;            &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;            &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;            &lt;init-param&gt;                &lt;param-name&gt;encoding&lt;/param-name&gt;                &lt;param-value&gt;UTF-8&lt;/param-value&gt;            &lt;/init-param&gt;            &lt;init-param&gt;                &lt;param-name&gt;forceEncoding&lt;/param-name&gt;                &lt;param-value&gt;true&lt;/param-value&gt;            &lt;/init-param&gt;        &lt;/filter&gt;        &lt;filter-mapping&gt;            &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;            &lt;url-pattern&gt;/*&lt;/url-pattern&gt;        &lt;/filter-mapping&gt;        &lt;!-- 配置分发器Servlet --&gt;        &lt;servlet&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;/servlet&gt;        &lt;servlet-mapping&gt;            &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;            &lt;url-pattern&gt;/&lt;/url-pattern&gt;        &lt;/servlet-mapping&gt;    &lt;/web-app&gt;3.确认mysql使用utf8编码，可以修改mysql的编码.    [mysql安装目录/my.ini]    uft84.spring中的数据库连接地址url中显式指定编码.    [beans.xml]    &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?user=root&amp;amp;password=root&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&quot;/&gt;</code></pre><p>unicode : 2        //两个字节</p><p>ascii    : 1        //7<br>iso8859 : 1        //8<br>utf8            //3<br>gbk                //2</p><h2 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h2><pre><code>0.技术背景    mysql:    select * from users limit 10 101.dao + service2.userList.jsp3.4.5.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;新建SSM模块，添加完之后再加入maven支持，刷新  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/p9PS1Gs.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;session数据访问&quot;&gt;&lt;a href=&quot;#session数据访问&quot; cl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>电信项目第一天</title>
    <link href="http://erichunn.github.io/2019/01/05/%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>http://erichunn.github.io/2019/01/05/电信项目第一天/</id>
    <published>2019-01-05T02:44:38.000Z</published>
    <updated>2019-01-05T14:42:44.415Z</updated>
    
    <content type="html"><![CDATA[<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化:"></a>可视化:</h2><pre><code>1.2.3.4.5.</code></pre><p>package com.it18zhang.callloggen;</p><p>import java.util.HashMap;<br>import java.util.Map;</p><p>/*<em> </em><br> */<br>public class App {<br>    public static Map&lt;String,String&gt; caller = new HashMap&lt;String, String&gt;();<br>    static{<br>        caller.put(“15810092493”, “史玉龙”);<br>        caller.put(“18000696806”, “赵贺彪”);<br>        caller.put(“15151889601”, “张倩 “);<br>        caller.put(“13269361119”, “王世昌”);<br>        caller.put(“15032293356”, “张涛”);<br>        caller.put(“17731088562”, “张阳”);<br>        caller.put(“15338595369”, “李进全”);<br>        caller.put(“15733218050”, “杜泽文”);<br>        caller.put(“15614201525”, “任宗阳”);<br>        caller.put(“15778423030”, “梁鹏”);<br>        caller.put(“18641241020”, “郭美彤”);<br>        caller.put(“15732648446”, “刘飞飞”);<br>        caller.put(“13341109505”, “段光星”);<br>        caller.put(“13560190665”, “唐会华”);<br>        caller.put(“18301589432”, “杨力谋”);<br>        caller.put(“13520404983”, “温海英”);<br>        caller.put(“18332562075”, “朱尚宽”);<br>        caller.put(“18620192711”, “刘能宗”);<br>    }</p><pre><code>public static void main(String[] args) {    genCallLog();}public static void genCallLog(){}</code></pre><h2 id="生成jar包，部署到centos执行"><a href="#生成jar包，部署到centos执行" class="headerlink" title="生成jar包，部署到centos执行"></a>生成jar包，部署到centos执行</h2><pre><code>1.使用maven生成jar文件    ...2.部署到centos3.执行    $&gt;mkdir /home/centos/calllog    java -cp xxx.jar com.it18zhang.callloggen.App /home/centos/calllog/calllog.log4.创建centos上的执行脚本    [calllog.sh]    #!/bin/bash    java -cp Calllog.jar com.it18zhang.callloggen.App /home/centos/calllog/calllog.log5.修改权限    $&gt;chmod a+x calllog.sh6.执行脚本    $&gt;cd ~/calllog    $&gt;./calllog.sh</code></pre><h2 id="手机号"><a href="#手机号" class="headerlink" title="手机号"></a>手机号</h2><pre><code>0755-67568979186----------</code></pre><p>086+0755-67568979</p><h2 id="固话"><a href="#固话" class="headerlink" title="固话"></a>固话</h2><pre><code>0755-675689790755-67568979</code></pre><h2 id="网络电话"><a href="#网络电话" class="headerlink" title="网络电话"></a>网络电话</h2><pre><code>12358757575765656565</code></pre><h2 id="启动zk集群-s201-s202-s203"><a href="#启动zk集群-s201-s202-s203" class="headerlink" title="启动zk集群[s201 + s202 + s203]"></a>启动zk集群[s201 + s202 + s203]</h2><pre><code>$&gt;zkServer.sh start </code></pre><h2 id="启动kafka集群-s202-s203-s204"><a href="#启动kafka集群-s202-s203-s204" class="headerlink" title="启动kafka集群[s202 + s203 + s204]"></a>启动kafka集群[s202 + s203 + s204]</h2><pre><code>$&gt;cd /soft/kafka/config$&gt;kafka-server-start.sh -daemon server.properties</code></pre><h2 id="创建kafka主题"><a href="#创建kafka主题" class="headerlink" title="创建kafka主题"></a>创建kafka主题</h2><pre><code>//创建主题$&gt;kafka-topics.sh --zookeeper s202:2181 --topic calllog --create --replication-factor 3 --partitions 4//查看主题列表$&gt;kafka-topics.sh --zookeeper s202:2181 --list//启动控制台消费者,消费calllog主题,用于测试.测试flume有没有取得到。</code></pre><p>消费者需要连接到zk主题需要连接到zk生产者不用连接zk<br>    $&gt;kafka-console-consumer.sh –zookeeper s201:2181 –topic calllog</p><h2 id="s201上编写flume配置文件件，实时收集calllog-log日志"><a href="#s201上编写flume配置文件件，实时收集calllog-log日志" class="headerlink" title="s201上编写flume配置文件件，实时收集calllog.log日志"></a>s201上编写flume配置文件件，实时收集calllog.log日志</h2><pre><code>1.配置文件    [/soft/flume/conf/calllog.conf]    a1.sources = r1    a1.sinks = k1    a1.channels = c1    a1.sources.r1.type=exec    #-F 最后10行,如果从头开始收集 -c +0 -F:持续收集后续数据,否则进程停止。    a1.sources.r1.command=tail -F -c +0 /home/centos/calllog/calllog.log    a1.channels.c1.type=memory    a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink    a1.sinks.k1.kafka.topic = calllog    #三台节点，启动的时候连接座初始化    a1.sinks.k1.kafka.bootstrap.servers = s202:9092 s203:9092 s204:9092    a1.sinks.k1.kafka.flumeBatchSize = 20    a1.sinks.k1.kafka.producer.acks = 1    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c12.启动flume收集程序    $&gt;flume-ng agent -f /soft/flume/conf/calllog.conf -n a1 &amp;</code></pre><h2 id="在s202主机安装flume软件"><a href="#在s202主机安装flume软件" class="headerlink" title="在s202主机安装flume软件"></a>在s202主机安装flume软件</h2><pre><code>...</code></pre><p>启动hadoop hdfs集群[s201 ~ s206]<br>角色划分:<br>NameNode        //s201,s206<br>DataNode        //s202,s203,s204,s205<br>JournalNode        //s202,s203,s204</p><h2 id="ZK-s201-s206"><a href="#ZK-s201-s206" class="headerlink" title="ZK                //s201,s206"></a>ZK                //s201,s206</h2><pre><code>1.启动hadoop(完全分布式 + HA,HA是s201 + s206作为主备名称节点namenode的2个节点)    在s201上启动dfs集群.    $&gt;start-dfs.sh2.webui        http://s201:50070/3.查看节点状态    $&gt;hdfs haadmin -getServiceState nn14.容灾切换    $&gt;hdfs haadmin -failover nn1 nn2</code></pre><h2 id="启动hbase集群"><a href="#启动hbase集群" class="headerlink" title="启动hbase集群"></a>启动hbase集群</h2><pre><code>1.[角色划分]对hbase做高可用    master            //s201,s204    regsionServer    //s202,s203,s2042.启动hbase集群    //s201    $&gt;start-hbase.sh3.查看进程和webui    http://s201:160104.启动备份master节点    //s204    $&gt;hbase-daemon.sh start master</code></pre><h2 id="创建hbase名字空间-表"><a href="#创建hbase名字空间-表" class="headerlink" title="创建hbase名字空间+表"></a>创建hbase名字空间+表</h2><pre><code>1.创建名字空间    $&gt;hbase shell                        //进入hbase shell    $hbase&gt;create_namespace &apos;ns1&apos;        //创建空间    $hbase&gt;create &apos;ns1:calllogs&apos; , &apos;f1&apos;    //创建表    $hbase&gt;truncate &apos;ns1:calllogs&apos;        //重建表</code></pre><h2 id="IBM-Power720-210000"><a href="#IBM-Power720-210000" class="headerlink" title="IBM Power720(210000) "></a>IBM Power720(210000) </h2><pre><code>基本规格    处理器类型POWER7+处理器主频3.6GHz处理器缓存每个内核256KB二级缓存，4MB三级缓存最大处理器个数8内存类型DDR3标准内存容量32GB最大内存容量128GB4颗CPU</code></pre><h2 id="去IOE"><a href="#去IOE" class="headerlink" title="去IOE"></a>去IOE</h2><pre><code>IBM:        //ibm小型机Oracle:        //oracle数据EMC            //网络存储设备</code></pre><h2 id="戴尔（DELL）13900-100-140万"><a href="#戴尔（DELL）13900-100-140万" class="headerlink" title="戴尔（DELL）13900 * 100 = 140万 "></a>戴尔（DELL）13900 * 100 = 140万 </h2><pre><code>商品名称：戴尔（DELL）R730服务器 机架式主机    2U 至强        E5处理器 内存类型    ECC硬盘总容量：8T以上 8T x 100 = 800T = 副本(3) 800/3 = 250  80%(4/5) =  150T类型：机架服务器电源：冗余操作系统：    DOS内存        总容量：64G及以上硬盘转速：其他支持CPU颗数    2颗机箱规格    2U机架式显存        集成显卡硬盘类型    SASRaid卡        缓存：        无缓存处理器：    至强Xeon-E5</code></pre><h2 id="创建kafka消费者，订阅calllog主题"><a href="#创建kafka消费者，订阅calllog主题" class="headerlink" title="创建kafka消费者，订阅calllog主题"></a>创建kafka消费者，订阅calllog主题</h2><pre><code>1.设计rowkey    业务数据: caller , callee , date , duration    分区号    号码     时间,标记  (对方号码),时长    regionNo, caller,date , flag,callee,duration    caller(11) + 通话时间(201701) =     (后四位) + 201701 = % 1002.3.4.</code></pre><p>11 - 4 = 7</p><p>hbase(main):001:0&gt; scan ‘ns1:calllogs’<br>ROW                             COLUMN+CELL<br> 39,15032293356,20170313140201,0,18620192711,297 column=f1:callDuration, timestamp=1491896679156, value=297</p><p> 39,15032293356,20170313140201,0,18620192711,297 column=f1:callTime, timestamp=1491896679156, value=20170313140201</p><p> 39,15032293356,20170313140201,0,18620192711,297 column=f1:callee, timestamp=1491896679156, value=18620192711</p><p> 39,15032293356,20170313140201,0,18620192711,297 column=f1:caller, timestamp=1491896679156, value=15032293356</p><p> 93,18620192711,20170313140201,1,15032293356,297 column=f1:dummy, timestamp=1491896679184, value=no</p><h2 id="使用mvn命令，下载工件的所有依赖软件包"><a href="#使用mvn命令，下载工件的所有依赖软件包" class="headerlink" title="使用mvn命令，下载工件的所有依赖软件包"></a>使用mvn命令，下载工件的所有依赖软件包</h2><pre><code>mvn -DoutputDirectory=./lib     -DgroupId=com.it18zhang     -DartifactId=CallLogConsumerModule     -Dversion=1.0-SNAPSHOT     dependency:copy-dependencies</code></pre><h2 id="导入kafka消费者，放置以上面的lib下，使用命令行方式运行"><a href="#导入kafka消费者，放置以上面的lib下，使用命令行方式运行" class="headerlink" title="导入kafka消费者，放置以上面的lib下，使用命令行方式运行"></a>导入kafka消费者，放置以上面的lib下，使用命令行方式运行</h2><pre><code>java -cp CallLogConsumerModule.jar;./lib/activation-1.1.jar;./lib/apacheds-i18n-2.0.0-M15.jar;./lib/apacheds-kerberos-codec-2.0.0-M15.jar;./lib/api-asn1-api-1.0.0-M20.jar;./lib/api-util-1.0.0-M20.jar;./lib/avro-1.7.4.jar;./lib/commons-beanutils-1.7.0.jar;./lib/commons-beanutils-core-1.8.0.jar;./lib/commons-cli-1.2.jar;./lib/commons-codec-1.9.jar;./lib/commons-collections-3.2.2.jar;./lib/commons-compress-1.4.1.jar;./lib/commons-configuration-1.6.jar;./lib/commons-digester-1.8.jar;./lib/commons-el-1.0.jar;./lib/commons-httpclient-3.1.jar;./lib/commons-io-2.4.jar;./lib/commons-lang-2.6.jar;./lib/commons-logging-1.2.jar;./lib/commons-math3-3.1.1.jar;./lib/commons-net-3.1.jar;./lib/findbugs-annotations-1.3.9-1.jar;./lib/guava-12.0.1.jar;./lib/hadoop-annotations-2.5.1.jar;./lib/hadoop-auth-2.5.1.jar;./lib/hadoop-common-2.5.1.jar;./lib/hadoop-mapreduce-client-core-2.5.1.jar;./lib/hadoop-yarn-api-2.5.1.jar;./lib/hadoop-yarn-common-2.5.1.jar;./lib/hamcrest-core-1.3.jar;./lib/hbase-annotations-1.2.4.jar;./lib/hbase-client-1.2.4.jar;./lib/hbase-common-1.2.4.jar;./lib/hbase-protocol-1.2.4.jar;./lib/htrace-core-3.1.0-incubating.jar;./lib/httpclient-4.2.5.jar;./lib/httpcore-4.2.4.jar;./lib/jackson-core-asl-1.9.13.jar;./lib/jackson-mapper-asl-1.9.13.jar;./lib/jaxb-api-2.2.2.jar;./lib/jcodings-1.0.8.jar;./lib/jdk.tools-1.6.jar;./lib/jetty-util-6.1.26.jar;./lib/jline-0.9.94.jar;./lib/joni-2.1.2.jar;./lib/jopt-simple-4.9.jar;./lib/jsch-0.1.42.jar;./lib/jsr305-1.3.9.jar;./lib/junit-4.12.jar;./lib/kafka-clients-0.10.0.1.jar;./lib/kafka_2.11-0.10.0.1.jar;./lib/log4j-1.2.15.jar;./lib/lz4-1.3.0.jar;./lib/mail-1.4.jar;./lib/metrics-core-2.2.0.jar;./lib/netty-3.7.0.Final.jar;./lib/netty-all-4.0.23.Final.jar;./lib/paranamer-2.3.jar;./lib/protobuf-java-2.5.0.jar;./lib/scala-library-2.11.8.jar;./lib/scala-parser-combinators_2.11-1.0.4.jar;./lib/slf4j-api-1.6.1.jar;./lib/slf4j-log4j12-1.7.21.jar;./lib/snappy-java-1.1.2.6.jar;./lib/stax-api-1.0-2.jar;./lib/xmlenc-0.52.jar;./lib/xz-1.0.jar;./lib/zkclient-0.8.jar;./lib/zookeeper-3.4.6.jar com.it18zhang.calllog.consumer.HbaseConsumer</code></pre><h2 id="编写web程序，从hbase中提取所有进行展示，可视化"><a href="#编写web程序，从hbase中提取所有进行展示，可视化" class="headerlink" title="编写web程序，从hbase中提取所有进行展示，可视化"></a>编写web程序，从hbase中提取所有进行展示，可视化</h2><pre><code>1.导入ssm项目    ...2.创建CallLog    ...3.创建CallLogService.java + CallLogServiceImpl.java    ...4.</code></pre><p>=======================================</p><p>在windows下编写的.sh文件到了linux上变成不可用了什么原因：<br><img src="https://i.imgur.com/5aOaIic.png" alt=""></p><p>因为换行符的原因，windows下的换行符和Linux下的换行符不一样。所以要在linux下编写.sh文件即可解决。</p><p>=================</p><p>kafka同一个组下只能有一个消费者。被消费一次就不能再次消费了</p><p>所以修改配置文件里面的group.id=5。这是kafka里面的具体问题了。</p><p>==================</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;可视化&quot;&gt;&lt;a href=&quot;#可视化&quot; class=&quot;headerlink&quot; title=&quot;可视化:&quot;&gt;&lt;/a&gt;可视化:&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;1.
2.
3.
4.
5.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;package com.it18zhang.cal
      
    
    </summary>
    
    
  </entry>
  
</feed>
